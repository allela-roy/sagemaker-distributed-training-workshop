{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Falcon model using SageMaker Distributed Data Parallel Library (SMDDP) and PyTorch Fully Sharded Data Parallelism (FSDP)\n",
    "\n",
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook.\n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/training|distributed_training|pytorch|data_parallel|fully_sharded_data_parallel|falcon|smddp_fsdp_example.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "In this tutorial, we will show how to train or fine-tune [Falcon-7B-instruct](https://huggingface.co/tiiuae/falcon-7b-instruct) on the [GLUE/SST2](https://huggingface.co/datasets/glue/viewer/sst2/train) dataset.  We will use 2 p4d.24xlarge instances, which come with 8 NVIDIA A100 40GB GPUs along with the PyTorch Fully Sharded Data Parallelism (FSDP) technique to efficiently train this large model with limited GPU memory.  \n",
    "\n",
    "To accelerate training speed, we will also use the **SageMaker Distributed Data Parallel Library (SMDDP)** which speeds up GPU communication across P4d instances during sharded data parallel training.  \n",
    "\n",
    "## Files\n",
    "\n",
    "* `scripts/train.py` - The entry point for the training script where we initialize the SMDDP library.\n",
    "* `scripts/utils.py` - Helper script for defining dataloaders\n",
    "* `scripts/requirements.txt` - List of dependencies required for this example to train on SageMaker\n",
    "\n",
    "*Note: The SMDDP library for accelerated sharded data parallel training is compatible with deep learning containers from PyTorch 2.0 onwards.  Ensure you are using PyTorch >=2.0 for this example.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How optimized GPU communication is enabled with SMDDP in FSDP\n",
    "Enabling the SMDDP library in an existing FSDP training script is seamless.  As shown in `train.py`, the only code modifications required are:\n",
    "* Importing the library: `import smdistributed.dataparallel.torch.torch_smddp`\n",
    "* Creating the process group with `\"smddp\"` backend: `torch.distributed.init_process_group(\"smddp\")`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting started\n",
    "\n",
    "First, we'll install some dependencies in our current environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use Sagemaker in a local environment, you need access to an IAM Role with the required permissions for Sagemaker. You can find more about it [here](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::015476483300:role/service-role/AmazonSageMaker-ExecutionRole-20240126T111548\n",
      "sagemaker bucket: sagemaker_session_bucket\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker, boto3, datetime\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    role = iam.get_role(RoleName=\"sagemaker_execution_role\")[\"Role\"][\"Arn\"]\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker session region: {sagemaker_session.boto_region_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and prepare the dataset\n",
    "\n",
    "As the base dataset, we will use the [GLUE/SST2](https://huggingface.co/datasets/glue/viewer/sst2/train) dataset, but before training the model, we need to preprocess the data. We will create chunks of `2048` tokens ([model max length](https://huggingface.co/EleutherAI/gpt-neox-20b)) to avoid unnecessary padding and computing. \n",
    "\n",
    "The first step is to load our dataset from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"tiiuae/falcon-7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_worker_batches(num_of_hf_splits, num_of_workers, token, split_name):\n",
    "    \"\"\"\n",
    "    Create a list of worker batches for processing a dataset.\n",
    "\n",
    "    Args:\n",
    "        num_of_hf_splits (int): The number of Hugging Face dataset splits.\n",
    "        num_of_workers (int): The number of worker processes.\n",
    "        token (str): The token to be replaced in the split name.\n",
    "        split_name (str): The base name of the dataset split files.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of worker batches, where each batch is a list of file names.\n",
    "    \"\"\"\n",
    "    batch_size = num_of_hf_splits // num_of_workers\n",
    "\n",
    "    worker_batches = []\n",
    "    for worker_index in range(num_of_workers):\n",
    "        worker_node = []\n",
    "        start = worker_index * batch_size\n",
    "        end = start + batch_size\n",
    "        for batch in range(start, end):\n",
    "            file_name = split_name.replace(token, str(batch).zfill(5))\n",
    "            worker_node.append(file_name)\n",
    "        worker_batches.append(worker_node)\n",
    "\n",
    "    return worker_batches\n",
    "\n",
    "# Example usage\n",
    "num_of_hf_splits = 1024\n",
    "num_of_workers = 200\n",
    "token = 'split_number'\n",
    "split_name = f'en/c4-train.{token}-of-01024.json.gz'\n",
    "\n",
    "worker_batches = create_worker_batches(num_of_hf_splits, num_of_workers, token, split_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en/c4-train.00000-of-01024.json.gz', 'en/c4-train.00001-of-01024.json.gz', 'en/c4-train.00002-of-01024.json.gz', 'en/c4-train.00003-of-01024.json.gz', 'en/c4-train.00004-of-01024.json.gz']\n",
      "['en/c4-train.00005-of-01024.json.gz', 'en/c4-train.00006-of-01024.json.gz', 'en/c4-train.00007-of-01024.json.gz', 'en/c4-train.00008-of-01024.json.gz', 'en/c4-train.00009-of-01024.json.gz']\n",
      "['en/c4-train.00010-of-01024.json.gz', 'en/c4-train.00011-of-01024.json.gz', 'en/c4-train.00012-of-01024.json.gz', 'en/c4-train.00013-of-01024.json.gz', 'en/c4-train.00014-of-01024.json.gz']\n",
      "['en/c4-train.00015-of-01024.json.gz', 'en/c4-train.00016-of-01024.json.gz', 'en/c4-train.00017-of-01024.json.gz', 'en/c4-train.00018-of-01024.json.gz', 'en/c4-train.00019-of-01024.json.gz']\n",
      "['en/c4-train.00020-of-01024.json.gz', 'en/c4-train.00021-of-01024.json.gz', 'en/c4-train.00022-of-01024.json.gz', 'en/c4-train.00023-of-01024.json.gz', 'en/c4-train.00024-of-01024.json.gz']\n",
      "['en/c4-train.00025-of-01024.json.gz', 'en/c4-train.00026-of-01024.json.gz', 'en/c4-train.00027-of-01024.json.gz', 'en/c4-train.00028-of-01024.json.gz', 'en/c4-train.00029-of-01024.json.gz']\n",
      "['en/c4-train.00030-of-01024.json.gz', 'en/c4-train.00031-of-01024.json.gz', 'en/c4-train.00032-of-01024.json.gz', 'en/c4-train.00033-of-01024.json.gz', 'en/c4-train.00034-of-01024.json.gz']\n",
      "['en/c4-train.00035-of-01024.json.gz', 'en/c4-train.00036-of-01024.json.gz', 'en/c4-train.00037-of-01024.json.gz', 'en/c4-train.00038-of-01024.json.gz', 'en/c4-train.00039-of-01024.json.gz']\n",
      "['en/c4-train.00040-of-01024.json.gz', 'en/c4-train.00041-of-01024.json.gz', 'en/c4-train.00042-of-01024.json.gz', 'en/c4-train.00043-of-01024.json.gz', 'en/c4-train.00044-of-01024.json.gz']\n",
      "['en/c4-train.00045-of-01024.json.gz', 'en/c4-train.00046-of-01024.json.gz', 'en/c4-train.00047-of-01024.json.gz', 'en/c4-train.00048-of-01024.json.gz', 'en/c4-train.00049-of-01024.json.gz']\n",
      "['en/c4-train.00050-of-01024.json.gz', 'en/c4-train.00051-of-01024.json.gz', 'en/c4-train.00052-of-01024.json.gz', 'en/c4-train.00053-of-01024.json.gz', 'en/c4-train.00054-of-01024.json.gz']\n",
      "['en/c4-train.00055-of-01024.json.gz', 'en/c4-train.00056-of-01024.json.gz', 'en/c4-train.00057-of-01024.json.gz', 'en/c4-train.00058-of-01024.json.gz', 'en/c4-train.00059-of-01024.json.gz']\n",
      "['en/c4-train.00060-of-01024.json.gz', 'en/c4-train.00061-of-01024.json.gz', 'en/c4-train.00062-of-01024.json.gz', 'en/c4-train.00063-of-01024.json.gz', 'en/c4-train.00064-of-01024.json.gz']\n",
      "['en/c4-train.00065-of-01024.json.gz', 'en/c4-train.00066-of-01024.json.gz', 'en/c4-train.00067-of-01024.json.gz', 'en/c4-train.00068-of-01024.json.gz', 'en/c4-train.00069-of-01024.json.gz']\n",
      "['en/c4-train.00070-of-01024.json.gz', 'en/c4-train.00071-of-01024.json.gz', 'en/c4-train.00072-of-01024.json.gz', 'en/c4-train.00073-of-01024.json.gz', 'en/c4-train.00074-of-01024.json.gz']\n",
      "['en/c4-train.00075-of-01024.json.gz', 'en/c4-train.00076-of-01024.json.gz', 'en/c4-train.00077-of-01024.json.gz', 'en/c4-train.00078-of-01024.json.gz', 'en/c4-train.00079-of-01024.json.gz']\n",
      "['en/c4-train.00080-of-01024.json.gz', 'en/c4-train.00081-of-01024.json.gz', 'en/c4-train.00082-of-01024.json.gz', 'en/c4-train.00083-of-01024.json.gz', 'en/c4-train.00084-of-01024.json.gz']\n",
      "['en/c4-train.00085-of-01024.json.gz', 'en/c4-train.00086-of-01024.json.gz', 'en/c4-train.00087-of-01024.json.gz', 'en/c4-train.00088-of-01024.json.gz', 'en/c4-train.00089-of-01024.json.gz']\n",
      "['en/c4-train.00090-of-01024.json.gz', 'en/c4-train.00091-of-01024.json.gz', 'en/c4-train.00092-of-01024.json.gz', 'en/c4-train.00093-of-01024.json.gz', 'en/c4-train.00094-of-01024.json.gz']\n",
      "['en/c4-train.00095-of-01024.json.gz', 'en/c4-train.00096-of-01024.json.gz', 'en/c4-train.00097-of-01024.json.gz', 'en/c4-train.00098-of-01024.json.gz', 'en/c4-train.00099-of-01024.json.gz']\n",
      "['en/c4-train.00100-of-01024.json.gz', 'en/c4-train.00101-of-01024.json.gz', 'en/c4-train.00102-of-01024.json.gz', 'en/c4-train.00103-of-01024.json.gz', 'en/c4-train.00104-of-01024.json.gz']\n",
      "['en/c4-train.00105-of-01024.json.gz', 'en/c4-train.00106-of-01024.json.gz', 'en/c4-train.00107-of-01024.json.gz', 'en/c4-train.00108-of-01024.json.gz', 'en/c4-train.00109-of-01024.json.gz']\n",
      "['en/c4-train.00110-of-01024.json.gz', 'en/c4-train.00111-of-01024.json.gz', 'en/c4-train.00112-of-01024.json.gz', 'en/c4-train.00113-of-01024.json.gz', 'en/c4-train.00114-of-01024.json.gz']\n",
      "['en/c4-train.00115-of-01024.json.gz', 'en/c4-train.00116-of-01024.json.gz', 'en/c4-train.00117-of-01024.json.gz', 'en/c4-train.00118-of-01024.json.gz', 'en/c4-train.00119-of-01024.json.gz']\n",
      "['en/c4-train.00120-of-01024.json.gz', 'en/c4-train.00121-of-01024.json.gz', 'en/c4-train.00122-of-01024.json.gz', 'en/c4-train.00123-of-01024.json.gz', 'en/c4-train.00124-of-01024.json.gz']\n",
      "['en/c4-train.00125-of-01024.json.gz', 'en/c4-train.00126-of-01024.json.gz', 'en/c4-train.00127-of-01024.json.gz', 'en/c4-train.00128-of-01024.json.gz', 'en/c4-train.00129-of-01024.json.gz']\n",
      "['en/c4-train.00130-of-01024.json.gz', 'en/c4-train.00131-of-01024.json.gz', 'en/c4-train.00132-of-01024.json.gz', 'en/c4-train.00133-of-01024.json.gz', 'en/c4-train.00134-of-01024.json.gz']\n",
      "['en/c4-train.00135-of-01024.json.gz', 'en/c4-train.00136-of-01024.json.gz', 'en/c4-train.00137-of-01024.json.gz', 'en/c4-train.00138-of-01024.json.gz', 'en/c4-train.00139-of-01024.json.gz']\n",
      "['en/c4-train.00140-of-01024.json.gz', 'en/c4-train.00141-of-01024.json.gz', 'en/c4-train.00142-of-01024.json.gz', 'en/c4-train.00143-of-01024.json.gz', 'en/c4-train.00144-of-01024.json.gz']\n",
      "['en/c4-train.00145-of-01024.json.gz', 'en/c4-train.00146-of-01024.json.gz', 'en/c4-train.00147-of-01024.json.gz', 'en/c4-train.00148-of-01024.json.gz', 'en/c4-train.00149-of-01024.json.gz']\n",
      "['en/c4-train.00150-of-01024.json.gz', 'en/c4-train.00151-of-01024.json.gz', 'en/c4-train.00152-of-01024.json.gz', 'en/c4-train.00153-of-01024.json.gz', 'en/c4-train.00154-of-01024.json.gz']\n",
      "['en/c4-train.00155-of-01024.json.gz', 'en/c4-train.00156-of-01024.json.gz', 'en/c4-train.00157-of-01024.json.gz', 'en/c4-train.00158-of-01024.json.gz', 'en/c4-train.00159-of-01024.json.gz']\n",
      "['en/c4-train.00160-of-01024.json.gz', 'en/c4-train.00161-of-01024.json.gz', 'en/c4-train.00162-of-01024.json.gz', 'en/c4-train.00163-of-01024.json.gz', 'en/c4-train.00164-of-01024.json.gz']\n",
      "['en/c4-train.00165-of-01024.json.gz', 'en/c4-train.00166-of-01024.json.gz', 'en/c4-train.00167-of-01024.json.gz', 'en/c4-train.00168-of-01024.json.gz', 'en/c4-train.00169-of-01024.json.gz']\n",
      "['en/c4-train.00170-of-01024.json.gz', 'en/c4-train.00171-of-01024.json.gz', 'en/c4-train.00172-of-01024.json.gz', 'en/c4-train.00173-of-01024.json.gz', 'en/c4-train.00174-of-01024.json.gz']\n",
      "['en/c4-train.00175-of-01024.json.gz', 'en/c4-train.00176-of-01024.json.gz', 'en/c4-train.00177-of-01024.json.gz', 'en/c4-train.00178-of-01024.json.gz', 'en/c4-train.00179-of-01024.json.gz']\n",
      "['en/c4-train.00180-of-01024.json.gz', 'en/c4-train.00181-of-01024.json.gz', 'en/c4-train.00182-of-01024.json.gz', 'en/c4-train.00183-of-01024.json.gz', 'en/c4-train.00184-of-01024.json.gz']\n",
      "['en/c4-train.00185-of-01024.json.gz', 'en/c4-train.00186-of-01024.json.gz', 'en/c4-train.00187-of-01024.json.gz', 'en/c4-train.00188-of-01024.json.gz', 'en/c4-train.00189-of-01024.json.gz']\n",
      "['en/c4-train.00190-of-01024.json.gz', 'en/c4-train.00191-of-01024.json.gz', 'en/c4-train.00192-of-01024.json.gz', 'en/c4-train.00193-of-01024.json.gz', 'en/c4-train.00194-of-01024.json.gz']\n",
      "['en/c4-train.00195-of-01024.json.gz', 'en/c4-train.00196-of-01024.json.gz', 'en/c4-train.00197-of-01024.json.gz', 'en/c4-train.00198-of-01024.json.gz', 'en/c4-train.00199-of-01024.json.gz']\n",
      "['en/c4-train.00200-of-01024.json.gz', 'en/c4-train.00201-of-01024.json.gz', 'en/c4-train.00202-of-01024.json.gz', 'en/c4-train.00203-of-01024.json.gz', 'en/c4-train.00204-of-01024.json.gz']\n",
      "['en/c4-train.00205-of-01024.json.gz', 'en/c4-train.00206-of-01024.json.gz', 'en/c4-train.00207-of-01024.json.gz', 'en/c4-train.00208-of-01024.json.gz', 'en/c4-train.00209-of-01024.json.gz']\n",
      "['en/c4-train.00210-of-01024.json.gz', 'en/c4-train.00211-of-01024.json.gz', 'en/c4-train.00212-of-01024.json.gz', 'en/c4-train.00213-of-01024.json.gz', 'en/c4-train.00214-of-01024.json.gz']\n",
      "['en/c4-train.00215-of-01024.json.gz', 'en/c4-train.00216-of-01024.json.gz', 'en/c4-train.00217-of-01024.json.gz', 'en/c4-train.00218-of-01024.json.gz', 'en/c4-train.00219-of-01024.json.gz']\n",
      "['en/c4-train.00220-of-01024.json.gz', 'en/c4-train.00221-of-01024.json.gz', 'en/c4-train.00222-of-01024.json.gz', 'en/c4-train.00223-of-01024.json.gz', 'en/c4-train.00224-of-01024.json.gz']\n",
      "['en/c4-train.00225-of-01024.json.gz', 'en/c4-train.00226-of-01024.json.gz', 'en/c4-train.00227-of-01024.json.gz', 'en/c4-train.00228-of-01024.json.gz', 'en/c4-train.00229-of-01024.json.gz']\n",
      "['en/c4-train.00230-of-01024.json.gz', 'en/c4-train.00231-of-01024.json.gz', 'en/c4-train.00232-of-01024.json.gz', 'en/c4-train.00233-of-01024.json.gz', 'en/c4-train.00234-of-01024.json.gz']\n",
      "['en/c4-train.00235-of-01024.json.gz', 'en/c4-train.00236-of-01024.json.gz', 'en/c4-train.00237-of-01024.json.gz', 'en/c4-train.00238-of-01024.json.gz', 'en/c4-train.00239-of-01024.json.gz']\n",
      "['en/c4-train.00240-of-01024.json.gz', 'en/c4-train.00241-of-01024.json.gz', 'en/c4-train.00242-of-01024.json.gz', 'en/c4-train.00243-of-01024.json.gz', 'en/c4-train.00244-of-01024.json.gz']\n",
      "['en/c4-train.00245-of-01024.json.gz', 'en/c4-train.00246-of-01024.json.gz', 'en/c4-train.00247-of-01024.json.gz', 'en/c4-train.00248-of-01024.json.gz', 'en/c4-train.00249-of-01024.json.gz']\n",
      "['en/c4-train.00250-of-01024.json.gz', 'en/c4-train.00251-of-01024.json.gz', 'en/c4-train.00252-of-01024.json.gz', 'en/c4-train.00253-of-01024.json.gz', 'en/c4-train.00254-of-01024.json.gz']\n",
      "['en/c4-train.00255-of-01024.json.gz', 'en/c4-train.00256-of-01024.json.gz', 'en/c4-train.00257-of-01024.json.gz', 'en/c4-train.00258-of-01024.json.gz', 'en/c4-train.00259-of-01024.json.gz']\n",
      "['en/c4-train.00260-of-01024.json.gz', 'en/c4-train.00261-of-01024.json.gz', 'en/c4-train.00262-of-01024.json.gz', 'en/c4-train.00263-of-01024.json.gz', 'en/c4-train.00264-of-01024.json.gz']\n",
      "['en/c4-train.00265-of-01024.json.gz', 'en/c4-train.00266-of-01024.json.gz', 'en/c4-train.00267-of-01024.json.gz', 'en/c4-train.00268-of-01024.json.gz', 'en/c4-train.00269-of-01024.json.gz']\n",
      "['en/c4-train.00270-of-01024.json.gz', 'en/c4-train.00271-of-01024.json.gz', 'en/c4-train.00272-of-01024.json.gz', 'en/c4-train.00273-of-01024.json.gz', 'en/c4-train.00274-of-01024.json.gz']\n",
      "['en/c4-train.00275-of-01024.json.gz', 'en/c4-train.00276-of-01024.json.gz', 'en/c4-train.00277-of-01024.json.gz', 'en/c4-train.00278-of-01024.json.gz', 'en/c4-train.00279-of-01024.json.gz']\n",
      "['en/c4-train.00280-of-01024.json.gz', 'en/c4-train.00281-of-01024.json.gz', 'en/c4-train.00282-of-01024.json.gz', 'en/c4-train.00283-of-01024.json.gz', 'en/c4-train.00284-of-01024.json.gz']\n",
      "['en/c4-train.00285-of-01024.json.gz', 'en/c4-train.00286-of-01024.json.gz', 'en/c4-train.00287-of-01024.json.gz', 'en/c4-train.00288-of-01024.json.gz', 'en/c4-train.00289-of-01024.json.gz']\n",
      "['en/c4-train.00290-of-01024.json.gz', 'en/c4-train.00291-of-01024.json.gz', 'en/c4-train.00292-of-01024.json.gz', 'en/c4-train.00293-of-01024.json.gz', 'en/c4-train.00294-of-01024.json.gz']\n",
      "['en/c4-train.00295-of-01024.json.gz', 'en/c4-train.00296-of-01024.json.gz', 'en/c4-train.00297-of-01024.json.gz', 'en/c4-train.00298-of-01024.json.gz', 'en/c4-train.00299-of-01024.json.gz']\n",
      "['en/c4-train.00300-of-01024.json.gz', 'en/c4-train.00301-of-01024.json.gz', 'en/c4-train.00302-of-01024.json.gz', 'en/c4-train.00303-of-01024.json.gz', 'en/c4-train.00304-of-01024.json.gz']\n",
      "['en/c4-train.00305-of-01024.json.gz', 'en/c4-train.00306-of-01024.json.gz', 'en/c4-train.00307-of-01024.json.gz', 'en/c4-train.00308-of-01024.json.gz', 'en/c4-train.00309-of-01024.json.gz']\n",
      "['en/c4-train.00310-of-01024.json.gz', 'en/c4-train.00311-of-01024.json.gz', 'en/c4-train.00312-of-01024.json.gz', 'en/c4-train.00313-of-01024.json.gz', 'en/c4-train.00314-of-01024.json.gz']\n",
      "['en/c4-train.00315-of-01024.json.gz', 'en/c4-train.00316-of-01024.json.gz', 'en/c4-train.00317-of-01024.json.gz', 'en/c4-train.00318-of-01024.json.gz', 'en/c4-train.00319-of-01024.json.gz']\n",
      "['en/c4-train.00320-of-01024.json.gz', 'en/c4-train.00321-of-01024.json.gz', 'en/c4-train.00322-of-01024.json.gz', 'en/c4-train.00323-of-01024.json.gz', 'en/c4-train.00324-of-01024.json.gz']\n",
      "['en/c4-train.00325-of-01024.json.gz', 'en/c4-train.00326-of-01024.json.gz', 'en/c4-train.00327-of-01024.json.gz', 'en/c4-train.00328-of-01024.json.gz', 'en/c4-train.00329-of-01024.json.gz']\n",
      "['en/c4-train.00330-of-01024.json.gz', 'en/c4-train.00331-of-01024.json.gz', 'en/c4-train.00332-of-01024.json.gz', 'en/c4-train.00333-of-01024.json.gz', 'en/c4-train.00334-of-01024.json.gz']\n",
      "['en/c4-train.00335-of-01024.json.gz', 'en/c4-train.00336-of-01024.json.gz', 'en/c4-train.00337-of-01024.json.gz', 'en/c4-train.00338-of-01024.json.gz', 'en/c4-train.00339-of-01024.json.gz']\n",
      "['en/c4-train.00340-of-01024.json.gz', 'en/c4-train.00341-of-01024.json.gz', 'en/c4-train.00342-of-01024.json.gz', 'en/c4-train.00343-of-01024.json.gz', 'en/c4-train.00344-of-01024.json.gz']\n",
      "['en/c4-train.00345-of-01024.json.gz', 'en/c4-train.00346-of-01024.json.gz', 'en/c4-train.00347-of-01024.json.gz', 'en/c4-train.00348-of-01024.json.gz', 'en/c4-train.00349-of-01024.json.gz']\n",
      "['en/c4-train.00350-of-01024.json.gz', 'en/c4-train.00351-of-01024.json.gz', 'en/c4-train.00352-of-01024.json.gz', 'en/c4-train.00353-of-01024.json.gz', 'en/c4-train.00354-of-01024.json.gz']\n",
      "['en/c4-train.00355-of-01024.json.gz', 'en/c4-train.00356-of-01024.json.gz', 'en/c4-train.00357-of-01024.json.gz', 'en/c4-train.00358-of-01024.json.gz', 'en/c4-train.00359-of-01024.json.gz']\n",
      "['en/c4-train.00360-of-01024.json.gz', 'en/c4-train.00361-of-01024.json.gz', 'en/c4-train.00362-of-01024.json.gz', 'en/c4-train.00363-of-01024.json.gz', 'en/c4-train.00364-of-01024.json.gz']\n",
      "['en/c4-train.00365-of-01024.json.gz', 'en/c4-train.00366-of-01024.json.gz', 'en/c4-train.00367-of-01024.json.gz', 'en/c4-train.00368-of-01024.json.gz', 'en/c4-train.00369-of-01024.json.gz']\n",
      "['en/c4-train.00370-of-01024.json.gz', 'en/c4-train.00371-of-01024.json.gz', 'en/c4-train.00372-of-01024.json.gz', 'en/c4-train.00373-of-01024.json.gz', 'en/c4-train.00374-of-01024.json.gz']\n",
      "['en/c4-train.00375-of-01024.json.gz', 'en/c4-train.00376-of-01024.json.gz', 'en/c4-train.00377-of-01024.json.gz', 'en/c4-train.00378-of-01024.json.gz', 'en/c4-train.00379-of-01024.json.gz']\n",
      "['en/c4-train.00380-of-01024.json.gz', 'en/c4-train.00381-of-01024.json.gz', 'en/c4-train.00382-of-01024.json.gz', 'en/c4-train.00383-of-01024.json.gz', 'en/c4-train.00384-of-01024.json.gz']\n",
      "['en/c4-train.00385-of-01024.json.gz', 'en/c4-train.00386-of-01024.json.gz', 'en/c4-train.00387-of-01024.json.gz', 'en/c4-train.00388-of-01024.json.gz', 'en/c4-train.00389-of-01024.json.gz']\n",
      "['en/c4-train.00390-of-01024.json.gz', 'en/c4-train.00391-of-01024.json.gz', 'en/c4-train.00392-of-01024.json.gz', 'en/c4-train.00393-of-01024.json.gz', 'en/c4-train.00394-of-01024.json.gz']\n",
      "['en/c4-train.00395-of-01024.json.gz', 'en/c4-train.00396-of-01024.json.gz', 'en/c4-train.00397-of-01024.json.gz', 'en/c4-train.00398-of-01024.json.gz', 'en/c4-train.00399-of-01024.json.gz']\n",
      "['en/c4-train.00400-of-01024.json.gz', 'en/c4-train.00401-of-01024.json.gz', 'en/c4-train.00402-of-01024.json.gz', 'en/c4-train.00403-of-01024.json.gz', 'en/c4-train.00404-of-01024.json.gz']\n",
      "['en/c4-train.00405-of-01024.json.gz', 'en/c4-train.00406-of-01024.json.gz', 'en/c4-train.00407-of-01024.json.gz', 'en/c4-train.00408-of-01024.json.gz', 'en/c4-train.00409-of-01024.json.gz']\n",
      "['en/c4-train.00410-of-01024.json.gz', 'en/c4-train.00411-of-01024.json.gz', 'en/c4-train.00412-of-01024.json.gz', 'en/c4-train.00413-of-01024.json.gz', 'en/c4-train.00414-of-01024.json.gz']\n",
      "['en/c4-train.00415-of-01024.json.gz', 'en/c4-train.00416-of-01024.json.gz', 'en/c4-train.00417-of-01024.json.gz', 'en/c4-train.00418-of-01024.json.gz', 'en/c4-train.00419-of-01024.json.gz']\n",
      "['en/c4-train.00420-of-01024.json.gz', 'en/c4-train.00421-of-01024.json.gz', 'en/c4-train.00422-of-01024.json.gz', 'en/c4-train.00423-of-01024.json.gz', 'en/c4-train.00424-of-01024.json.gz']\n",
      "['en/c4-train.00425-of-01024.json.gz', 'en/c4-train.00426-of-01024.json.gz', 'en/c4-train.00427-of-01024.json.gz', 'en/c4-train.00428-of-01024.json.gz', 'en/c4-train.00429-of-01024.json.gz']\n",
      "['en/c4-train.00430-of-01024.json.gz', 'en/c4-train.00431-of-01024.json.gz', 'en/c4-train.00432-of-01024.json.gz', 'en/c4-train.00433-of-01024.json.gz', 'en/c4-train.00434-of-01024.json.gz']\n",
      "['en/c4-train.00435-of-01024.json.gz', 'en/c4-train.00436-of-01024.json.gz', 'en/c4-train.00437-of-01024.json.gz', 'en/c4-train.00438-of-01024.json.gz', 'en/c4-train.00439-of-01024.json.gz']\n",
      "['en/c4-train.00440-of-01024.json.gz', 'en/c4-train.00441-of-01024.json.gz', 'en/c4-train.00442-of-01024.json.gz', 'en/c4-train.00443-of-01024.json.gz', 'en/c4-train.00444-of-01024.json.gz']\n",
      "['en/c4-train.00445-of-01024.json.gz', 'en/c4-train.00446-of-01024.json.gz', 'en/c4-train.00447-of-01024.json.gz', 'en/c4-train.00448-of-01024.json.gz', 'en/c4-train.00449-of-01024.json.gz']\n",
      "['en/c4-train.00450-of-01024.json.gz', 'en/c4-train.00451-of-01024.json.gz', 'en/c4-train.00452-of-01024.json.gz', 'en/c4-train.00453-of-01024.json.gz', 'en/c4-train.00454-of-01024.json.gz']\n",
      "['en/c4-train.00455-of-01024.json.gz', 'en/c4-train.00456-of-01024.json.gz', 'en/c4-train.00457-of-01024.json.gz', 'en/c4-train.00458-of-01024.json.gz', 'en/c4-train.00459-of-01024.json.gz']\n",
      "['en/c4-train.00460-of-01024.json.gz', 'en/c4-train.00461-of-01024.json.gz', 'en/c4-train.00462-of-01024.json.gz', 'en/c4-train.00463-of-01024.json.gz', 'en/c4-train.00464-of-01024.json.gz']\n",
      "['en/c4-train.00465-of-01024.json.gz', 'en/c4-train.00466-of-01024.json.gz', 'en/c4-train.00467-of-01024.json.gz', 'en/c4-train.00468-of-01024.json.gz', 'en/c4-train.00469-of-01024.json.gz']\n",
      "['en/c4-train.00470-of-01024.json.gz', 'en/c4-train.00471-of-01024.json.gz', 'en/c4-train.00472-of-01024.json.gz', 'en/c4-train.00473-of-01024.json.gz', 'en/c4-train.00474-of-01024.json.gz']\n",
      "['en/c4-train.00475-of-01024.json.gz', 'en/c4-train.00476-of-01024.json.gz', 'en/c4-train.00477-of-01024.json.gz', 'en/c4-train.00478-of-01024.json.gz', 'en/c4-train.00479-of-01024.json.gz']\n",
      "['en/c4-train.00480-of-01024.json.gz', 'en/c4-train.00481-of-01024.json.gz', 'en/c4-train.00482-of-01024.json.gz', 'en/c4-train.00483-of-01024.json.gz', 'en/c4-train.00484-of-01024.json.gz']\n",
      "['en/c4-train.00485-of-01024.json.gz', 'en/c4-train.00486-of-01024.json.gz', 'en/c4-train.00487-of-01024.json.gz', 'en/c4-train.00488-of-01024.json.gz', 'en/c4-train.00489-of-01024.json.gz']\n",
      "['en/c4-train.00490-of-01024.json.gz', 'en/c4-train.00491-of-01024.json.gz', 'en/c4-train.00492-of-01024.json.gz', 'en/c4-train.00493-of-01024.json.gz', 'en/c4-train.00494-of-01024.json.gz']\n",
      "['en/c4-train.00495-of-01024.json.gz', 'en/c4-train.00496-of-01024.json.gz', 'en/c4-train.00497-of-01024.json.gz', 'en/c4-train.00498-of-01024.json.gz', 'en/c4-train.00499-of-01024.json.gz']\n",
      "['en/c4-train.00500-of-01024.json.gz', 'en/c4-train.00501-of-01024.json.gz', 'en/c4-train.00502-of-01024.json.gz', 'en/c4-train.00503-of-01024.json.gz', 'en/c4-train.00504-of-01024.json.gz']\n",
      "['en/c4-train.00505-of-01024.json.gz', 'en/c4-train.00506-of-01024.json.gz', 'en/c4-train.00507-of-01024.json.gz', 'en/c4-train.00508-of-01024.json.gz', 'en/c4-train.00509-of-01024.json.gz']\n",
      "['en/c4-train.00510-of-01024.json.gz', 'en/c4-train.00511-of-01024.json.gz', 'en/c4-train.00512-of-01024.json.gz', 'en/c4-train.00513-of-01024.json.gz', 'en/c4-train.00514-of-01024.json.gz']\n",
      "['en/c4-train.00515-of-01024.json.gz', 'en/c4-train.00516-of-01024.json.gz', 'en/c4-train.00517-of-01024.json.gz', 'en/c4-train.00518-of-01024.json.gz', 'en/c4-train.00519-of-01024.json.gz']\n",
      "['en/c4-train.00520-of-01024.json.gz', 'en/c4-train.00521-of-01024.json.gz', 'en/c4-train.00522-of-01024.json.gz', 'en/c4-train.00523-of-01024.json.gz', 'en/c4-train.00524-of-01024.json.gz']\n",
      "['en/c4-train.00525-of-01024.json.gz', 'en/c4-train.00526-of-01024.json.gz', 'en/c4-train.00527-of-01024.json.gz', 'en/c4-train.00528-of-01024.json.gz', 'en/c4-train.00529-of-01024.json.gz']\n",
      "['en/c4-train.00530-of-01024.json.gz', 'en/c4-train.00531-of-01024.json.gz', 'en/c4-train.00532-of-01024.json.gz', 'en/c4-train.00533-of-01024.json.gz', 'en/c4-train.00534-of-01024.json.gz']\n",
      "['en/c4-train.00535-of-01024.json.gz', 'en/c4-train.00536-of-01024.json.gz', 'en/c4-train.00537-of-01024.json.gz', 'en/c4-train.00538-of-01024.json.gz', 'en/c4-train.00539-of-01024.json.gz']\n",
      "['en/c4-train.00540-of-01024.json.gz', 'en/c4-train.00541-of-01024.json.gz', 'en/c4-train.00542-of-01024.json.gz', 'en/c4-train.00543-of-01024.json.gz', 'en/c4-train.00544-of-01024.json.gz']\n",
      "['en/c4-train.00545-of-01024.json.gz', 'en/c4-train.00546-of-01024.json.gz', 'en/c4-train.00547-of-01024.json.gz', 'en/c4-train.00548-of-01024.json.gz', 'en/c4-train.00549-of-01024.json.gz']\n",
      "['en/c4-train.00550-of-01024.json.gz', 'en/c4-train.00551-of-01024.json.gz', 'en/c4-train.00552-of-01024.json.gz', 'en/c4-train.00553-of-01024.json.gz', 'en/c4-train.00554-of-01024.json.gz']\n",
      "['en/c4-train.00555-of-01024.json.gz', 'en/c4-train.00556-of-01024.json.gz', 'en/c4-train.00557-of-01024.json.gz', 'en/c4-train.00558-of-01024.json.gz', 'en/c4-train.00559-of-01024.json.gz']\n",
      "['en/c4-train.00560-of-01024.json.gz', 'en/c4-train.00561-of-01024.json.gz', 'en/c4-train.00562-of-01024.json.gz', 'en/c4-train.00563-of-01024.json.gz', 'en/c4-train.00564-of-01024.json.gz']\n",
      "['en/c4-train.00565-of-01024.json.gz', 'en/c4-train.00566-of-01024.json.gz', 'en/c4-train.00567-of-01024.json.gz', 'en/c4-train.00568-of-01024.json.gz', 'en/c4-train.00569-of-01024.json.gz']\n",
      "['en/c4-train.00570-of-01024.json.gz', 'en/c4-train.00571-of-01024.json.gz', 'en/c4-train.00572-of-01024.json.gz', 'en/c4-train.00573-of-01024.json.gz', 'en/c4-train.00574-of-01024.json.gz']\n",
      "['en/c4-train.00575-of-01024.json.gz', 'en/c4-train.00576-of-01024.json.gz', 'en/c4-train.00577-of-01024.json.gz', 'en/c4-train.00578-of-01024.json.gz', 'en/c4-train.00579-of-01024.json.gz']\n",
      "['en/c4-train.00580-of-01024.json.gz', 'en/c4-train.00581-of-01024.json.gz', 'en/c4-train.00582-of-01024.json.gz', 'en/c4-train.00583-of-01024.json.gz', 'en/c4-train.00584-of-01024.json.gz']\n",
      "['en/c4-train.00585-of-01024.json.gz', 'en/c4-train.00586-of-01024.json.gz', 'en/c4-train.00587-of-01024.json.gz', 'en/c4-train.00588-of-01024.json.gz', 'en/c4-train.00589-of-01024.json.gz']\n",
      "['en/c4-train.00590-of-01024.json.gz', 'en/c4-train.00591-of-01024.json.gz', 'en/c4-train.00592-of-01024.json.gz', 'en/c4-train.00593-of-01024.json.gz', 'en/c4-train.00594-of-01024.json.gz']\n",
      "['en/c4-train.00595-of-01024.json.gz', 'en/c4-train.00596-of-01024.json.gz', 'en/c4-train.00597-of-01024.json.gz', 'en/c4-train.00598-of-01024.json.gz', 'en/c4-train.00599-of-01024.json.gz']\n",
      "['en/c4-train.00600-of-01024.json.gz', 'en/c4-train.00601-of-01024.json.gz', 'en/c4-train.00602-of-01024.json.gz', 'en/c4-train.00603-of-01024.json.gz', 'en/c4-train.00604-of-01024.json.gz']\n",
      "['en/c4-train.00605-of-01024.json.gz', 'en/c4-train.00606-of-01024.json.gz', 'en/c4-train.00607-of-01024.json.gz', 'en/c4-train.00608-of-01024.json.gz', 'en/c4-train.00609-of-01024.json.gz']\n",
      "['en/c4-train.00610-of-01024.json.gz', 'en/c4-train.00611-of-01024.json.gz', 'en/c4-train.00612-of-01024.json.gz', 'en/c4-train.00613-of-01024.json.gz', 'en/c4-train.00614-of-01024.json.gz']\n",
      "['en/c4-train.00615-of-01024.json.gz', 'en/c4-train.00616-of-01024.json.gz', 'en/c4-train.00617-of-01024.json.gz', 'en/c4-train.00618-of-01024.json.gz', 'en/c4-train.00619-of-01024.json.gz']\n",
      "['en/c4-train.00620-of-01024.json.gz', 'en/c4-train.00621-of-01024.json.gz', 'en/c4-train.00622-of-01024.json.gz', 'en/c4-train.00623-of-01024.json.gz', 'en/c4-train.00624-of-01024.json.gz']\n",
      "['en/c4-train.00625-of-01024.json.gz', 'en/c4-train.00626-of-01024.json.gz', 'en/c4-train.00627-of-01024.json.gz', 'en/c4-train.00628-of-01024.json.gz', 'en/c4-train.00629-of-01024.json.gz']\n",
      "['en/c4-train.00630-of-01024.json.gz', 'en/c4-train.00631-of-01024.json.gz', 'en/c4-train.00632-of-01024.json.gz', 'en/c4-train.00633-of-01024.json.gz', 'en/c4-train.00634-of-01024.json.gz']\n",
      "['en/c4-train.00635-of-01024.json.gz', 'en/c4-train.00636-of-01024.json.gz', 'en/c4-train.00637-of-01024.json.gz', 'en/c4-train.00638-of-01024.json.gz', 'en/c4-train.00639-of-01024.json.gz']\n",
      "['en/c4-train.00640-of-01024.json.gz', 'en/c4-train.00641-of-01024.json.gz', 'en/c4-train.00642-of-01024.json.gz', 'en/c4-train.00643-of-01024.json.gz', 'en/c4-train.00644-of-01024.json.gz']\n",
      "['en/c4-train.00645-of-01024.json.gz', 'en/c4-train.00646-of-01024.json.gz', 'en/c4-train.00647-of-01024.json.gz', 'en/c4-train.00648-of-01024.json.gz', 'en/c4-train.00649-of-01024.json.gz']\n",
      "['en/c4-train.00650-of-01024.json.gz', 'en/c4-train.00651-of-01024.json.gz', 'en/c4-train.00652-of-01024.json.gz', 'en/c4-train.00653-of-01024.json.gz', 'en/c4-train.00654-of-01024.json.gz']\n",
      "['en/c4-train.00655-of-01024.json.gz', 'en/c4-train.00656-of-01024.json.gz', 'en/c4-train.00657-of-01024.json.gz', 'en/c4-train.00658-of-01024.json.gz', 'en/c4-train.00659-of-01024.json.gz']\n",
      "['en/c4-train.00660-of-01024.json.gz', 'en/c4-train.00661-of-01024.json.gz', 'en/c4-train.00662-of-01024.json.gz', 'en/c4-train.00663-of-01024.json.gz', 'en/c4-train.00664-of-01024.json.gz']\n",
      "['en/c4-train.00665-of-01024.json.gz', 'en/c4-train.00666-of-01024.json.gz', 'en/c4-train.00667-of-01024.json.gz', 'en/c4-train.00668-of-01024.json.gz', 'en/c4-train.00669-of-01024.json.gz']\n",
      "['en/c4-train.00670-of-01024.json.gz', 'en/c4-train.00671-of-01024.json.gz', 'en/c4-train.00672-of-01024.json.gz', 'en/c4-train.00673-of-01024.json.gz', 'en/c4-train.00674-of-01024.json.gz']\n",
      "['en/c4-train.00675-of-01024.json.gz', 'en/c4-train.00676-of-01024.json.gz', 'en/c4-train.00677-of-01024.json.gz', 'en/c4-train.00678-of-01024.json.gz', 'en/c4-train.00679-of-01024.json.gz']\n",
      "['en/c4-train.00680-of-01024.json.gz', 'en/c4-train.00681-of-01024.json.gz', 'en/c4-train.00682-of-01024.json.gz', 'en/c4-train.00683-of-01024.json.gz', 'en/c4-train.00684-of-01024.json.gz']\n",
      "['en/c4-train.00685-of-01024.json.gz', 'en/c4-train.00686-of-01024.json.gz', 'en/c4-train.00687-of-01024.json.gz', 'en/c4-train.00688-of-01024.json.gz', 'en/c4-train.00689-of-01024.json.gz']\n",
      "['en/c4-train.00690-of-01024.json.gz', 'en/c4-train.00691-of-01024.json.gz', 'en/c4-train.00692-of-01024.json.gz', 'en/c4-train.00693-of-01024.json.gz', 'en/c4-train.00694-of-01024.json.gz']\n",
      "['en/c4-train.00695-of-01024.json.gz', 'en/c4-train.00696-of-01024.json.gz', 'en/c4-train.00697-of-01024.json.gz', 'en/c4-train.00698-of-01024.json.gz', 'en/c4-train.00699-of-01024.json.gz']\n",
      "['en/c4-train.00700-of-01024.json.gz', 'en/c4-train.00701-of-01024.json.gz', 'en/c4-train.00702-of-01024.json.gz', 'en/c4-train.00703-of-01024.json.gz', 'en/c4-train.00704-of-01024.json.gz']\n",
      "['en/c4-train.00705-of-01024.json.gz', 'en/c4-train.00706-of-01024.json.gz', 'en/c4-train.00707-of-01024.json.gz', 'en/c4-train.00708-of-01024.json.gz', 'en/c4-train.00709-of-01024.json.gz']\n",
      "['en/c4-train.00710-of-01024.json.gz', 'en/c4-train.00711-of-01024.json.gz', 'en/c4-train.00712-of-01024.json.gz', 'en/c4-train.00713-of-01024.json.gz', 'en/c4-train.00714-of-01024.json.gz']\n",
      "['en/c4-train.00715-of-01024.json.gz', 'en/c4-train.00716-of-01024.json.gz', 'en/c4-train.00717-of-01024.json.gz', 'en/c4-train.00718-of-01024.json.gz', 'en/c4-train.00719-of-01024.json.gz']\n",
      "['en/c4-train.00720-of-01024.json.gz', 'en/c4-train.00721-of-01024.json.gz', 'en/c4-train.00722-of-01024.json.gz', 'en/c4-train.00723-of-01024.json.gz', 'en/c4-train.00724-of-01024.json.gz']\n",
      "['en/c4-train.00725-of-01024.json.gz', 'en/c4-train.00726-of-01024.json.gz', 'en/c4-train.00727-of-01024.json.gz', 'en/c4-train.00728-of-01024.json.gz', 'en/c4-train.00729-of-01024.json.gz']\n",
      "['en/c4-train.00730-of-01024.json.gz', 'en/c4-train.00731-of-01024.json.gz', 'en/c4-train.00732-of-01024.json.gz', 'en/c4-train.00733-of-01024.json.gz', 'en/c4-train.00734-of-01024.json.gz']\n",
      "['en/c4-train.00735-of-01024.json.gz', 'en/c4-train.00736-of-01024.json.gz', 'en/c4-train.00737-of-01024.json.gz', 'en/c4-train.00738-of-01024.json.gz', 'en/c4-train.00739-of-01024.json.gz']\n",
      "['en/c4-train.00740-of-01024.json.gz', 'en/c4-train.00741-of-01024.json.gz', 'en/c4-train.00742-of-01024.json.gz', 'en/c4-train.00743-of-01024.json.gz', 'en/c4-train.00744-of-01024.json.gz']\n",
      "['en/c4-train.00745-of-01024.json.gz', 'en/c4-train.00746-of-01024.json.gz', 'en/c4-train.00747-of-01024.json.gz', 'en/c4-train.00748-of-01024.json.gz', 'en/c4-train.00749-of-01024.json.gz']\n",
      "['en/c4-train.00750-of-01024.json.gz', 'en/c4-train.00751-of-01024.json.gz', 'en/c4-train.00752-of-01024.json.gz', 'en/c4-train.00753-of-01024.json.gz', 'en/c4-train.00754-of-01024.json.gz']\n",
      "['en/c4-train.00755-of-01024.json.gz', 'en/c4-train.00756-of-01024.json.gz', 'en/c4-train.00757-of-01024.json.gz', 'en/c4-train.00758-of-01024.json.gz', 'en/c4-train.00759-of-01024.json.gz']\n",
      "['en/c4-train.00760-of-01024.json.gz', 'en/c4-train.00761-of-01024.json.gz', 'en/c4-train.00762-of-01024.json.gz', 'en/c4-train.00763-of-01024.json.gz', 'en/c4-train.00764-of-01024.json.gz']\n",
      "['en/c4-train.00765-of-01024.json.gz', 'en/c4-train.00766-of-01024.json.gz', 'en/c4-train.00767-of-01024.json.gz', 'en/c4-train.00768-of-01024.json.gz', 'en/c4-train.00769-of-01024.json.gz']\n",
      "['en/c4-train.00770-of-01024.json.gz', 'en/c4-train.00771-of-01024.json.gz', 'en/c4-train.00772-of-01024.json.gz', 'en/c4-train.00773-of-01024.json.gz', 'en/c4-train.00774-of-01024.json.gz']\n",
      "['en/c4-train.00775-of-01024.json.gz', 'en/c4-train.00776-of-01024.json.gz', 'en/c4-train.00777-of-01024.json.gz', 'en/c4-train.00778-of-01024.json.gz', 'en/c4-train.00779-of-01024.json.gz']\n",
      "['en/c4-train.00780-of-01024.json.gz', 'en/c4-train.00781-of-01024.json.gz', 'en/c4-train.00782-of-01024.json.gz', 'en/c4-train.00783-of-01024.json.gz', 'en/c4-train.00784-of-01024.json.gz']\n",
      "['en/c4-train.00785-of-01024.json.gz', 'en/c4-train.00786-of-01024.json.gz', 'en/c4-train.00787-of-01024.json.gz', 'en/c4-train.00788-of-01024.json.gz', 'en/c4-train.00789-of-01024.json.gz']\n",
      "['en/c4-train.00790-of-01024.json.gz', 'en/c4-train.00791-of-01024.json.gz', 'en/c4-train.00792-of-01024.json.gz', 'en/c4-train.00793-of-01024.json.gz', 'en/c4-train.00794-of-01024.json.gz']\n",
      "['en/c4-train.00795-of-01024.json.gz', 'en/c4-train.00796-of-01024.json.gz', 'en/c4-train.00797-of-01024.json.gz', 'en/c4-train.00798-of-01024.json.gz', 'en/c4-train.00799-of-01024.json.gz']\n",
      "['en/c4-train.00800-of-01024.json.gz', 'en/c4-train.00801-of-01024.json.gz', 'en/c4-train.00802-of-01024.json.gz', 'en/c4-train.00803-of-01024.json.gz', 'en/c4-train.00804-of-01024.json.gz']\n",
      "['en/c4-train.00805-of-01024.json.gz', 'en/c4-train.00806-of-01024.json.gz', 'en/c4-train.00807-of-01024.json.gz', 'en/c4-train.00808-of-01024.json.gz', 'en/c4-train.00809-of-01024.json.gz']\n",
      "['en/c4-train.00810-of-01024.json.gz', 'en/c4-train.00811-of-01024.json.gz', 'en/c4-train.00812-of-01024.json.gz', 'en/c4-train.00813-of-01024.json.gz', 'en/c4-train.00814-of-01024.json.gz']\n",
      "['en/c4-train.00815-of-01024.json.gz', 'en/c4-train.00816-of-01024.json.gz', 'en/c4-train.00817-of-01024.json.gz', 'en/c4-train.00818-of-01024.json.gz', 'en/c4-train.00819-of-01024.json.gz']\n",
      "['en/c4-train.00820-of-01024.json.gz', 'en/c4-train.00821-of-01024.json.gz', 'en/c4-train.00822-of-01024.json.gz', 'en/c4-train.00823-of-01024.json.gz', 'en/c4-train.00824-of-01024.json.gz']\n",
      "['en/c4-train.00825-of-01024.json.gz', 'en/c4-train.00826-of-01024.json.gz', 'en/c4-train.00827-of-01024.json.gz', 'en/c4-train.00828-of-01024.json.gz', 'en/c4-train.00829-of-01024.json.gz']\n",
      "['en/c4-train.00830-of-01024.json.gz', 'en/c4-train.00831-of-01024.json.gz', 'en/c4-train.00832-of-01024.json.gz', 'en/c4-train.00833-of-01024.json.gz', 'en/c4-train.00834-of-01024.json.gz']\n",
      "['en/c4-train.00835-of-01024.json.gz', 'en/c4-train.00836-of-01024.json.gz', 'en/c4-train.00837-of-01024.json.gz', 'en/c4-train.00838-of-01024.json.gz', 'en/c4-train.00839-of-01024.json.gz']\n",
      "['en/c4-train.00840-of-01024.json.gz', 'en/c4-train.00841-of-01024.json.gz', 'en/c4-train.00842-of-01024.json.gz', 'en/c4-train.00843-of-01024.json.gz', 'en/c4-train.00844-of-01024.json.gz']\n",
      "['en/c4-train.00845-of-01024.json.gz', 'en/c4-train.00846-of-01024.json.gz', 'en/c4-train.00847-of-01024.json.gz', 'en/c4-train.00848-of-01024.json.gz', 'en/c4-train.00849-of-01024.json.gz']\n",
      "['en/c4-train.00850-of-01024.json.gz', 'en/c4-train.00851-of-01024.json.gz', 'en/c4-train.00852-of-01024.json.gz', 'en/c4-train.00853-of-01024.json.gz', 'en/c4-train.00854-of-01024.json.gz']\n",
      "['en/c4-train.00855-of-01024.json.gz', 'en/c4-train.00856-of-01024.json.gz', 'en/c4-train.00857-of-01024.json.gz', 'en/c4-train.00858-of-01024.json.gz', 'en/c4-train.00859-of-01024.json.gz']\n",
      "['en/c4-train.00860-of-01024.json.gz', 'en/c4-train.00861-of-01024.json.gz', 'en/c4-train.00862-of-01024.json.gz', 'en/c4-train.00863-of-01024.json.gz', 'en/c4-train.00864-of-01024.json.gz']\n",
      "['en/c4-train.00865-of-01024.json.gz', 'en/c4-train.00866-of-01024.json.gz', 'en/c4-train.00867-of-01024.json.gz', 'en/c4-train.00868-of-01024.json.gz', 'en/c4-train.00869-of-01024.json.gz']\n",
      "['en/c4-train.00870-of-01024.json.gz', 'en/c4-train.00871-of-01024.json.gz', 'en/c4-train.00872-of-01024.json.gz', 'en/c4-train.00873-of-01024.json.gz', 'en/c4-train.00874-of-01024.json.gz']\n",
      "['en/c4-train.00875-of-01024.json.gz', 'en/c4-train.00876-of-01024.json.gz', 'en/c4-train.00877-of-01024.json.gz', 'en/c4-train.00878-of-01024.json.gz', 'en/c4-train.00879-of-01024.json.gz']\n",
      "['en/c4-train.00880-of-01024.json.gz', 'en/c4-train.00881-of-01024.json.gz', 'en/c4-train.00882-of-01024.json.gz', 'en/c4-train.00883-of-01024.json.gz', 'en/c4-train.00884-of-01024.json.gz']\n",
      "['en/c4-train.00885-of-01024.json.gz', 'en/c4-train.00886-of-01024.json.gz', 'en/c4-train.00887-of-01024.json.gz', 'en/c4-train.00888-of-01024.json.gz', 'en/c4-train.00889-of-01024.json.gz']\n",
      "['en/c4-train.00890-of-01024.json.gz', 'en/c4-train.00891-of-01024.json.gz', 'en/c4-train.00892-of-01024.json.gz', 'en/c4-train.00893-of-01024.json.gz', 'en/c4-train.00894-of-01024.json.gz']\n",
      "['en/c4-train.00895-of-01024.json.gz', 'en/c4-train.00896-of-01024.json.gz', 'en/c4-train.00897-of-01024.json.gz', 'en/c4-train.00898-of-01024.json.gz', 'en/c4-train.00899-of-01024.json.gz']\n",
      "['en/c4-train.00900-of-01024.json.gz', 'en/c4-train.00901-of-01024.json.gz', 'en/c4-train.00902-of-01024.json.gz', 'en/c4-train.00903-of-01024.json.gz', 'en/c4-train.00904-of-01024.json.gz']\n",
      "['en/c4-train.00905-of-01024.json.gz', 'en/c4-train.00906-of-01024.json.gz', 'en/c4-train.00907-of-01024.json.gz', 'en/c4-train.00908-of-01024.json.gz', 'en/c4-train.00909-of-01024.json.gz']\n",
      "['en/c4-train.00910-of-01024.json.gz', 'en/c4-train.00911-of-01024.json.gz', 'en/c4-train.00912-of-01024.json.gz', 'en/c4-train.00913-of-01024.json.gz', 'en/c4-train.00914-of-01024.json.gz']\n",
      "['en/c4-train.00915-of-01024.json.gz', 'en/c4-train.00916-of-01024.json.gz', 'en/c4-train.00917-of-01024.json.gz', 'en/c4-train.00918-of-01024.json.gz', 'en/c4-train.00919-of-01024.json.gz']\n",
      "['en/c4-train.00920-of-01024.json.gz', 'en/c4-train.00921-of-01024.json.gz', 'en/c4-train.00922-of-01024.json.gz', 'en/c4-train.00923-of-01024.json.gz', 'en/c4-train.00924-of-01024.json.gz']\n",
      "['en/c4-train.00925-of-01024.json.gz', 'en/c4-train.00926-of-01024.json.gz', 'en/c4-train.00927-of-01024.json.gz', 'en/c4-train.00928-of-01024.json.gz', 'en/c4-train.00929-of-01024.json.gz']\n",
      "['en/c4-train.00930-of-01024.json.gz', 'en/c4-train.00931-of-01024.json.gz', 'en/c4-train.00932-of-01024.json.gz', 'en/c4-train.00933-of-01024.json.gz', 'en/c4-train.00934-of-01024.json.gz']\n",
      "['en/c4-train.00935-of-01024.json.gz', 'en/c4-train.00936-of-01024.json.gz', 'en/c4-train.00937-of-01024.json.gz', 'en/c4-train.00938-of-01024.json.gz', 'en/c4-train.00939-of-01024.json.gz']\n",
      "['en/c4-train.00940-of-01024.json.gz', 'en/c4-train.00941-of-01024.json.gz', 'en/c4-train.00942-of-01024.json.gz', 'en/c4-train.00943-of-01024.json.gz', 'en/c4-train.00944-of-01024.json.gz']\n",
      "['en/c4-train.00945-of-01024.json.gz', 'en/c4-train.00946-of-01024.json.gz', 'en/c4-train.00947-of-01024.json.gz', 'en/c4-train.00948-of-01024.json.gz', 'en/c4-train.00949-of-01024.json.gz']\n",
      "['en/c4-train.00950-of-01024.json.gz', 'en/c4-train.00951-of-01024.json.gz', 'en/c4-train.00952-of-01024.json.gz', 'en/c4-train.00953-of-01024.json.gz', 'en/c4-train.00954-of-01024.json.gz']\n",
      "['en/c4-train.00955-of-01024.json.gz', 'en/c4-train.00956-of-01024.json.gz', 'en/c4-train.00957-of-01024.json.gz', 'en/c4-train.00958-of-01024.json.gz', 'en/c4-train.00959-of-01024.json.gz']\n",
      "['en/c4-train.00960-of-01024.json.gz', 'en/c4-train.00961-of-01024.json.gz', 'en/c4-train.00962-of-01024.json.gz', 'en/c4-train.00963-of-01024.json.gz', 'en/c4-train.00964-of-01024.json.gz']\n",
      "['en/c4-train.00965-of-01024.json.gz', 'en/c4-train.00966-of-01024.json.gz', 'en/c4-train.00967-of-01024.json.gz', 'en/c4-train.00968-of-01024.json.gz', 'en/c4-train.00969-of-01024.json.gz']\n",
      "['en/c4-train.00970-of-01024.json.gz', 'en/c4-train.00971-of-01024.json.gz', 'en/c4-train.00972-of-01024.json.gz', 'en/c4-train.00973-of-01024.json.gz', 'en/c4-train.00974-of-01024.json.gz']\n",
      "['en/c4-train.00975-of-01024.json.gz', 'en/c4-train.00976-of-01024.json.gz', 'en/c4-train.00977-of-01024.json.gz', 'en/c4-train.00978-of-01024.json.gz', 'en/c4-train.00979-of-01024.json.gz']\n",
      "['en/c4-train.00980-of-01024.json.gz', 'en/c4-train.00981-of-01024.json.gz', 'en/c4-train.00982-of-01024.json.gz', 'en/c4-train.00983-of-01024.json.gz', 'en/c4-train.00984-of-01024.json.gz']\n",
      "['en/c4-train.00985-of-01024.json.gz', 'en/c4-train.00986-of-01024.json.gz', 'en/c4-train.00987-of-01024.json.gz', 'en/c4-train.00988-of-01024.json.gz', 'en/c4-train.00989-of-01024.json.gz']\n",
      "['en/c4-train.00990-of-01024.json.gz', 'en/c4-train.00991-of-01024.json.gz', 'en/c4-train.00992-of-01024.json.gz', 'en/c4-train.00993-of-01024.json.gz', 'en/c4-train.00994-of-01024.json.gz']\n",
      "['en/c4-train.00995-of-01024.json.gz', 'en/c4-train.00996-of-01024.json.gz', 'en/c4-train.00997-of-01024.json.gz', 'en/c4-train.00998-of-01024.json.gz', 'en/c4-train.00999-of-01024.json.gz']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(worker_batches)):\n",
    "    print(worker_batches[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Falcon model using FSDP and SMDDP on Amazon SageMaker\n",
    "\n",
    "We will begin by uploading the tokenized data to S3 which will be uploaded to the training cluster during training.\n",
    "\n",
    "After we process the datasets we are going to use the new [FileSystem integration](https://huggingface.co/docs/datasets/filesystems) to upload our dataset to S3. We are using the `sagemaker_session.default_bucket()`, adjust this if you want to store the dataset in a different S3 bucket. We will use the S3 path later in our training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_fsx = True\n",
    "\n",
    "if use_fsx:\n",
    "    from sagemaker.inputs import FileSystemInput\n",
    "\n",
    "    file_system_directory_path = \"/56uy3bev/c4\"\n",
    "    file_system_access_mode = \"rw\"\n",
    "    file_system_type = \"FSxLustre\"\n",
    "    train_fs = FileSystemInput(\n",
    "        file_system_id='fs-0335d20f0f69afd9b',\n",
    "        file_system_type=file_system_type,\n",
    "        directory_path=file_system_directory_path,\n",
    "        file_system_access_mode=file_system_access_mode,\n",
    "    )\n",
    "    data_channels = {\"train\": train_fs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface-dataset-workertest-0-00-25-54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-dataset-workertest-0-00-25-54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-19 00:25:54 Starting - Starting the training job...\n",
      "2024-04-19 00:26:11 Starting - Preparing the instances for training...\n",
      "2024-04-19 00:26:46 Downloading - Downloading input data........\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-04-19 00:27:56,749 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-04-19 00:27:56,750 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-19 00:27:56,750 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-19 00:27:56,759 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-04-19 00:27:56,760 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-04-19 00:27:58,047 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.33.0 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.33.0-py3-none-any.whl.metadata (119 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.9/119.9 kB 5.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting datasets (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: accelerate>=0.21 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.22.0)\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting einops (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0->-r requirements.txt (line 1)) (3.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0->-r requirements.txt (line 1)) (0.19.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0->-r requirements.txt (line 1)) (1.26.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0->-r requirements.txt (line 1)) (23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0->-r requirements.txt (line 1)) (6.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0->-r requirements.txt (line 1)) (2023.10.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0->-r requirements.txt (line 1)) (2.31.0)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.33.0->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0->-r requirements.txt (line 1)) (0.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0->-r requirements.txt (line 1)) (4.64.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (14.0.1)\u001b[0m\n",
      "\u001b[34mCollecting pyarrow-hotfix (from datasets->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (0.3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (2.1.3)\u001b[0m\n",
      "\u001b[34mCollecting xxhash (from datasets->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (0.70.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets->-r requirements.txt (line 2)) (2023.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (3.9.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21->-r requirements.txt (line 3)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21->-r requirements.txt (line 3)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (23.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (6.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.9.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (4.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.0->-r requirements.txt (line 1)) (4.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0->-r requirements.txt (line 1)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0->-r requirements.txt (line 1)) (1.26.18)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0->-r requirements.txt (line 1)) (2023.11.17)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21->-r requirements.txt (line 3)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21->-r requirements.txt (line 3)) (3.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21->-r requirements.txt (line 3)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2023.3.post1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate>=0.21->-r requirements.txt (line 3)) (2.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate>=0.21->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.33.0-py3-none-any.whl (7.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.6/7.6 MB 92.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 510.5/510.5 kB 50.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.8/119.8 MB 24.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading einops-0.7.0-py3-none-any.whl (44 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.6/44.6 kB 7.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 120.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.1/194.1 kB 26.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tokenizers, xxhash, pyarrow-hotfix, einops, transformers, bitsandbytes, datasets\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.15.0\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.15.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.15.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.35.2\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.35.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.35.2\u001b[0m\n",
      "\u001b[34mSuccessfully installed bitsandbytes-0.43.1 datasets-2.18.0 einops-0.7.0 pyarrow-hotfix-0.6 tokenizers-0.13.3 transformers-4.33.0 xxhash-3.4.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.3.1 -> 24.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-04-19 00:28:10,147 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-04-19 00:28:10,147 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-04-19 00:28:10,149 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-19 00:28:10,149 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-19 00:28:10,159 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-19 00:28:10,160 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-19 00:28:10,169 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-19 00:28:10,170 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-19 00:28:10,179 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.c5.18xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"job_name\": \"huggingface-dataset-workertest-0-00-25-54\",\n",
      "        \"model_id\": \"tiiuae/falcon-7b\",\n",
      "        \"num_proc\": 72,\n",
      "        \"split_range\": \"en/c4-train.00000-of-01024.json.gz,en/c4-train.00001-of-01024.json.gz,en/c4-train.00002-of-01024.json.gz,en/c4-train.00003-of-01024.json.gz,en/c4-train.00004-of-01024.json.gz\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.c5.18xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"huggingface-dataset-workertest-0-00-25-54\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-demo-c4/huggingface-dataset-workertest-0-00-25-54/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"data\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 72,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.18xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.18xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"data.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"job_name\":\"huggingface-dataset-workertest-0-00-25-54\",\"model_id\":\"tiiuae/falcon-7b\",\"num_proc\":72,\"split_range\":\"en/c4-train.00000-of-01024.json.gz,en/c4-train.00001-of-01024.json.gz,en/c4-train.00002-of-01024.json.gz,en/c4-train.00003-of-01024.json.gz,en/c4-train.00004-of-01024.json.gz\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=data.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.18xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.18xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.c5.18xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.18xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=data\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=72\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-demo-c4/huggingface-dataset-workertest-0-00-25-54/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.c5.18xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"job_name\":\"huggingface-dataset-workertest-0-00-25-54\",\"model_id\":\"tiiuae/falcon-7b\",\"num_proc\":72,\"split_range\":\"en/c4-train.00000-of-01024.json.gz,en/c4-train.00001-of-01024.json.gz,en/c4-train.00002-of-01024.json.gz,en/c4-train.00003-of-01024.json.gz,en/c4-train.00004-of-01024.json.gz\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.18xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"huggingface-dataset-workertest-0-00-25-54\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-demo-c4/huggingface-dataset-workertest-0-00-25-54/source/sourcedir.tar.gz\",\"module_name\":\"data\",\"network_interface_name\":\"eth0\",\"num_cpus\":72,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.18xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.18xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"data.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--job_name\",\"huggingface-dataset-workertest-0-00-25-54\",\"--model_id\",\"tiiuae/falcon-7b\",\"--num_proc\",\"72\",\"--split_range\",\"en/c4-train.00000-of-01024.json.gz,en/c4-train.00001-of-01024.json.gz,en/c4-train.00002-of-01024.json.gz,en/c4-train.00003-of-01024.json.gz,en/c4-train.00004-of-01024.json.gz\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_JOB_NAME=huggingface-dataset-workertest-0-00-25-54\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=tiiuae/falcon-7b\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_PROC=72\u001b[0m\n",
      "\u001b[34mSM_HP_SPLIT_RANGE=en/c4-train.00000-of-01024.json.gz,en/c4-train.00001-of-01024.json.gz,en/c4-train.00002-of-01024.json.gz,en/c4-train.00003-of-01024.json.gz,en/c4-train.00004-of-01024.json.gz\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 data.py --job_name huggingface-dataset-workertest-0-00-25-54 --model_id tiiuae/falcon-7b --num_proc 72 --split_range en/c4-train.00000-of-01024.json.gz,en/c4-train.00001-of-01024.json.gz,en/c4-train.00002-of-01024.json.gz,en/c4-train.00003-of-01024.json.gz,en/c4-train.00004-of-01024.json.gz\u001b[0m\n",
      "\u001b[34m2024-04-19 00:28:10,203 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mlist of files being processed:['en/c4-train.00000-of-01024.json.gz', 'en/c4-train.00001-of-01024.json.gz', 'en/c4-train.00002-of-01024.json.gz', 'en/c4-train.00003-of-01024.json.gz', 'en/c4-train.00004-of-01024.json.gz']\u001b[0m\n",
      "\u001b[34mDownloading readme:   0%|          | 0.00/41.1k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading readme: 100%|██████████| 41.1k/41.1k [00:00<00:00, 10.0MB/s]\u001b[0m\n",
      "\n",
      "2024-04-19 00:27:56 Training - Training image download completed. Training in progress.\u001b[34mDownloading data:   0%|          | 0.00/319M [00:00<?, ?B/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/320M [00:00<?, ?B/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   1%|▏         | 4.19M/319M [00:00<00:14, 21.3MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   4%|▍         | 12.6M/319M [00:00<00:07, 43.0MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   1%|▏         | 4.19M/320M [00:00<00:27, 11.4MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   7%|▋         | 21.0M/319M [00:00<00:05, 52.6MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   4%|▍         | 12.6M/320M [00:00<00:10, 29.7MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/319M [00:00<?, ?B/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   9%|▉         | 29.4M/319M [00:00<00:05, 54.1MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   7%|▋         | 21.0M/320M [00:00<00:07, 41.9MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  12%|█▏        | 37.7M/319M [00:00<00:04, 59.0MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  14%|█▍        | 46.1M/319M [00:00<00:04, 58.6MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/318M [00:00<?, ?B/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   9%|▉         | 29.4M/320M [00:00<00:07, 37.4MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   1%|▏         | 4.19M/319M [00:00<00:27, 11.4MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  17%|█▋        | 54.5M/319M [00:00<00:04, 61.8MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  12%|█▏        | 37.7M/320M [00:00<00:06, 44.7MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   4%|▍         | 12.6M/319M [00:00<00:10, 29.0MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  20%|█▉        | 62.9M/319M [00:01<00:04, 63.2MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   1%|▏         | 4.19M/318M [00:00<00:14, 21.7MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   7%|▋         | 21.0M/319M [00:00<00:07, 41.2MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  22%|██▏       | 71.3M/319M [00:01<00:03, 64.4MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   4%|▍         | 12.6M/318M [00:00<00:07, 42.3MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  14%|█▍        | 46.1M/320M [00:01<00:06, 42.3MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   9%|▉         | 29.4M/319M [00:00<00:05, 49.3MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   7%|▋         | 21.0M/318M [00:00<00:05, 51.0MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  17%|█▋        | 54.5M/320M [00:01<00:05, 45.0MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  12%|█▏        | 37.7M/319M [00:00<00:05, 54.7MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   9%|▉         | 29.4M/318M [00:00<00:05, 56.3MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  20%|█▉        | 62.9M/320M [00:01<00:05, 50.3MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  25%|██▌       | 79.7M/319M [00:01<00:05, 43.5MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  14%|█▍        | 46.1M/319M [00:00<00:04, 58.8MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  12%|█▏        | 37.7M/318M [00:00<00:04, 57.3MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  22%|██▏       | 71.3M/320M [00:01<00:04, 54.6MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  28%|██▊       | 88.1M/319M [00:01<00:04, 49.2MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  17%|█▋        | 54.5M/319M [00:01<00:04, 62.6MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  15%|█▍        | 46.1M/318M [00:00<00:04, 60.6MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  30%|███       | 96.5M/319M [00:01<00:04, 53.7MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  20%|█▉        | 62.9M/319M [00:01<00:03, 65.0MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  25%|██▍       | 79.7M/320M [00:01<00:04, 53.4MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  17%|█▋        | 54.5M/318M [00:00<00:04, 62.6MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  33%|███▎      | 105M/319M [00:01<00:03, 57.5MB/s] #033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  22%|██▏       | 71.3M/319M [00:01<00:03, 66.1MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  28%|██▊       | 88.1M/320M [00:01<00:04, 57.1MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  20%|█▉        | 62.9M/318M [00:01<00:03, 64.5MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/319M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  25%|██▌       | 79.7M/319M [00:01<00:03, 67.9MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  36%|███▌      | 113M/319M [00:02<00:03, 60.7MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  30%|███       | 96.5M/320M [00:02<00:03, 59.9MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  22%|██▏       | 71.3M/318M [00:01<00:03, 65.7MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  28%|██▊       | 88.1M/319M [00:01<00:03, 67.4MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   1%|▏         | 4.19M/319M [00:00<00:14, 21.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  33%|███▎      | 105M/320M [00:02<00:03, 58.6MB/s] #033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  25%|██▌       | 79.7M/318M [00:01<00:03, 63.6MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  30%|███       | 96.5M/319M [00:01<00:03, 68.0MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   4%|▍         | 12.6M/319M [00:00<00:07, 42.9MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  38%|███▊      | 122M/319M [00:02<00:04, 42.4MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  33%|███▎      | 105M/319M [00:01<00:03, 67.8MB/s] #033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  28%|██▊       | 88.1M/318M [00:01<00:03, 60.6MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   7%|▋         | 21.0M/319M [00:00<00:05, 51.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  41%|████      | 130M/319M [00:02<00:03, 48.3MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  36%|███▌      | 113M/319M [00:01<00:03, 67.8MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  30%|███       | 96.5M/318M [00:01<00:03, 61.7MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  35%|███▌      | 113M/320M [00:02<00:04, 41.5MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   9%|▉         | 29.4M/319M [00:00<00:05, 57.0MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  33%|███▎      | 105M/318M [00:01<00:03, 63.1MB/s] #033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  38%|███▊      | 122M/320M [00:02<00:04, 46.9MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  12%|█▏        | 37.7M/319M [00:00<00:04, 60.4MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  38%|███▊      | 122M/319M [00:02<00:03, 56.6MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  43%|████▎     | 138M/319M [00:02<00:04, 41.8MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  36%|███▌      | 113M/318M [00:01<00:03, 64.2MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  41%|████      | 130M/320M [00:02<00:03, 51.9MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  41%|████      | 130M/319M [00:02<00:03, 59.5MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  46%|████▌     | 147M/319M [00:02<00:03, 47.8MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  14%|█▍        | 46.1M/319M [00:00<00:04, 57.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  38%|███▊      | 122M/318M [00:02<00:03, 64.1MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  43%|████▎     | 138M/320M [00:02<00:03, 55.5MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  43%|████▎     | 138M/319M [00:02<00:02, 62.5MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  41%|████      | 130M/318M [00:02<00:02, 64.9MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  17%|█▋        | 54.5M/319M [00:01<00:05, 51.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  49%|████▊     | 155M/319M [00:03<00:03, 45.8MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  46%|████▌     | 147M/320M [00:03<00:03, 57.4MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  46%|████▌     | 147M/319M [00:02<00:02, 64.9MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  44%|████▎     | 138M/318M [00:02<00:02, 66.3MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  20%|█▉        | 62.9M/319M [00:01<00:04, 56.0MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  51%|█████▏    | 164M/319M [00:03<00:03, 50.6MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  49%|████▊     | 155M/319M [00:02<00:02, 65.3MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  49%|████▊     | 155M/320M [00:03<00:03, 51.6MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  46%|████▌     | 147M/318M [00:02<00:02, 66.4MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  54%|█████▍    | 172M/319M [00:03<00:02, 54.6MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  51%|█████▏    | 164M/319M [00:02<00:02, 66.6MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  49%|████▉     | 155M/318M [00:02<00:02, 66.0MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  57%|█████▋    | 180M/319M [00:03<00:02, 58.7MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  22%|██▏       | 71.3M/319M [00:01<00:05, 43.2MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  54%|█████▍    | 172M/319M [00:02<00:02, 62.9MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  51%|█████     | 164M/320M [00:03<00:03, 42.4MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  51%|█████▏    | 164M/318M [00:02<00:02, 66.2MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  59%|█████▉    | 189M/319M [00:03<00:02, 60.0MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  25%|██▍       | 79.7M/319M [00:01<00:04, 48.9MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  57%|█████▋    | 180M/319M [00:03<00:02, 63.8MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  54%|█████▍    | 172M/318M [00:02<00:02, 65.5MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  54%|█████▍    | 172M/320M [00:03<00:03, 46.7MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  62%|██████▏   | 197M/319M [00:03<00:01, 60.9MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  28%|██▊       | 88.1M/319M [00:01<00:04, 53.3MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  59%|█████▉    | 189M/319M [00:03<00:02, 64.7MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  56%|█████▋    | 180M/320M [00:03<00:02, 50.7MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  57%|█████▋    | 180M/318M [00:02<00:02, 63.6MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  30%|███       | 96.5M/319M [00:01<00:03, 55.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  62%|██████▏   | 197M/319M [00:03<00:01, 65.7MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  65%|██████▍   | 206M/319M [00:03<00:02, 53.3MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  59%|█████▉    | 189M/320M [00:03<00:02, 54.2MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  59%|█████▉    | 189M/318M [00:03<00:02, 63.8MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  33%|███▎      | 105M/319M [00:01<00:03, 58.8MB/s] #033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  65%|██████▍   | 206M/319M [00:03<00:01, 65.8MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  67%|██████▋   | 214M/319M [00:04<00:02, 52.2MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  62%|██████▏   | 197M/320M [00:04<00:02, 57.1MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  62%|██████▏   | 197M/318M [00:03<00:01, 64.0MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  35%|███▌      | 113M/319M [00:02<00:03, 61.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  67%|██████▋   | 214M/319M [00:03<00:01, 66.3MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  70%|██████▉   | 222M/319M [00:04<00:01, 55.7MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  64%|██████▍   | 206M/320M [00:04<00:01, 59.7MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  65%|██████▍   | 206M/318M [00:03<00:01, 63.5MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  70%|██████▉   | 222M/319M [00:03<00:01, 62.7MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  72%|███████▏  | 231M/319M [00:04<00:01, 59.5MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  67%|██████▋   | 214M/320M [00:04<00:01, 60.6MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  67%|██████▋   | 214M/318M [00:03<00:01, 64.5MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  38%|███▊      | 122M/319M [00:02<00:04, 48.0MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  72%|███████▏  | 231M/319M [00:03<00:01, 63.6MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  75%|███████▌  | 239M/319M [00:04<00:01, 61.8MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  41%|████      | 130M/319M [00:02<00:03, 52.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  75%|███████▌  | 239M/319M [00:03<00:01, 65.2MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  70%|██████▉   | 222M/318M [00:03<00:01, 57.9MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  78%|███████▊  | 247M/319M [00:04<00:01, 61.0MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  43%|████▎     | 138M/319M [00:02<00:03, 56.3MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  78%|███████▊  | 247M/319M [00:04<00:01, 67.2MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  70%|██████▉   | 222M/320M [00:04<00:02, 45.1MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  73%|███████▎  | 231M/318M [00:03<00:01, 57.9MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  80%|████████  | 256M/319M [00:04<00:01, 62.3MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  46%|████▌     | 147M/319M [00:02<00:02, 58.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  80%|████████  | 256M/319M [00:04<00:00, 66.2MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  72%|███████▏  | 231M/320M [00:04<00:01, 49.5MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  75%|███████▌  | 239M/318M [00:03<00:01, 60.5MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  83%|████████▎ | 264M/319M [00:04<00:00, 64.6MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  49%|████▊     | 155M/319M [00:02<00:02, 61.0MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  83%|████████▎ | 264M/319M [00:04<00:00, 67.3MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  75%|███████▍  | 239M/320M [00:04<00:01, 54.4MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  78%|███████▊  | 247M/318M [00:04<00:01, 61.9MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  86%|████████▌ | 273M/319M [00:04<00:00, 65.2MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  77%|███████▋  | 247M/320M [00:04<00:01, 57.6MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  51%|█████     | 164M/319M [00:03<00:02, 59.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  86%|████████▌ | 273M/319M [00:04<00:00, 62.9MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  80%|████████  | 256M/318M [00:04<00:00, 63.7MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  88%|████████▊ | 281M/319M [00:05<00:00, 62.2MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  80%|████████  | 256M/320M [00:05<00:01, 60.4MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  54%|█████▍    | 172M/319M [00:03<00:02, 60.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  83%|████████▎ | 264M/318M [00:04<00:00, 65.1MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  88%|████████▊ | 281M/319M [00:04<00:00, 55.7MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  83%|████████▎ | 264M/320M [00:05<00:00, 62.9MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  86%|████████▌ | 273M/318M [00:04<00:00, 63.7MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  91%|█████████ | 289M/319M [00:05<00:00, 51.3MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  91%|█████████ | 289M/319M [00:04<00:00, 58.9MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  85%|████████▌ | 273M/320M [00:05<00:00, 64.3MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  88%|████████▊ | 281M/318M [00:04<00:00, 64.3MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  93%|█████████▎| 298M/319M [00:04<00:00, 62.5MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  93%|█████████▎| 298M/319M [00:05<00:00, 54.0MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  56%|█████▋    | 180M/319M [00:03<00:03, 41.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  88%|████████▊ | 281M/320M [00:05<00:00, 65.4MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  91%|█████████ | 289M/318M [00:04<00:00, 64.0MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  96%|█████████▌| 306M/319M [00:05<00:00, 57.7MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  59%|█████▉    | 189M/319M [00:03<00:02, 47.4MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  91%|█████████ | 289M/320M [00:05<00:00, 65.6MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  94%|█████████▎| 298M/318M [00:04<00:00, 63.7MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  99%|█████████▊| 315M/319M [00:05<00:00, 60.7MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 319M/319M [00:05<00:00, 55.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:  96%|█████████▌| 306M/319M [00:05<00:00, 49.0MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  62%|██████▏   | 197M/319M [00:03<00:02, 52.7MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  93%|█████████▎| 298M/320M [00:05<00:00, 66.6MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  96%|█████████▋| 306M/318M [00:04<00:00, 63.8MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  99%|█████████▊| 315M/319M [00:05<00:00, 53.5MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 319M/319M [00:05<00:00, 60.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:  64%|██████▍   | 206M/319M [00:03<00:02, 55.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  96%|█████████▌| 306M/320M [00:05<00:00, 65.4MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  99%|█████████▉| 315M/318M [00:05<00:00, 66.0MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 318M/318M [00:05<00:00, 63.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:  98%|█████████▊| 315M/320M [00:05<00:00, 65.8MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 320M/320M [00:05<00:00, 53.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:  67%|██████▋   | 214M/319M [00:04<00:01, 54.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  70%|██████▉   | 222M/319M [00:04<00:01, 57.2MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  72%|███████▏  | 231M/319M [00:04<00:01, 59.0MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  75%|███████▍  | 239M/319M [00:04<00:01, 60.9MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  77%|███████▋  | 247M/319M [00:04<00:01, 62.0MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  80%|████████  | 256M/319M [00:04<00:00, 63.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  83%|████████▎ | 264M/319M [00:04<00:00, 63.9MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  85%|████████▌ | 273M/319M [00:04<00:00, 64.9MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  88%|████████▊ | 281M/319M [00:05<00:00, 64.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  91%|█████████ | 289M/319M [00:05<00:00, 65.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  93%|█████████▎| 298M/319M [00:05<00:00, 65.3MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  96%|█████████▌| 306M/319M [00:05<00:00, 63.7MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  99%|█████████▊| 315M/319M [00:05<00:00, 63.7MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 319M/319M [00:05<00:00, 57.2MB/s]\u001b[0m\n",
      "\u001b[34mSetting num_proc from 72 to 5 for the train split as it only contains 5 shards.\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 9178 examples [00:00, 74730.06 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 101020 examples [00:00, 495540.95 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 223940 examples [00:00, 787405.48 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 360792 examples [00:00, 958161.66 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 496646 examples [00:00, 1065958.75 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 634065 examples [00:00, 1119882.06 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 747884 examples [00:00, 1104329.20 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 865879 examples [00:00, 1109151.90 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1003688 examples [00:01, 1106119.25 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1139617 examples [00:01, 1138030.51 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1261503 examples [00:01, 1154236.23 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1384695 examples [00:01, 1168041.46 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1521450 examples [00:01, 1177740.38 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1658846 examples [00:01, 1215821.18 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1781586 examples [00:01, 1075178.18 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1781586 examples [00:01, 1018159.84 examples/s]\u001b[0m\n",
      "\u001b[34mdataset printing:DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'timestamp', 'url'],\n",
      "        num_rows: 1781586\n",
      "    })\u001b[0m\n",
      "\u001b[34m})\u001b[0m\n",
      "\u001b[34mcolumn names: ['text', 'timestamp', 'url']\u001b[0m\n",
      "\u001b[34mtext cloumn name identified: text\u001b[0m\n",
      "\u001b[34msample train rown:{'text': 'Beginners BBQ Class Taking Place in Missoula!\\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\\nHe will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\\nThe cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.', 'timestamp': datetime.datetime(2019, 4, 25, 12, 57, 54), 'url': 'https://klyq.com/beginners-bbq-class-taking-place-in-missoula/'}\u001b[0m\n",
      "\u001b[34mtokenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json: 100%|██████████| 287/287 [00:00<00:00, 2.51MB/s]\u001b[0m\n",
      "\u001b[34mtokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer.json: 100%|██████████| 2.73M/2.73M [00:00<00:00, 30.1MB/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json: 100%|██████████| 281/281 [00:00<00:00, 1.97MB/s]\u001b[0m\n",
      "\u001b[34mcloumn names: ['text', 'timestamp', 'url']\u001b[0m\n",
      "\u001b[34msample train row again:{'text': 'Beginners BBQ Class Taking Place in Missoula!\\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\\nHe will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\\nThe cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.', 'timestamp': datetime.datetime(2019, 4, 25, 12, 57, 54), 'url': 'https://klyq.com/beginners-bbq-class-taking-place-in-missoula/'}\u001b[0m\n",
      "\u001b[34mparallel_proc:72\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   0%|          | 0/1781586 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2523 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2214 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2537 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   0%|          | 1000/1781586 [00:01<56:18, 527.00 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2541 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (6375 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4174 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4463 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (5300 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4545 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2827 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2400 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   0%|          | 4000/1781586 [00:02<13:20, 2219.86 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3379 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3523 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   0%|          | 6000/1781586 [00:02<08:23, 3529.56 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4893 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4283 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2245 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2730 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   1%|          | 10000/1781586 [00:02<04:16, 6899.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   1%|          | 15000/1781586 [00:02<02:32, 11595.50 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (10940 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2904 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2609 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2922 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   1%|          | 18000/1781586 [00:02<02:33, 11500.27 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (6276 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2432 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (5359 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   1%|          | 21000/1781586 [00:03<02:22, 12355.79 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4284 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   1%|▏         | 23000/1781586 [00:03<02:17, 12828.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   1%|▏         | 25000/1781586 [00:03<02:27, 11932.10 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2439 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (5058 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (9424 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   2%|▏         | 27000/1781586 [00:03<03:08, 9311.92 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2734 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (10657 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2957 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (7931 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   2%|▏         | 29000/1781586 [00:04<03:22, 8666.81 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2162 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (7378 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2939 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2150 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   2%|▏         | 32000/1781586 [00:04<02:50, 10283.84 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   2%|▏         | 36000/1781586 [00:04<02:06, 13778.82 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3447 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2054 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3286 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2656 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2062 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   2%|▏         | 38000/1781586 [00:04<02:28, 11757.83 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2514 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4413 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   2%|▏         | 40000/1781586 [00:04<02:16, 12773.92 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3501 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   2%|▏         | 44000/1781586 [00:04<01:43, 16847.81 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4907 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2206 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2311 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3734 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3082 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (11324 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   3%|▎         | 46000/1781586 [00:05<01:54, 15179.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   3%|▎         | 50000/1781586 [00:05<01:27, 19694.94 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2972 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2070 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2124 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2301 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (5471 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   3%|▎         | 54000/1781586 [00:05<01:18, 21973.51 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4092 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   3%|▎         | 59000/1781586 [00:05<01:11, 23979.21 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3527 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2536 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   4%|▎         | 65000/1781586 [00:05<01:08, 25160.88 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4684 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3391 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   4%|▍         | 71000/1781586 [00:05<01:02, 27357.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   4%|▍         | 74000/1781586 [00:06<01:04, 26559.02 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3786 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4060 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3430 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   4%|▍         | 79000/1781586 [00:06<00:55, 30750.97 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (5530 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2253 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   5%|▍         | 83000/1781586 [00:06<00:55, 30543.16 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3288 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2117 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   5%|▍         | 87000/1781586 [00:06<00:55, 30684.65 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2164 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (6066 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2098 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   5%|▌         | 91000/1781586 [00:06<01:00, 27929.31 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3244 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   5%|▌         | 94000/1781586 [00:06<01:12, 23177.03 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3236 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   5%|▌         | 97000/1781586 [00:07<01:27, 19324.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   6%|▌         | 100000/1781586 [00:07<01:31, 18468.79 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   6%|▌         | 102000/1781586 [00:07<01:31, 18400.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   6%|▌         | 105000/1781586 [00:07<01:25, 19536.68 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   6%|▌         | 108000/1781586 [00:07<01:47, 15502.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   6%|▌         | 111000/1781586 [00:07<01:34, 17732.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   6%|▋         | 114000/1781586 [00:08<01:51, 14933.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   7%|▋         | 118000/1781586 [00:08<01:33, 17724.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   7%|▋         | 121000/1781586 [00:08<01:28, 18737.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   7%|▋         | 128000/1781586 [00:08<01:00, 27538.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   7%|▋         | 132000/1781586 [00:08<00:56, 29075.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   8%|▊         | 136000/1781586 [00:08<01:04, 25644.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   8%|▊         | 139000/1781586 [00:09<01:20, 20364.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   8%|▊         | 142000/1781586 [00:09<01:19, 20660.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   8%|▊         | 146000/1781586 [00:09<01:07, 24056.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   8%|▊         | 149000/1781586 [00:09<01:06, 24537.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   9%|▊         | 153000/1781586 [00:09<01:01, 26512.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   9%|▉         | 156000/1781586 [00:09<00:59, 27228.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   9%|▉         | 159000/1781586 [00:09<01:04, 24965.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   9%|▉         | 163000/1781586 [00:09<00:59, 27194.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   9%|▉         | 166000/1781586 [00:10<01:16, 21124.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  10%|▉         | 170000/1781586 [00:10<01:13, 21959.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  10%|▉         | 173000/1781586 [00:10<01:12, 22243.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  10%|▉         | 176000/1781586 [00:10<01:18, 20559.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  10%|█         | 180000/1781586 [00:10<01:29, 17882.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  10%|█         | 182000/1781586 [00:11<01:34, 16839.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  10%|█         | 184000/1781586 [00:11<01:45, 15154.73 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  11%|█         | 188000/1781586 [00:11<01:24, 18941.84 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  11%|█         | 194000/1781586 [00:11<01:07, 23483.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  11%|█         | 198000/1781586 [00:11<01:02, 25521.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  12%|█▏        | 205000/1781586 [00:11<00:48, 32292.96 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  12%|█▏        | 209000/1781586 [00:12<00:52, 29762.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  12%|█▏        | 213000/1781586 [00:12<00:59, 26314.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  12%|█▏        | 216000/1781586 [00:12<01:18, 19977.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  12%|█▏        | 219000/1781586 [00:12<01:17, 20168.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  12%|█▏        | 222000/1781586 [00:12<01:26, 18129.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  13%|█▎        | 225000/1781586 [00:13<01:36, 16201.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  13%|█▎        | 229000/1781586 [00:13<01:27, 17789.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  13%|█▎        | 233000/1781586 [00:13<01:33, 16490.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  13%|█▎        | 237000/1781586 [00:13<01:18, 19650.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  14%|█▎        | 243000/1781586 [00:13<01:02, 24502.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  14%|█▍        | 249000/1781586 [00:13<00:52, 29272.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  14%|█▍        | 253000/1781586 [00:14<01:10, 21820.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  14%|█▍        | 256000/1781586 [00:14<01:16, 19950.89 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  15%|█▍        | 261000/1781586 [00:14<01:02, 24391.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  15%|█▍        | 264000/1781586 [00:14<01:03, 23776.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  15%|█▍        | 267000/1781586 [00:14<01:02, 24062.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  15%|█▌        | 272000/1781586 [00:15<01:01, 24564.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  16%|█▌        | 277000/1781586 [00:15<01:10, 21194.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  16%|█▌        | 284000/1781586 [00:15<00:51, 29115.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  16%|█▌        | 288000/1781586 [00:15<00:52, 28556.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  16%|█▋        | 292000/1781586 [00:15<01:09, 21468.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  17%|█▋        | 295000/1781586 [00:16<01:14, 19974.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  17%|█▋        | 298000/1781586 [00:16<01:14, 19995.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  17%|█▋        | 301000/1781586 [00:16<01:40, 14680.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  17%|█▋        | 305000/1781586 [00:16<01:22, 17976.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  17%|█▋        | 308000/1781586 [00:16<01:18, 18670.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  17%|█▋        | 311000/1781586 [00:17<01:20, 18289.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  18%|█▊        | 314000/1781586 [00:17<01:19, 18362.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  18%|█▊        | 317000/1781586 [00:17<01:19, 18508.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  18%|█▊        | 320000/1781586 [00:17<01:15, 19398.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  18%|█▊        | 325000/1781586 [00:17<01:06, 21796.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  18%|█▊        | 328000/1781586 [00:17<01:02, 23377.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  19%|█▊        | 331000/1781586 [00:17<00:58, 24788.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  19%|█▉        | 335000/1781586 [00:18<00:53, 26943.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  19%|█▉        | 338000/1781586 [00:18<00:52, 27613.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  19%|█▉        | 342000/1781586 [00:18<00:48, 29410.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  19%|█▉        | 346000/1781586 [00:18<00:50, 28589.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  20%|█▉        | 349000/1781586 [00:18<00:49, 28801.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  20%|█▉        | 355000/1781586 [00:18<00:39, 35770.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  20%|██        | 359000/1781586 [00:18<00:54, 25928.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  20%|██        | 363000/1781586 [00:19<01:05, 21663.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  21%|██        | 366000/1781586 [00:19<01:16, 18519.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  21%|██        | 369000/1781586 [00:19<01:25, 16510.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  21%|██        | 371000/1781586 [00:19<01:23, 16842.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  21%|██        | 373000/1781586 [00:19<01:37, 14507.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  21%|██        | 375000/1781586 [00:20<01:42, 13787.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  21%|██        | 377000/1781586 [00:20<01:33, 14958.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  21%|██▏       | 379000/1781586 [00:20<01:31, 15374.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  22%|██▏       | 384000/1781586 [00:20<01:02, 22275.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  22%|██▏       | 389000/1781586 [00:20<00:53, 25990.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  22%|██▏       | 392000/1781586 [00:20<00:55, 25021.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  22%|██▏       | 395000/1781586 [00:20<01:04, 21555.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  22%|██▏       | 398000/1781586 [00:21<01:21, 17017.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  22%|██▏       | 400000/1781586 [00:21<01:28, 15639.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  23%|██▎       | 406000/1781586 [00:21<00:58, 23580.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  23%|██▎       | 413000/1781586 [00:21<00:44, 31102.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  23%|██▎       | 418000/1781586 [00:21<00:38, 35022.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  24%|██▍       | 424000/1781586 [00:21<00:33, 40407.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  24%|██▍       | 429000/1781586 [00:22<00:55, 24356.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  24%|██▍       | 433000/1781586 [00:22<00:52, 25529.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  25%|██▍       | 437000/1781586 [00:22<01:02, 21496.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  25%|██▍       | 440000/1781586 [00:22<01:15, 17832.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  25%|██▍       | 443000/1781586 [00:23<01:13, 18212.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  25%|██▌       | 446000/1781586 [00:23<01:25, 15544.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  25%|██▌       | 450000/1781586 [00:23<01:09, 19211.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  25%|██▌       | 453000/1781586 [00:23<01:05, 20141.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  26%|██▌       | 456000/1781586 [00:23<01:01, 21497.68 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  26%|██▌       | 460000/1781586 [00:23<01:09, 19147.21 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  26%|██▌       | 463000/1781586 [00:24<01:04, 20427.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  26%|██▌       | 466000/1781586 [00:24<01:10, 18658.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  26%|██▋       | 469000/1781586 [00:24<01:21, 16149.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  27%|██▋       | 473000/1781586 [00:24<01:05, 19974.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  27%|██▋       | 480000/1781586 [00:24<00:44, 29323.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  27%|██▋       | 484000/1781586 [00:24<00:44, 29166.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  27%|██▋       | 488000/1781586 [00:25<00:48, 26399.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  28%|██▊       | 493000/1781586 [00:25<00:42, 30602.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  28%|██▊       | 497000/1781586 [00:25<00:40, 31487.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  28%|██▊       | 501000/1781586 [00:25<00:50, 25418.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  28%|██▊       | 504000/1781586 [00:25<01:03, 20061.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  28%|██▊       | 507000/1781586 [00:25<01:03, 20027.21 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  29%|██▊       | 510000/1781586 [00:26<01:25, 14796.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  29%|██▉       | 513000/1781586 [00:26<01:19, 15969.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  29%|██▉       | 515000/1781586 [00:26<01:16, 16635.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  29%|██▉       | 521000/1781586 [00:26<00:59, 21059.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  30%|██▉       | 528000/1781586 [00:26<00:47, 26570.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  30%|██▉       | 531000/1781586 [00:27<00:50, 24694.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  30%|██▉       | 534000/1781586 [00:27<00:50, 24661.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  30%|███       | 537000/1781586 [00:27<00:59, 21035.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  30%|███       | 540000/1781586 [00:27<01:20, 15342.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  31%|███       | 544000/1781586 [00:27<01:06, 18490.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  31%|███       | 547000/1781586 [00:28<01:10, 17583.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  31%|███       | 550000/1781586 [00:28<01:04, 19181.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  31%|███       | 555000/1781586 [00:28<00:50, 24109.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  31%|███▏      | 558000/1781586 [00:28<00:58, 20742.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  32%|███▏      | 563000/1781586 [00:28<00:46, 26250.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  32%|███▏      | 567000/1781586 [00:28<00:45, 26713.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  32%|███▏      | 571000/1781586 [00:28<00:47, 25391.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  32%|███▏      | 574000/1781586 [00:28<00:47, 25628.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  32%|███▏      | 577000/1781586 [00:29<00:45, 26206.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  33%|███▎      | 580000/1781586 [00:29<00:57, 20836.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  33%|███▎      | 583000/1781586 [00:29<00:57, 20837.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  33%|███▎      | 586000/1781586 [00:29<01:07, 17608.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  33%|███▎      | 589000/1781586 [00:29<00:59, 19957.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  33%|███▎      | 594000/1781586 [00:29<00:45, 25927.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  34%|███▎      | 597000/1781586 [00:30<01:00, 19690.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  34%|███▎      | 600000/1781586 [00:30<00:59, 19693.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  34%|███▍      | 603000/1781586 [00:30<01:00, 19335.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  34%|███▍      | 606000/1781586 [00:30<00:58, 19998.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  34%|███▍      | 611000/1781586 [00:30<00:57, 20337.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  34%|███▍      | 614000/1781586 [00:30<00:54, 21362.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  35%|███▍      | 617000/1781586 [00:31<00:50, 23062.79 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  35%|███▍      | 620000/1781586 [00:31<00:53, 21910.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  35%|███▍      | 623000/1781586 [00:31<00:51, 22385.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  35%|███▌      | 628000/1781586 [00:31<00:46, 24727.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  35%|███▌      | 631000/1781586 [00:31<00:48, 23679.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  36%|███▌      | 634000/1781586 [00:31<00:53, 21507.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  36%|███▌      | 637000/1781586 [00:31<00:52, 21950.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  36%|███▌      | 640000/1781586 [00:32<00:48, 23660.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  36%|███▌      | 643000/1781586 [00:32<00:56, 20142.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  36%|███▋      | 649000/1781586 [00:32<00:46, 24564.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  37%|███▋      | 652000/1781586 [00:32<00:51, 22053.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  37%|███▋      | 655000/1781586 [00:32<00:51, 21701.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  37%|███▋      | 658000/1781586 [00:32<00:48, 23116.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  37%|███▋      | 661000/1781586 [00:33<00:56, 19969.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  37%|███▋      | 667000/1781586 [00:33<00:40, 27477.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  38%|███▊      | 671000/1781586 [00:33<00:48, 22675.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  38%|███▊      | 674000/1781586 [00:33<00:57, 19295.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  38%|███▊      | 680000/1781586 [00:33<00:44, 24636.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  38%|███▊      | 683000/1781586 [00:33<00:46, 23821.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  39%|███▊      | 686000/1781586 [00:34<01:03, 17241.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  39%|███▊      | 689000/1781586 [00:34<00:59, 18463.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  39%|███▉      | 692000/1781586 [00:34<01:04, 16873.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  39%|███▉      | 696000/1781586 [00:34<00:52, 20660.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  39%|███▉      | 702000/1781586 [00:34<00:41, 26278.68 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  40%|███▉      | 705000/1781586 [00:35<00:47, 22612.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  40%|███▉      | 708000/1781586 [00:35<00:44, 23877.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  40%|███▉      | 712000/1781586 [00:35<00:50, 21076.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  40%|████      | 715000/1781586 [00:35<00:51, 20897.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  40%|████      | 721000/1781586 [00:35<00:38, 27460.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  41%|████      | 725000/1781586 [00:35<00:47, 22132.07 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  41%|████      | 728000/1781586 [00:36<00:48, 21659.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  41%|████      | 731000/1781586 [00:36<00:49, 21286.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  41%|████      | 734000/1781586 [00:36<00:52, 20061.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  41%|████▏     | 737000/1781586 [00:36<00:48, 21378.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  42%|████▏     | 740000/1781586 [00:36<01:02, 16620.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  42%|████▏     | 744000/1781586 [00:36<00:50, 20742.96 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  42%|████▏     | 749000/1781586 [00:37<00:41, 24754.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  42%|████▏     | 755000/1781586 [00:37<00:34, 29427.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  43%|████▎     | 759000/1781586 [00:37<01:00, 16995.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  43%|████▎     | 762000/1781586 [00:37<01:00, 16876.89 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  43%|████▎     | 765000/1781586 [00:38<00:54, 18546.21 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  43%|████▎     | 770000/1781586 [00:38<00:45, 22310.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  44%|████▎     | 775000/1781586 [00:38<00:44, 22844.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  44%|████▎     | 779000/1781586 [00:38<00:39, 25515.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  44%|████▍     | 782000/1781586 [00:38<00:47, 21184.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  44%|████▍     | 786000/1781586 [00:38<00:41, 24189.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  44%|████▍     | 789000/1781586 [00:38<00:44, 22230.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  45%|████▍     | 793000/1781586 [00:39<00:38, 25562.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  45%|████▍     | 796000/1781586 [00:39<00:39, 24883.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  45%|████▍     | 800000/1781586 [00:39<00:43, 22404.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  45%|████▌     | 803000/1781586 [00:39<00:42, 22959.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  45%|████▌     | 806000/1781586 [00:39<00:55, 17705.56 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  45%|████▌     | 810000/1781586 [00:39<00:45, 21161.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  46%|████▌     | 815000/1781586 [00:40<00:38, 24815.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  46%|████▌     | 818000/1781586 [00:40<00:44, 21485.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  46%|████▌     | 821000/1781586 [00:40<00:46, 20512.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  46%|████▋     | 826000/1781586 [00:40<00:48, 19598.75 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  47%|████▋     | 829000/1781586 [00:40<00:51, 18640.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  47%|████▋     | 832000/1781586 [00:41<00:46, 20605.56 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  47%|████▋     | 841000/1781586 [00:41<00:33, 28109.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  47%|████▋     | 844000/1781586 [00:41<00:35, 26124.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  48%|████▊     | 847000/1781586 [00:41<00:40, 23259.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  48%|████▊     | 850000/1781586 [00:41<00:40, 23251.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  48%|████▊     | 854000/1781586 [00:41<00:43, 21136.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  48%|████▊     | 858000/1781586 [00:42<00:37, 24432.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  48%|████▊     | 863000/1781586 [00:42<00:33, 27592.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  49%|████▊     | 866000/1781586 [00:42<00:57, 16004.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  49%|████▉     | 871000/1781586 [00:42<00:56, 16072.56 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  49%|████▉     | 875000/1781586 [00:43<00:47, 19109.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  49%|████▉     | 879000/1781586 [00:43<00:40, 22226.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  50%|████▉     | 885000/1781586 [00:43<00:31, 28817.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  50%|████▉     | 889000/1781586 [00:43<00:44, 19879.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  50%|█████     | 892000/1781586 [00:43<00:48, 18457.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  50%|█████     | 895000/1781586 [00:43<00:45, 19464.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  50%|█████     | 899000/1781586 [00:44<00:38, 22864.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  51%|█████     | 904000/1781586 [00:44<00:35, 25013.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  51%|█████     | 907000/1781586 [00:44<00:34, 25557.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  51%|█████     | 910000/1781586 [00:44<00:45, 19125.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  51%|█████▏    | 916000/1781586 [00:44<00:37, 23124.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  52%|█████▏    | 920000/1781586 [00:44<00:33, 25707.68 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  52%|█████▏    | 923000/1781586 [00:45<00:32, 26291.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  52%|█████▏    | 927000/1781586 [00:45<00:30, 27850.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  52%|█████▏    | 931000/1781586 [00:45<00:33, 25757.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  52%|█████▏    | 934000/1781586 [00:45<00:34, 24701.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  53%|█████▎    | 937000/1781586 [00:45<00:42, 19911.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  53%|█████▎    | 940000/1781586 [00:45<00:47, 17784.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  53%|█████▎    | 942000/1781586 [00:46<00:46, 17935.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  53%|█████▎    | 946000/1781586 [00:46<00:39, 21009.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  53%|█████▎    | 949000/1781586 [00:46<00:41, 20107.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  53%|█████▎    | 952000/1781586 [00:46<00:45, 18402.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  54%|█████▎    | 954000/1781586 [00:46<00:52, 15867.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  54%|█████▍    | 959000/1781586 [00:46<00:37, 21668.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  54%|█████▍    | 962000/1781586 [00:47<00:47, 17405.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  54%|█████▍    | 968000/1781586 [00:47<00:34, 23410.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  55%|█████▍    | 972000/1781586 [00:47<00:38, 20982.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  55%|█████▍    | 976000/1781586 [00:47<00:34, 23451.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  55%|█████▌    | 980000/1781586 [00:47<00:34, 22942.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  55%|█████▌    | 983000/1781586 [00:47<00:37, 21523.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  55%|█████▌    | 986000/1781586 [00:48<00:37, 21144.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  56%|█████▌    | 991000/1781586 [00:48<00:31, 25232.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  56%|█████▌    | 996000/1781586 [00:48<00:26, 30160.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  56%|█████▌    | 1000000/1781586 [00:48<00:26, 29861.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  56%|█████▋    | 1004000/1781586 [00:48<00:27, 28238.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  57%|█████▋    | 1007000/1781586 [00:48<00:31, 24274.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  57%|█████▋    | 1010000/1781586 [00:49<00:39, 19736.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  57%|█████▋    | 1013000/1781586 [00:49<00:39, 19521.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  57%|█████▋    | 1016000/1781586 [00:49<00:42, 18084.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  57%|█████▋    | 1018000/1781586 [00:49<00:55, 13781.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  57%|█████▋    | 1022000/1781586 [00:49<00:43, 17489.73 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  58%|█████▊    | 1025000/1781586 [00:49<00:40, 18655.89 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  58%|█████▊    | 1028000/1781586 [00:50<00:39, 18951.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  58%|█████▊    | 1032000/1781586 [00:50<00:32, 22949.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  58%|█████▊    | 1035000/1781586 [00:50<00:37, 20054.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  58%|█████▊    | 1038000/1781586 [00:50<00:36, 20435.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  58%|█████▊    | 1041000/1781586 [00:50<00:38, 19358.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  59%|█████▊    | 1045000/1781586 [00:50<00:31, 23473.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  59%|█████▉    | 1048000/1781586 [00:51<00:40, 18335.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  59%|█████▉    | 1053000/1781586 [00:51<00:35, 20466.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  59%|█████▉    | 1056000/1781586 [00:51<00:38, 19028.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  60%|█████▉    | 1062000/1781586 [00:51<00:27, 26441.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  60%|██████    | 1070000/1781586 [00:51<00:21, 32903.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  60%|██████    | 1074000/1781586 [00:52<00:28, 25129.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  60%|██████    | 1077000/1781586 [00:52<00:28, 24344.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  61%|██████    | 1082000/1781586 [00:52<00:29, 23471.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  61%|██████    | 1085000/1781586 [00:52<00:35, 19369.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  61%|██████    | 1089000/1781586 [00:52<00:36, 18917.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  61%|██████▏   | 1092000/1781586 [00:53<00:35, 19345.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  61%|██████▏   | 1095000/1781586 [00:53<00:34, 19820.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  62%|██████▏   | 1098000/1781586 [00:53<00:34, 19783.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  62%|██████▏   | 1101000/1781586 [00:53<00:37, 18263.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  62%|██████▏   | 1105000/1781586 [00:53<00:32, 20842.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  62%|██████▏   | 1109000/1781586 [00:53<00:33, 20086.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  62%|██████▏   | 1112000/1781586 [00:54<00:45, 14833.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  63%|██████▎   | 1115000/1781586 [00:54<00:42, 15805.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  63%|██████▎   | 1120000/1781586 [00:54<00:31, 21154.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  63%|██████▎   | 1123000/1781586 [00:54<00:33, 19628.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  63%|██████▎   | 1127000/1781586 [00:54<00:29, 21840.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  64%|██████▍   | 1136000/1781586 [00:54<00:19, 33530.68 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  64%|██████▍   | 1140000/1781586 [00:55<00:21, 29775.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  64%|██████▍   | 1145000/1781586 [00:55<00:20, 30815.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  64%|██████▍   | 1149000/1781586 [00:55<00:22, 27791.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  65%|██████▍   | 1152000/1781586 [00:55<00:26, 23875.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  65%|██████▍   | 1156000/1781586 [00:55<00:27, 22935.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  65%|██████▌   | 1159000/1781586 [00:55<00:27, 23007.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  65%|██████▌   | 1162000/1781586 [00:56<00:30, 20619.79 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  65%|██████▌   | 1165000/1781586 [00:56<00:28, 21684.75 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  66%|██████▌   | 1170000/1781586 [00:56<00:24, 24671.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  66%|██████▌   | 1173000/1781586 [00:56<00:33, 17998.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  66%|██████▌   | 1177000/1781586 [00:56<00:33, 18150.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  66%|██████▌   | 1180000/1781586 [00:57<00:37, 16188.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  66%|██████▋   | 1182000/1781586 [00:57<00:42, 14024.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  67%|██████▋   | 1185000/1781586 [00:57<00:36, 16565.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  67%|██████▋   | 1188000/1781586 [00:57<00:36, 16449.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  67%|██████▋   | 1190000/1781586 [00:57<00:36, 16425.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  67%|██████▋   | 1192000/1781586 [00:57<00:37, 15794.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  67%|██████▋   | 1197000/1781586 [00:58<00:26, 22445.89 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  67%|██████▋   | 1202000/1781586 [00:58<00:20, 28720.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  68%|██████▊   | 1206000/1781586 [00:58<00:21, 27407.79 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  68%|██████▊   | 1211000/1781586 [00:58<00:17, 32196.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  68%|██████▊   | 1217000/1781586 [00:58<00:15, 35929.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  69%|██████▊   | 1221000/1781586 [00:58<00:18, 29718.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  69%|██████▉   | 1225000/1781586 [00:58<00:20, 27034.73 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  69%|██████▉   | 1228000/1781586 [00:59<00:24, 22464.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  69%|██████▉   | 1231000/1781586 [00:59<00:24, 22284.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  69%|██████▉   | 1234000/1781586 [00:59<00:31, 17568.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  70%|██████▉   | 1239000/1781586 [00:59<00:24, 21960.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  70%|██████▉   | 1242000/1781586 [00:59<00:25, 21450.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  70%|██████▉   | 1245000/1781586 [01:00<00:26, 20192.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  70%|███████   | 1248000/1781586 [01:00<00:28, 18406.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  70%|███████   | 1251000/1781586 [01:00<00:27, 19402.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  70%|███████   | 1254000/1781586 [01:00<00:26, 20179.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  71%|███████   | 1257000/1781586 [01:00<00:28, 18279.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  71%|███████   | 1259000/1781586 [01:00<00:36, 14277.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  71%|███████   | 1262000/1781586 [01:01<00:34, 14956.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  71%|███████   | 1265000/1781586 [01:01<00:29, 17358.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  71%|███████   | 1269000/1781586 [01:01<00:28, 17980.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  71%|███████▏  | 1273000/1781586 [01:01<00:23, 21552.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  72%|███████▏  | 1277000/1781586 [01:01<00:21, 23797.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  72%|███████▏  | 1283000/1781586 [01:01<00:16, 30401.07 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  72%|███████▏  | 1287000/1781586 [01:01<00:15, 31010.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  73%|███████▎  | 1292000/1781586 [01:02<00:14, 32832.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  73%|███████▎  | 1296000/1781586 [01:02<00:15, 31276.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  73%|███████▎  | 1300000/1781586 [01:02<00:17, 26801.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  73%|███████▎  | 1303000/1781586 [01:02<00:19, 24772.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  73%|███████▎  | 1306000/1781586 [01:02<00:24, 19667.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  73%|███████▎  | 1309000/1781586 [01:03<00:30, 15416.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  74%|███████▎  | 1313000/1781586 [01:03<00:25, 18663.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  74%|███████▍  | 1316000/1781586 [01:03<00:23, 19683.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  74%|███████▍  | 1319000/1781586 [01:03<00:27, 16923.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  74%|███████▍  | 1322000/1781586 [01:03<00:24, 18853.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  74%|███████▍  | 1326000/1781586 [01:03<00:22, 20567.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  75%|███████▍  | 1329000/1781586 [01:04<00:21, 20816.07 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  75%|███████▍  | 1333000/1781586 [01:04<00:20, 22091.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  75%|███████▍  | 1336000/1781586 [01:04<00:20, 21470.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  75%|███████▌  | 1339000/1781586 [01:04<00:22, 20072.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  75%|███████▌  | 1343000/1781586 [01:04<00:18, 23641.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  76%|███████▌  | 1349000/1781586 [01:04<00:19, 22295.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  76%|███████▌  | 1354000/1781586 [01:05<00:16, 26670.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  76%|███████▌  | 1357000/1781586 [01:05<00:17, 24732.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  76%|███████▋  | 1361000/1781586 [01:05<00:15, 26316.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  77%|███████▋  | 1364000/1781586 [01:05<00:19, 21537.75 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  77%|███████▋  | 1369000/1781586 [01:05<00:15, 26705.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  77%|███████▋  | 1373000/1781586 [01:05<00:20, 20237.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  77%|███████▋  | 1376000/1781586 [01:06<00:23, 17425.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  77%|███████▋  | 1379000/1781586 [01:06<00:21, 18308.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  78%|███████▊  | 1385000/1781586 [01:06<00:17, 22087.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  78%|███████▊  | 1388000/1781586 [01:06<00:22, 17375.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  78%|███████▊  | 1392000/1781586 [01:07<00:21, 18456.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  78%|███████▊  | 1396000/1781586 [01:07<00:18, 20403.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  79%|███████▊  | 1400000/1781586 [01:07<00:16, 23071.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  79%|███████▉  | 1404000/1781586 [01:07<00:14, 26084.79 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  79%|███████▉  | 1407000/1781586 [01:07<00:14, 25614.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  79%|███████▉  | 1412000/1781586 [01:07<00:12, 28730.91 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  79%|███████▉  | 1416000/1781586 [01:07<00:13, 27818.89 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  80%|███████▉  | 1419000/1781586 [01:07<00:13, 26237.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  80%|███████▉  | 1422000/1781586 [01:08<00:13, 26123.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  80%|███████▉  | 1425000/1781586 [01:08<00:13, 26544.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  80%|████████  | 1428000/1781586 [01:08<00:14, 24943.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  80%|████████  | 1431000/1781586 [01:08<00:17, 19973.07 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  80%|████████  | 1434000/1781586 [01:08<00:21, 16370.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  81%|████████  | 1439000/1781586 [01:08<00:17, 19833.96 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  81%|████████  | 1442000/1781586 [01:09<00:16, 20180.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  81%|████████  | 1445000/1781586 [01:09<00:21, 15556.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  81%|████████▏ | 1449000/1781586 [01:09<00:19, 17301.73 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  82%|████████▏ | 1453000/1781586 [01:09<00:16, 19806.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  82%|████████▏ | 1456000/1781586 [01:10<00:21, 15243.96 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  82%|████████▏ | 1461000/1781586 [01:10<00:16, 19798.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  82%|████████▏ | 1465000/1781586 [01:10<00:14, 21755.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  82%|████████▏ | 1468000/1781586 [01:10<00:16, 18635.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  83%|████████▎ | 1471000/1781586 [01:10<00:16, 19281.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  83%|████████▎ | 1477000/1781586 [01:10<00:11, 26807.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  83%|████████▎ | 1482000/1781586 [01:10<00:10, 29881.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  83%|████████▎ | 1486000/1781586 [01:11<00:10, 27878.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  84%|████████▎ | 1490000/1781586 [01:11<00:09, 30102.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  84%|████████▍ | 1494000/1781586 [01:11<00:09, 30608.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  84%|████████▍ | 1498000/1781586 [01:11<00:09, 29531.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  84%|████████▍ | 1502000/1781586 [01:11<00:13, 20878.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  85%|████████▍ | 1506000/1781586 [01:11<00:12, 22258.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  85%|████████▍ | 1510000/1781586 [01:12<00:10, 25550.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  85%|████████▍ | 1513000/1781586 [01:12<00:14, 18057.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  85%|████████▌ | 1516000/1781586 [01:12<00:15, 17696.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  85%|████████▌ | 1519000/1781586 [01:12<00:13, 19615.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  85%|████████▌ | 1522000/1781586 [01:12<00:13, 19448.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  86%|████████▌ | 1525000/1781586 [01:13<00:16, 15656.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  86%|████████▌ | 1527000/1781586 [01:13<00:15, 16055.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  86%|████████▌ | 1529000/1781586 [01:13<00:16, 15104.89 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  86%|████████▌ | 1534000/1781586 [01:13<00:12, 19835.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  86%|████████▋ | 1539000/1781586 [01:13<00:10, 22524.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  87%|████████▋ | 1542000/1781586 [01:13<00:10, 21879.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  87%|████████▋ | 1547000/1781586 [01:14<00:11, 19616.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  87%|████████▋ | 1554000/1781586 [01:14<00:08, 27078.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  87%|████████▋ | 1558000/1781586 [01:14<00:07, 28796.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  88%|████████▊ | 1563000/1781586 [01:14<00:07, 29432.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  88%|████████▊ | 1567000/1781586 [01:14<00:07, 28580.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  88%|████████▊ | 1571000/1781586 [01:14<00:07, 29636.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  88%|████████▊ | 1575000/1781586 [01:15<00:09, 20982.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  89%|████████▊ | 1580000/1781586 [01:15<00:09, 22094.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  89%|████████▉ | 1583000/1781586 [01:15<00:09, 20565.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  89%|████████▉ | 1586000/1781586 [01:15<00:11, 17225.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  89%|████████▉ | 1588000/1781586 [01:15<00:11, 16927.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  89%|████████▉ | 1590000/1781586 [01:16<00:10, 17451.91 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  89%|████████▉ | 1592000/1781586 [01:16<00:11, 15978.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  90%|████████▉ | 1595745/1781586 [01:16<00:09, 19874.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  90%|█████████ | 1603745/1781586 [01:16<00:07, 23382.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  90%|█████████ | 1606745/1781586 [01:16<00:08, 21494.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  90%|█████████ | 1610489/1781586 [01:16<00:07, 21878.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  91%|█████████ | 1614489/1781586 [01:17<00:06, 24443.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  91%|█████████ | 1617489/1781586 [01:17<00:08, 20199.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  91%|█████████ | 1620234/1781586 [01:17<00:07, 21206.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  91%|█████████▏| 1626723/1781586 [01:17<00:05, 28688.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  92%|█████████▏| 1630723/1781586 [01:17<00:05, 28225.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  92%|█████████▏| 1635723/1781586 [01:17<00:04, 32184.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  92%|█████████▏| 1639723/1781586 [01:18<00:08, 16981.07 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  92%|█████████▏| 1643468/1781586 [01:18<00:07, 19434.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  92%|█████████▏| 1646468/1781586 [01:18<00:07, 19254.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  93%|█████████▎| 1652468/1781586 [01:18<00:04, 26395.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  93%|█████████▎| 1656957/1781586 [01:18<00:04, 25119.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  93%|█████████▎| 1660701/1781586 [01:19<00:04, 25914.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  93%|█████████▎| 1664445/1781586 [01:19<00:04, 27816.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  94%|█████████▎| 1668445/1781586 [01:19<00:05, 19907.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  94%|█████████▍| 1671445/1781586 [01:19<00:05, 19432.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  94%|█████████▍| 1674189/1781586 [01:19<00:05, 19504.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  94%|█████████▍| 1676678/1781586 [01:19<00:05, 19653.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  94%|█████████▍| 1681167/1781586 [01:20<00:04, 22933.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  95%|█████████▍| 1685144/1781586 [01:20<00:03, 26327.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  95%|█████████▍| 1689144/1781586 [01:20<00:03, 29421.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  95%|█████████▌| 1692889/1781586 [01:20<00:02, 29620.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  95%|█████████▌| 1696633/1781586 [01:20<00:03, 22859.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  95%|█████████▌| 1701353/1781586 [01:20<00:02, 27354.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  96%|█████████▌| 1704586/1781586 [01:21<00:03, 20851.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  96%|█████████▌| 1710074/1781586 [01:21<00:02, 26579.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  96%|█████████▌| 1713562/1781586 [01:21<00:02, 26060.36 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  96%|█████████▋| 1717562/1781586 [01:21<00:03, 19276.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  97%|█████████▋| 1721794/1781586 [01:21<00:02, 21931.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  97%|█████████▋| 1725514/1781586 [01:21<00:02, 23749.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  97%|█████████▋| 1728746/1781586 [01:22<00:02, 24439.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  97%|█████████▋| 1734978/1781586 [01:22<00:01, 27849.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  98%|█████████▊| 1739467/1781586 [01:22<00:01, 27785.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  98%|█████████▊| 1742699/1781586 [01:22<00:01, 20226.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  98%|█████████▊| 1745443/1781586 [01:23<00:02, 12985.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  98%|█████████▊| 1747931/1781586 [01:23<00:02, 13730.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  98%|█████████▊| 1752419/1781586 [01:23<00:01, 18143.79 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  99%|█████████▊| 1755419/1781586 [01:23<00:01, 13171.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  99%|█████████▊| 1757419/1781586 [01:24<00:01, 12186.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  99%|█████████▉| 1759419/1781586 [01:24<00:01, 11406.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  99%|█████████▉| 1761163/1781586 [01:24<00:02, 10184.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  99%|█████████▉| 1763163/1781586 [01:24<00:01, 11067.56 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  99%|█████████▉| 1764907/1781586 [01:25<00:02, 7525.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  99%|█████████▉| 1766907/1781586 [01:25<00:02, 7334.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  99%|█████████▉| 1769651/1781586 [01:25<00:01, 9257.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  99%|█████████▉| 1771395/1781586 [01:25<00:01, 8717.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72): 100%|█████████▉| 1775630/1781586 [01:26<00:00, 10034.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72): 100%|█████████▉| 1777118/1781586 [01:26<00:00, 6268.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72): 100%|█████████▉| 1778607/1781586 [01:26<00:00, 6723.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72): 100%|█████████▉| 1780097/1781586 [01:27<00:00, 6053.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72): 100%|██████████| 1781586/1781586 [01:27<00:00, 20411.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):   0%|          | 0/1781586 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):   0%|          | 1000/1781586 [00:00<23:23, 1268.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):   0%|          | 6000/1781586 [00:00<03:27, 8570.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):   2%|▏         | 36000/1781586 [00:01<00:29, 60061.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):   4%|▎         | 64000/1781586 [00:01<00:16, 103033.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):   5%|▍         | 84000/1781586 [00:01<00:31, 54141.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):   6%|▋         | 115000/1781586 [00:01<00:19, 84898.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):   8%|▊         | 135000/1781586 [00:02<00:17, 95892.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):   9%|▊         | 153000/1781586 [00:02<00:28, 57936.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  10%|█         | 179000/1781586 [00:02<00:20, 80120.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  11%|█▏        | 202000/1781586 [00:02<00:16, 97972.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  12%|█▏        | 220000/1781586 [00:03<00:25, 61717.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  13%|█▎        | 234000/1781586 [00:03<00:22, 67764.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  15%|█▍        | 264000/1781586 [00:03<00:15, 98466.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  16%|█▌        | 282000/1781586 [00:03<00:16, 92700.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  17%|█▋        | 297000/1781586 [00:04<00:23, 62876.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  18%|█▊        | 317000/1781586 [00:04<00:18, 79679.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  19%|█▉        | 336000/1781586 [00:04<00:15, 95942.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  20%|█▉        | 352000/1781586 [00:04<00:14, 97659.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  21%|██        | 366000/1781586 [00:05<00:23, 59241.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  21%|██▏       | 381000/1781586 [00:05<00:19, 71029.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  22%|██▏       | 400000/1781586 [00:05<00:15, 89241.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  23%|██▎       | 416000/1781586 [00:05<00:13, 101765.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  24%|██▍       | 431000/1781586 [00:06<00:19, 68213.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  25%|██▍       | 443000/1781586 [00:06<00:20, 65605.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  26%|██▌       | 457000/1781586 [00:06<00:17, 77218.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  27%|██▋       | 478000/1781586 [00:06<00:13, 96539.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  28%|██▊       | 491000/1781586 [00:06<00:14, 91741.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  28%|██▊       | 503000/1781586 [00:06<00:17, 71400.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  29%|██▉       | 513000/1781586 [00:07<00:19, 65658.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  29%|██▉       | 525000/1781586 [00:07<00:17, 72178.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  30%|███       | 542000/1781586 [00:07<00:13, 88884.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  31%|███       | 555000/1781586 [00:07<00:12, 95568.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  32%|███▏      | 566000/1781586 [00:07<00:15, 78182.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  32%|███▏      | 576000/1781586 [00:07<00:17, 70534.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  33%|███▎      | 585000/1781586 [00:08<00:17, 68795.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  34%|███▎      | 598000/1781586 [00:08<00:14, 81526.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  34%|███▍      | 609000/1781586 [00:08<00:13, 84277.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  35%|███▌      | 624000/1781586 [00:08<00:11, 99996.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  36%|███▌      | 635000/1781586 [00:08<00:13, 84404.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  36%|███▌      | 645000/1781586 [00:08<00:16, 70047.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  37%|███▋      | 654000/1781586 [00:08<00:16, 67709.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  37%|███▋      | 664000/1781586 [00:08<00:15, 74497.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  38%|███▊      | 673000/1781586 [00:09<00:14, 75539.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  39%|███▊      | 690000/1781586 [00:09<00:11, 97590.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  39%|███▉      | 701000/1781586 [00:09<00:11, 96050.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  40%|███▉      | 712000/1781586 [00:09<00:11, 94109.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  41%|████      | 722000/1781586 [00:09<00:14, 70966.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  41%|████      | 731000/1781586 [00:09<00:15, 69747.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  41%|████▏     | 739000/1781586 [00:09<00:15, 67970.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  42%|████▏     | 750000/1781586 [00:10<00:13, 76958.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  43%|████▎     | 765000/1781586 [00:10<00:11, 92194.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  44%|████▎     | 776000/1781586 [00:10<00:10, 94077.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  44%|████▍     | 786000/1781586 [00:10<00:14, 68960.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  45%|████▍     | 795000/1781586 [00:10<00:13, 71778.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  45%|████▌     | 804000/1781586 [00:10<00:12, 75354.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  46%|████▌     | 813000/1781586 [00:10<00:13, 73908.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  46%|████▋     | 826000/1781586 [00:10<00:11, 85906.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  47%|████▋     | 837000/1781586 [00:11<00:10, 91172.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  48%|████▊     | 849000/1781586 [00:11<00:09, 94710.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  48%|████▊     | 859000/1781586 [00:11<00:12, 76534.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  49%|████▊     | 868000/1781586 [00:11<00:13, 69970.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  49%|████▉     | 876000/1781586 [00:11<00:12, 69762.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  50%|████▉     | 885000/1781586 [00:11<00:12, 71737.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  50%|█████     | 898000/1781586 [00:11<00:10, 83488.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  51%|█████▏    | 914000/1781586 [00:11<00:08, 102844.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  52%|█████▏    | 925000/1781586 [00:12<00:09, 92465.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  52%|█████▏    | 935000/1781586 [00:12<00:12, 70052.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  53%|█████▎    | 944000/1781586 [00:12<00:11, 72896.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  53%|█████▎    | 953000/1781586 [00:12<00:11, 69064.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  54%|█████▍    | 965000/1781586 [00:12<00:10, 79950.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  55%|█████▌    | 981000/1781586 [00:12<00:08, 98200.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  56%|█████▌    | 992000/1781586 [00:12<00:08, 98682.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  56%|█████▋    | 1003000/1781586 [00:13<00:11, 70435.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  57%|█████▋    | 1012000/1781586 [00:13<00:10, 70967.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  57%|█████▋    | 1022000/1781586 [00:13<00:10, 73492.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  58%|█████▊    | 1033000/1781586 [00:13<00:09, 80022.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  59%|█████▊    | 1046000/1781586 [00:13<00:08, 91865.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  59%|█████▉    | 1058000/1781586 [00:13<00:07, 97816.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  60%|██████    | 1069000/1781586 [00:14<00:10, 69878.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  61%|██████    | 1078000/1781586 [00:14<00:09, 73419.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  61%|██████    | 1087000/1781586 [00:14<00:10, 69049.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  61%|██████▏   | 1095000/1781586 [00:14<00:09, 70473.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  62%|██████▏   | 1107000/1781586 [00:14<00:08, 81812.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  63%|██████▎   | 1120000/1781586 [00:14<00:07, 93597.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  64%|██████▎   | 1134000/1781586 [00:14<00:06, 98376.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  64%|██████▍   | 1145000/1781586 [00:14<00:08, 73386.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  65%|██████▍   | 1154000/1781586 [00:15<00:08, 74691.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  65%|██████▌   | 1163000/1781586 [00:15<00:09, 64365.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  66%|██████▌   | 1178000/1781586 [00:15<00:07, 80809.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  67%|██████▋   | 1191000/1781586 [00:15<00:06, 90449.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  68%|██████▊   | 1203000/1781586 [00:15<00:05, 96815.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  68%|██████▊   | 1214000/1781586 [00:15<00:07, 73986.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  69%|██████▊   | 1223000/1781586 [00:16<00:08, 67212.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  69%|██████▉   | 1233000/1781586 [00:16<00:07, 71870.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  70%|██████▉   | 1242000/1781586 [00:16<00:07, 74044.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  71%|███████   | 1262000/1781586 [00:16<00:05, 103119.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  72%|███████▏  | 1274000/1781586 [00:16<00:05, 86396.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  72%|███████▏  | 1284000/1781586 [00:16<00:05, 83590.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  73%|███████▎  | 1294000/1781586 [00:16<00:07, 65297.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  73%|███████▎  | 1304000/1781586 [00:17<00:07, 67571.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  74%|███████▍  | 1319000/1781586 [00:17<00:05, 83205.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  75%|███████▍  | 1333000/1781586 [00:17<00:04, 95014.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  75%|███████▌  | 1344000/1781586 [00:17<00:04, 89864.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  76%|███████▌  | 1354000/1781586 [00:17<00:05, 85123.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  77%|███████▋  | 1364000/1781586 [00:17<00:06, 65905.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  77%|███████▋  | 1375000/1781586 [00:17<00:05, 67868.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  78%|███████▊  | 1390000/1781586 [00:18<00:04, 84513.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  79%|███████▊  | 1400000/1781586 [00:18<00:04, 87027.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  79%|███████▉  | 1411000/1781586 [00:18<00:04, 90799.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  80%|███████▉  | 1421000/1781586 [00:18<00:04, 78091.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  80%|████████  | 1430000/1781586 [00:18<00:04, 74213.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  81%|████████  | 1438000/1781586 [00:18<00:04, 70853.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  81%|████████  | 1446000/1781586 [00:18<00:04, 70192.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  82%|████████▏ | 1456000/1781586 [00:18<00:04, 76922.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  83%|████████▎ | 1471000/1781586 [00:19<00:03, 95465.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  83%|████████▎ | 1482000/1781586 [00:19<00:03, 98033.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  84%|████████▍ | 1493000/1781586 [00:19<00:03, 82935.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  84%|████████▍ | 1502000/1781586 [00:19<00:04, 63328.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  85%|████████▍ | 1510000/1781586 [00:19<00:04, 64844.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  85%|████████▌ | 1523000/1781586 [00:19<00:03, 79109.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  86%|████████▋ | 1538000/1781586 [00:19<00:02, 91855.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  87%|████████▋ | 1552000/1781586 [00:19<00:02, 103633.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  88%|████████▊ | 1564000/1781586 [00:20<00:02, 89065.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  88%|████████▊ | 1574000/1781586 [00:20<00:03, 63010.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  89%|████████▉ | 1584000/1781586 [00:20<00:02, 69628.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  90%|████████▉ | 1595000/1781586 [00:20<00:02, 78113.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  90%|█████████ | 1608000/1781586 [00:20<00:01, 88804.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  91%|█████████ | 1619000/1781586 [00:20<00:01, 93366.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  91%|█████████▏| 1630000/1781586 [00:20<00:01, 93215.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  92%|█████████▏| 1640000/1781586 [00:21<00:01, 81254.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  93%|█████████▎| 1649000/1781586 [00:21<00:02, 63126.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  93%|█████████▎| 1662744/1781586 [00:21<00:01, 77060.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  94%|█████████▍| 1674233/1781586 [00:21<00:01, 83312.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  95%|█████████▍| 1689722/1781586 [00:21<00:00, 98475.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  95%|█████████▌| 1700722/1781586 [00:21<00:00, 82295.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  96%|█████████▌| 1711443/1781586 [00:22<00:00, 79079.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  97%|█████████▋| 1727843/1781586 [00:22<00:00, 97455.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  98%|█████████▊| 1741261/1781586 [00:22<00:00, 106302.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  98%|█████████▊| 1752934/1781586 [00:22<00:00, 95917.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  99%|█████████▉| 1763865/1781586 [00:22<00:00, 82662.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72): 100%|█████████▉| 1773097/1781586 [00:24<00:00, 17358.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72): 100%|█████████▉| 1780097/1781586 [00:25<00:00, 11102.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72): 100%|██████████| 1781586/1781586 [00:26<00:00, 67657.09 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (0/23 shards):   0%|          | 0/416795 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (0/23 shards):   1%|          | 3000/416795 [00:00<00:19, 21329.43 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (0/23 shards):   1%|▏         | 6000/416795 [00:00<00:20, 19699.74 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (0/23 shards):   2%|▏         | 10000/416795 [00:00<00:18, 21743.02 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (0/23 shards):   3%|▎         | 14000/416795 [00:00<00:17, 22757.11 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (0/23 shards):   4%|▍         | 18000/416795 [00:00<00:17, 23226.02 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (1/23 shards):   4%|▍         | 18122/416795 [00:00<00:17, 23226.02 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (1/23 shards):   5%|▌         | 22122/416795 [00:01<00:20, 19052.31 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (1/23 shards):   6%|▋         | 26122/416795 [00:01<00:19, 20405.66 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (1/23 shards):   7%|▋         | 30122/416795 [00:01<00:17, 21661.80 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (1/23 shards):   8%|▊         | 34122/416795 [00:01<00:16, 22588.76 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (2/23 shards):   9%|▊         | 36244/416795 [00:01<00:16, 22588.76 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (2/23 shards):   9%|▉         | 38244/416795 [00:01<00:16, 22995.37 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (2/23 shards):  10%|█         | 42244/416795 [00:02<00:21, 17098.50 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (2/23 shards):  11%|█         | 46244/416795 [00:02<00:19, 18944.80 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (2/23 shards):  12%|█▏        | 50244/416795 [00:02<00:17, 20520.12 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (2/23 shards):  13%|█▎        | 54244/416795 [00:02<00:16, 21740.92 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (3/23 shards):  13%|█▎        | 54366/416795 [00:02<00:16, 21740.92 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (3/23 shards):  14%|█▍        | 58366/416795 [00:02<00:18, 18978.77 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (3/23 shards):  15%|█▍        | 62366/416795 [00:03<00:17, 20440.03 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (3/23 shards):  16%|█▌        | 66366/416795 [00:03<00:16, 21724.91 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (3/23 shards):  17%|█▋        | 70366/416795 [00:03<00:15, 22720.13 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (4/23 shards):  17%|█▋        | 72488/416795 [00:03<00:15, 22720.13 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (4/23 shards):  18%|█▊        | 73488/416795 [00:03<00:15, 22010.65 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (4/23 shards):  18%|█▊        | 76488/416795 [00:03<00:19, 17554.54 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (4/23 shards):  19%|█▉        | 80488/416795 [00:03<00:17, 19473.86 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (4/23 shards):  20%|██        | 84488/416795 [00:04<00:15, 20990.35 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (4/23 shards):  21%|██        | 88488/416795 [00:04<00:14, 22106.31 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (5/23 shards):  22%|██▏       | 90610/416795 [00:04<00:14, 22106.31 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (5/23 shards):  22%|██▏       | 92610/416795 [00:04<00:14, 22643.77 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (5/23 shards):  23%|██▎       | 96610/416795 [00:04<00:17, 18044.57 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (5/23 shards):  24%|██▍       | 100610/416795 [00:04<00:16, 19684.46 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (5/23 shards):  25%|██▌       | 104610/416795 [00:05<00:14, 21076.06 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (5/23 shards):  26%|██▌       | 108610/416795 [00:05<00:13, 22224.54 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (6/23 shards):  26%|██▌       | 108732/416795 [00:05<00:13, 22224.54 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (6/23 shards):  27%|██▋       | 112732/416795 [00:05<00:16, 18652.40 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (6/23 shards):  28%|██▊       | 116732/416795 [00:05<00:14, 20190.78 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (6/23 shards):  29%|██▉       | 120732/416795 [00:05<00:13, 21532.46 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (6/23 shards):  30%|██▉       | 124732/416795 [00:05<00:12, 22593.05 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (7/23 shards):  30%|███       | 126854/416795 [00:06<00:12, 22593.05 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (7/23 shards):  31%|███       | 128854/416795 [00:06<00:12, 23087.19 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (7/23 shards):  32%|███▏      | 132854/416795 [00:06<00:14, 19867.57 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (7/23 shards):  33%|███▎      | 136854/416795 [00:06<00:13, 21224.69 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (7/23 shards):  34%|███▍      | 140854/416795 [00:06<00:12, 22281.21 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (7/23 shards):  35%|███▍      | 144854/416795 [00:06<00:11, 22963.78 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (8/23 shards):  35%|███▍      | 144976/416795 [00:06<00:11, 22963.78 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (8/23 shards):  36%|███▌      | 148976/416795 [00:07<00:13, 19733.27 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (8/23 shards):  37%|███▋      | 152976/416795 [00:07<00:12, 21131.95 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (8/23 shards):  38%|███▊      | 156976/416795 [00:07<00:11, 22284.58 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (8/23 shards):  39%|███▊      | 160976/416795 [00:07<00:11, 23219.92 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (9/23 shards):  39%|███▉      | 163098/416795 [00:07<00:10, 23219.92 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (9/23 shards):  40%|███▉      | 165098/416795 [00:07<00:10, 23456.39 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (9/23 shards):  41%|████      | 169098/416795 [00:08<00:12, 19753.32 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (9/23 shards):  42%|████▏     | 173098/416795 [00:08<00:11, 21144.02 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (9/23 shards):  42%|████▏     | 177098/416795 [00:08<00:10, 22224.38 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (9/23 shards):  43%|████▎     | 181098/416795 [00:08<00:10, 23168.01 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (10/23 shards):  43%|████▎     | 181220/416795 [00:08<00:10, 23168.01 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (10/23 shards):  44%|████▍     | 184220/416795 [00:08<00:10, 21912.87 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (10/23 shards):  45%|████▍     | 187220/416795 [00:08<00:11, 19766.44 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (10/23 shards):  46%|████▌     | 191220/416795 [00:09<00:10, 21214.39 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (10/23 shards):  47%|████▋     | 195220/416795 [00:09<00:09, 22294.05 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (10/23 shards):  48%|████▊     | 199220/416795 [00:09<00:09, 23211.09 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (11/23 shards):  48%|████▊     | 199342/416795 [00:09<00:09, 23211.09 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (11/23 shards):  49%|████▊     | 202342/416795 [00:09<00:09, 22645.39 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (11/23 shards):  49%|████▉     | 205342/416795 [00:09<00:11, 17798.16 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (11/23 shards):  50%|█████     | 209342/416795 [00:09<00:10, 19774.16 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (11/23 shards):  51%|█████     | 213342/416795 [00:10<00:09, 21207.30 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (11/23 shards):  52%|█████▏    | 217342/416795 [00:10<00:08, 22477.32 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (12/23 shards):  52%|█████▏    | 217464/416795 [00:10<00:08, 22477.32 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (12/23 shards):  53%|█████▎    | 221464/416795 [00:10<00:10, 17858.30 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (12/23 shards):  54%|█████▍    | 225464/416795 [00:10<00:09, 19637.96 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (12/23 shards):  55%|█████▌    | 229464/416795 [00:10<00:08, 21109.13 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (12/23 shards):  56%|█████▌    | 233464/416795 [00:11<00:08, 22320.79 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (13/23 shards):  57%|█████▋    | 235585/416795 [00:11<00:08, 22320.79 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (13/23 shards):  57%|█████▋    | 237585/416795 [00:11<00:07, 22920.18 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (13/23 shards):  58%|█████▊    | 241585/416795 [00:11<00:09, 18156.15 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (13/23 shards):  59%|█████▉    | 245585/416795 [00:11<00:08, 19861.48 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (13/23 shards):  60%|█████▉    | 249585/416795 [00:11<00:07, 21220.89 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (13/23 shards):  61%|██████    | 253585/416795 [00:12<00:07, 22267.79 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (14/23 shards):  61%|██████    | 253706/416795 [00:12<00:07, 22267.79 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (14/23 shards):  62%|██████▏   | 257706/416795 [00:12<00:08, 18991.70 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (14/23 shards):  63%|██████▎   | 261706/416795 [00:12<00:07, 20607.92 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (14/23 shards):  64%|██████▎   | 265706/416795 [00:12<00:06, 21914.19 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (14/23 shards):  65%|██████▍   | 269706/416795 [00:12<00:06, 22877.03 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (15/23 shards):  65%|██████▌   | 271827/416795 [00:12<00:06, 22877.03 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (15/23 shards):  66%|██████▌   | 273827/416795 [00:13<00:06, 23002.84 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (15/23 shards):  67%|██████▋   | 277827/416795 [00:13<00:07, 18965.78 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (15/23 shards):  68%|██████▊   | 281827/416795 [00:13<00:06, 20534.82 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (15/23 shards):  69%|██████▊   | 285827/416795 [00:13<00:06, 21791.13 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (15/23 shards):  70%|██████▉   | 289827/416795 [00:13<00:05, 22700.97 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (16/23 shards):  70%|██████▉   | 289948/416795 [00:13<00:05, 22700.97 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (16/23 shards):  70%|███████   | 292948/416795 [00:13<00:05, 21102.33 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (16/23 shards):  71%|███████   | 295948/416795 [00:14<00:06, 19305.42 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (16/23 shards):  72%|███████▏  | 299948/416795 [00:14<00:05, 21032.24 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (16/23 shards):  73%|███████▎  | 303948/416795 [00:14<00:05, 22356.22 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (16/23 shards):  74%|███████▍  | 307948/416795 [00:14<00:04, 23321.78 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (17/23 shards):  74%|███████▍  | 308069/416795 [00:14<00:04, 23321.78 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (17/23 shards):  75%|███████▍  | 312069/416795 [00:14<00:05, 18308.80 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (17/23 shards):  76%|███████▌  | 316069/416795 [00:15<00:05, 19961.77 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (17/23 shards):  77%|███████▋  | 320069/416795 [00:15<00:04, 21310.91 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (17/23 shards):  78%|███████▊  | 324069/416795 [00:15<00:04, 22523.24 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (18/23 shards):  78%|███████▊  | 326190/416795 [00:15<00:04, 22523.24 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (18/23 shards):  79%|███████▊  | 328190/416795 [00:15<00:03, 23029.92 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (18/23 shards):  80%|███████▉  | 332190/416795 [00:15<00:04, 18461.87 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (18/23 shards):  81%|████████  | 336190/416795 [00:16<00:04, 20106.10 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (18/23 shards):  82%|████████▏ | 340190/416795 [00:16<00:03, 21427.51 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (18/23 shards):  83%|████████▎ | 344190/416795 [00:16<00:03, 22416.16 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (19/23 shards):  83%|████████▎ | 344311/416795 [00:16<00:03, 22416.16 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (19/23 shards):  84%|████████▎ | 348311/416795 [00:16<00:03, 19264.05 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (19/23 shards):  85%|████████▍ | 352311/416795 [00:16<00:03, 20731.45 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (19/23 shards):  85%|████████▌ | 356311/416795 [00:16<00:02, 21961.98 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (19/23 shards):  86%|████████▋ | 360311/416795 [00:17<00:02, 22894.35 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (20/23 shards):  87%|████████▋ | 362432/416795 [00:17<00:02, 22894.35 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (20/23 shards):  87%|████████▋ | 364432/416795 [00:17<00:02, 23227.81 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (20/23 shards):  88%|████████▊ | 368432/416795 [00:17<00:02, 20057.04 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (20/23 shards):  89%|████████▉ | 372432/416795 [00:17<00:02, 21412.05 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (20/23 shards):  90%|█████████ | 376432/416795 [00:17<00:01, 22571.13 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (20/23 shards):  91%|█████████▏| 380432/416795 [00:18<00:01, 23347.77 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (21/23 shards):  91%|█████████▏| 380553/416795 [00:18<00:01, 23347.77 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (21/23 shards):  92%|█████████▏| 384553/416795 [00:18<00:01, 19283.61 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (21/23 shards):  93%|█████████▎| 388553/416795 [00:18<00:01, 20765.65 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (21/23 shards):  94%|█████████▍| 392553/416795 [00:18<00:01, 22058.09 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (21/23 shards):  95%|█████████▌| 396553/416795 [00:18<00:00, 23019.42 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (22/23 shards):  96%|█████████▌| 398674/416795 [00:18<00:00, 23019.42 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (22/23 shards):  96%|█████████▌| 399674/416795 [00:18<00:00, 22280.82 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (22/23 shards):  97%|█████████▋| 402674/416795 [00:19<00:00, 17758.16 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (22/23 shards):  98%|█████████▊| 406674/416795 [00:19<00:00, 19750.69 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (22/23 shards):  99%|█████████▊| 410674/416795 [00:19<00:00, 21376.01 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (22/23 shards):  99%|█████████▉| 414674/416795 [00:19<00:00, 22528.27 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (23/23 shards): 100%|██████████| 416795/416795 [00:19<00:00, 22528.27 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (23/23 shards): 100%|██████████| 416795/416795 [00:19<00:00, 21063.73 examples/s]\u001b[0m\n",
      "\u001b[34mSaved data to: /opt/ml/input/data/train/huggingface-dataset-workertest-0-00-25-54/\u001b[0m\n",
      "\u001b[34m2024-04-19 00:31:00,590 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-04-19 00:31:00,590 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-04-19 00:31:00,590 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-04-19 00:32:26 Uploading - Uploading generated training model\n",
      "2024-04-19 00:32:26 Completed - Resource retained for reuse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-dataset-workertest-1-00-32-41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 337\n",
      "Billable seconds: 337\n",
      "huggingface-dataset-workertest-1-00-32-41\n",
      "2024-04-19 00:32:41 Starting - Starting the training job..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-04-19 00:32:52,294 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-04-19 00:32:52,294 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-19 00:32:52,295 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-19 00:32:52,304 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-04-19 00:32:52,305 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-04-19 00:32:53,632 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.33.0 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.33.0-py3-none-any.whl.metadata (119 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.9/119.9 kB 5.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting datasets (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: accelerate>=0.21 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.22.0)\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting einops (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0->-r requirements.txt (line 1)) (3.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0->-r requirements.txt (line 1)) (0.19.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0->-r requirements.txt (line 1)) (1.26.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0->-r requirements.txt (line 1)) (23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0->-r requirements.txt (line 1)) (6.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0->-r requirements.txt (line 1)) (2023.10.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0->-r requirements.txt (line 1)) (2.31.0)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.33.0->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0->-r requirements.txt (line 1)) (0.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0->-r requirements.txt (line 1)) (4.64.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (14.0.1)\u001b[0m\n",
      "\u001b[34mCollecting pyarrow-hotfix (from datasets->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (0.3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (2.1.3)\u001b[0m\n",
      "\u001b[34mCollecting xxhash (from datasets->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (0.70.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets->-r requirements.txt (line 2)) (2023.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (3.9.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21->-r requirements.txt (line 3)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21->-r requirements.txt (line 3)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (23.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (6.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.9.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (4.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.0->-r requirements.txt (line 1)) (4.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0->-r requirements.txt (line 1)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0->-r requirements.txt (line 1)) (1.26.18)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0->-r requirements.txt (line 1)) (2023.11.17)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21->-r requirements.txt (line 3)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21->-r requirements.txt (line 3)) (3.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.21->-r requirements.txt (line 3)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2023.3.post1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate>=0.21->-r requirements.txt (line 3)) (2.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate>=0.21->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.33.0-py3-none-any.whl (7.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.6/7.6 MB 96.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 510.5/510.5 kB 66.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.8/119.8 MB 26.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading einops-0.7.0-py3-none-any.whl (44 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.6/44.6 kB 8.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 133.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.1/194.1 kB 33.9 MB/s eta 0:00:00\u001b[0m\n",
      "\n",
      "2024-04-19 00:32:51 Downloading - Downloading the training image\n",
      "2024-04-19 00:32:51 Training - Training image download completed. Training in progress.\u001b[34mInstalling collected packages: tokenizers, xxhash, pyarrow-hotfix, einops, transformers, bitsandbytes, datasets\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.15.0\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.15.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.15.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.35.2\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.35.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.35.2\u001b[0m\n",
      "\u001b[34mSuccessfully installed bitsandbytes-0.43.1 datasets-2.18.0 einops-0.7.0 pyarrow-hotfix-0.6 tokenizers-0.13.3 transformers-4.33.0 xxhash-3.4.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.3.1 -> 24.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-04-19 00:33:05,519 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-04-19 00:33:05,519 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-04-19 00:33:05,521 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-19 00:33:05,521 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-19 00:33:05,532 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-19 00:33:05,532 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-19 00:33:05,542 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-04-19 00:33:05,543 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-04-19 00:33:05,552 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.c5.18xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"job_name\": \"huggingface-dataset-workertest-1-00-32-41\",\n",
      "        \"model_id\": \"tiiuae/falcon-7b\",\n",
      "        \"num_proc\": 72,\n",
      "        \"split_range\": \"en/c4-train.00005-of-01024.json.gz,en/c4-train.00006-of-01024.json.gz,en/c4-train.00007-of-01024.json.gz,en/c4-train.00008-of-01024.json.gz,en/c4-train.00009-of-01024.json.gz\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.c5.18xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"huggingface-dataset-workertest-1-00-32-41\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-demo-c4/huggingface-dataset-workertest-1-00-32-41/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"data\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 72,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.18xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.18xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"data.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"job_name\":\"huggingface-dataset-workertest-1-00-32-41\",\"model_id\":\"tiiuae/falcon-7b\",\"num_proc\":72,\"split_range\":\"en/c4-train.00005-of-01024.json.gz,en/c4-train.00006-of-01024.json.gz,en/c4-train.00007-of-01024.json.gz,en/c4-train.00008-of-01024.json.gz,en/c4-train.00009-of-01024.json.gz\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=data.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.18xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.18xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.c5.18xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.18xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=data\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=72\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-demo-c4/huggingface-dataset-workertest-1-00-32-41/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.c5.18xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"job_name\":\"huggingface-dataset-workertest-1-00-32-41\",\"model_id\":\"tiiuae/falcon-7b\",\"num_proc\":72,\"split_range\":\"en/c4-train.00005-of-01024.json.gz,en/c4-train.00006-of-01024.json.gz,en/c4-train.00007-of-01024.json.gz,en/c4-train.00008-of-01024.json.gz,en/c4-train.00009-of-01024.json.gz\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.18xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"huggingface-dataset-workertest-1-00-32-41\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-demo-c4/huggingface-dataset-workertest-1-00-32-41/source/sourcedir.tar.gz\",\"module_name\":\"data\",\"network_interface_name\":\"eth0\",\"num_cpus\":72,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.18xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.18xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"data.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--job_name\",\"huggingface-dataset-workertest-1-00-32-41\",\"--model_id\",\"tiiuae/falcon-7b\",\"--num_proc\",\"72\",\"--split_range\",\"en/c4-train.00005-of-01024.json.gz,en/c4-train.00006-of-01024.json.gz,en/c4-train.00007-of-01024.json.gz,en/c4-train.00008-of-01024.json.gz,en/c4-train.00009-of-01024.json.gz\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_JOB_NAME=huggingface-dataset-workertest-1-00-32-41\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=tiiuae/falcon-7b\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_PROC=72\u001b[0m\n",
      "\u001b[34mSM_HP_SPLIT_RANGE=en/c4-train.00005-of-01024.json.gz,en/c4-train.00006-of-01024.json.gz,en/c4-train.00007-of-01024.json.gz,en/c4-train.00008-of-01024.json.gz,en/c4-train.00009-of-01024.json.gz\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 data.py --job_name huggingface-dataset-workertest-1-00-32-41 --model_id tiiuae/falcon-7b --num_proc 72 --split_range en/c4-train.00005-of-01024.json.gz,en/c4-train.00006-of-01024.json.gz,en/c4-train.00007-of-01024.json.gz,en/c4-train.00008-of-01024.json.gz,en/c4-train.00009-of-01024.json.gz\u001b[0m\n",
      "\u001b[34m2024-04-19 00:33:05,575 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mlist of files being processed:['en/c4-train.00005-of-01024.json.gz', 'en/c4-train.00006-of-01024.json.gz', 'en/c4-train.00007-of-01024.json.gz', 'en/c4-train.00008-of-01024.json.gz', 'en/c4-train.00009-of-01024.json.gz']\u001b[0m\n",
      "\u001b[34mDownloading readme:   0%|          | 0.00/41.1k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading readme: 100%|██████████| 41.1k/41.1k [00:00<00:00, 571kB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/318M [00:00<?, ?B/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/318M [00:00<?, ?B/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/318M [00:00<?, ?B/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   1%|▏         | 4.19M/318M [00:00<00:18, 16.8MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   1%|▏         | 4.19M/318M [00:00<00:18, 16.9MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   4%|▍         | 12.6M/318M [00:00<00:09, 31.2MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   1%|▏         | 4.19M/318M [00:00<00:14, 21.2MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   4%|▍         | 12.6M/318M [00:00<00:10, 29.3MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   4%|▍         | 12.6M/318M [00:00<00:07, 38.3MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/318M [00:00<?, ?B/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   7%|▋         | 21.0M/318M [00:00<00:07, 37.4MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   7%|▋         | 21.0M/318M [00:00<00:07, 38.8MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   7%|▋         | 21.0M/318M [00:00<00:06, 44.0MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   9%|▉         | 29.4M/318M [00:00<00:06, 43.3MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   1%|▏         | 4.19M/318M [00:00<00:15, 20.5MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   9%|▉         | 29.4M/318M [00:00<00:06, 42.2MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  12%|█▏        | 37.7M/318M [00:00<00:05, 47.2MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   4%|▍         | 12.6M/318M [00:00<00:08, 35.2MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  15%|█▍        | 46.1M/318M [00:01<00:05, 48.5MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   9%|▉         | 29.4M/318M [00:00<00:08, 32.4MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   7%|▋         | 21.0M/318M [00:00<00:06, 43.0MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  12%|█▏        | 37.7M/318M [00:01<00:07, 38.7MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  17%|█▋        | 54.5M/318M [00:01<00:06, 40.2MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   9%|▉         | 29.4M/318M [00:00<00:07, 37.1MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  15%|█▍        | 46.1M/318M [00:01<00:06, 41.5MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  17%|█▋        | 54.5M/318M [00:01<00:05, 45.4MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  12%|█▏        | 37.7M/318M [00:01<00:07, 39.1MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  20%|█▉        | 62.9M/318M [00:01<00:07, 36.4MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  20%|█▉        | 62.9M/318M [00:01<00:05, 47.2MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  14%|█▍        | 46.1M/318M [00:01<00:06, 40.2MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  12%|█▏        | 37.7M/318M [00:01<00:17, 16.3MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  17%|█▋        | 54.5M/318M [00:01<00:05, 44.0MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  22%|██▏       | 71.3M/318M [00:01<00:05, 44.7MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  14%|█▍        | 46.1M/318M [00:01<00:12, 21.8MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  22%|██▏       | 71.3M/318M [00:02<00:08, 29.4MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  25%|██▌       | 79.7M/318M [00:01<00:05, 46.5MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/318M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  25%|██▌       | 79.7M/318M [00:02<00:07, 33.1MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  28%|██▊       | 88.1M/318M [00:02<00:04, 47.5MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   1%|▏         | 4.19M/318M [00:00<00:13, 23.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  28%|██▊       | 88.1M/318M [00:02<00:06, 37.1MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   4%|▍         | 12.6M/318M [00:00<00:07, 39.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  30%|███       | 96.5M/318M [00:02<00:05, 41.1MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   7%|▋         | 21.0M/318M [00:00<00:05, 50.3MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   9%|▉         | 29.4M/318M [00:00<00:05, 55.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  33%|███▎      | 105M/318M [00:02<00:05, 41.2MB/s] #033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  12%|█▏        | 37.7M/318M [00:00<00:05, 52.7MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  36%|███▌      | 113M/318M [00:02<00:04, 42.0MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  17%|█▋        | 54.5M/318M [00:02<00:18, 14.6MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  15%|█▍        | 46.1M/318M [00:00<00:04, 56.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  38%|███▊      | 122M/318M [00:03<00:04, 44.3MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  20%|█▉        | 62.9M/318M [00:03<00:14, 17.7MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  17%|█▋        | 54.5M/318M [00:01<00:05, 48.0MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  22%|██▏       | 71.3M/318M [00:03<00:10, 22.7MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  30%|███       | 96.5M/318M [00:03<00:12, 18.5MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  20%|█▉        | 62.9M/318M [00:01<00:04, 53.4MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  22%|██▏       | 71.3M/318M [00:01<00:04, 57.9MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  25%|██▌       | 79.7M/318M [00:03<00:08, 27.3MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  41%|████      | 130M/318M [00:03<00:05, 31.7MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  25%|██▌       | 79.7M/318M [00:01<00:04, 58.4MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  33%|███▎      | 105M/318M [00:03<00:10, 20.8MB/s] #033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  44%|████▎     | 138M/318M [00:03<00:04, 36.0MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  28%|██▊       | 88.1M/318M [00:01<00:03, 60.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  36%|███▌      | 113M/318M [00:03<00:07, 25.6MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  30%|███       | 96.5M/318M [00:01<00:03, 62.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  33%|███▎      | 105M/318M [00:01<00:03, 62.5MB/s] #033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  38%|███▊      | 122M/318M [00:03<00:06, 28.2MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  36%|███▌      | 113M/318M [00:02<00:03, 63.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  41%|████      | 130M/318M [00:03<00:05, 33.7MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  38%|███▊      | 122M/318M [00:02<00:03, 65.4MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  44%|████▎     | 138M/318M [00:04<00:04, 37.1MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  46%|████▌     | 147M/318M [00:04<00:04, 41.3MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  41%|████      | 130M/318M [00:02<00:03, 49.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  46%|████▌     | 147M/318M [00:04<00:08, 19.4MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  49%|████▉     | 155M/318M [00:04<00:03, 44.8MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  44%|████▎     | 138M/318M [00:02<00:03, 53.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  46%|████▌     | 147M/318M [00:02<00:03, 56.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  49%|████▉     | 155M/318M [00:04<00:07, 22.8MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  51%|█████▏    | 164M/318M [00:04<00:03, 45.4MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  49%|████▉     | 155M/318M [00:02<00:02, 59.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  51%|█████▏    | 164M/318M [00:04<00:05, 27.7MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  54%|█████▍    | 172M/318M [00:04<00:03, 48.1MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  51%|█████▏    | 164M/318M [00:02<00:02, 61.9MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  57%|█████▋    | 180M/318M [00:04<00:02, 49.4MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  54%|█████▍    | 172M/318M [00:03<00:02, 62.4MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  28%|██▊       | 88.1M/318M [00:05<00:20, 11.3MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  59%|█████▉    | 189M/318M [00:05<00:02, 51.8MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  57%|█████▋    | 180M/318M [00:03<00:02, 62.9MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  59%|█████▉    | 189M/318M [00:03<00:02, 63.2MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  20%|█▉        | 62.9M/318M [00:04<00:38, 6.67MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  62%|██████▏   | 197M/318M [00:05<00:02, 49.3MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  62%|██████▏   | 197M/318M [00:03<00:01, 62.0MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  30%|███       | 96.5M/318M [00:05<00:16, 13.7MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  65%|██████▍   | 206M/318M [00:05<00:02, 48.2MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  65%|██████▍   | 206M/318M [00:03<00:01, 63.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  67%|██████▋   | 214M/318M [00:03<00:01, 63.3MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  33%|███▎      | 105M/318M [00:05<00:12, 16.6MB/s] #033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  54%|█████▍    | 172M/318M [00:05<00:08, 16.7MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  67%|██████▋   | 214M/318M [00:05<00:02, 40.6MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  70%|██████▉   | 222M/318M [00:03<00:01, 66.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  36%|███▌      | 113M/318M [00:05<00:09, 20.9MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  73%|███████▎  | 231M/318M [00:03<00:01, 65.9MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  70%|██████▉   | 222M/318M [00:05<00:02, 44.9MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  57%|█████▋    | 180M/318M [00:06<00:06, 21.2MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  38%|███▊      | 122M/318M [00:06<00:07, 25.8MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  75%|███████▌  | 239M/318M [00:04<00:01, 66.9MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  73%|███████▎  | 231M/318M [00:05<00:01, 48.3MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  41%|████      | 130M/318M [00:06<00:06, 30.4MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  78%|███████▊  | 247M/318M [00:04<00:01, 65.4MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  22%|██▏       | 71.3M/318M [00:05<00:34, 7.17MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  80%|████████  | 256M/318M [00:04<00:00, 64.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  43%|████▎     | 138M/318M [00:06<00:05, 32.7MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  83%|████████▎ | 264M/318M [00:04<00:00, 58.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  25%|██▌       | 79.7M/318M [00:06<00:25, 9.51MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  46%|████▌     | 147M/318M [00:06<00:04, 36.7MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  86%|████████▌ | 273M/318M [00:04<00:00, 60.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  28%|██▊       | 88.1M/318M [00:06<00:18, 12.6MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  88%|████████▊ | 281M/318M [00:04<00:00, 54.0MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  30%|███       | 96.5M/318M [00:06<00:13, 16.6MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  59%|█████▉    | 189M/318M [00:07<00:08, 15.1MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  91%|█████████ | 289M/318M [00:04<00:00, 58.3MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  33%|███▎      | 105M/318M [00:06<00:10, 21.2MB/s] #033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  62%|██████▏   | 197M/318M [00:07<00:06, 19.4MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  94%|█████████▎| 298M/318M [00:05<00:00, 59.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  75%|███████▌  | 239M/318M [00:07<00:04, 19.3MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  65%|██████▍   | 206M/318M [00:07<00:04, 22.6MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  78%|███████▊  | 247M/318M [00:07<00:02, 24.3MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  96%|█████████▋| 306M/318M [00:05<00:00, 47.2MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  36%|███▌      | 113M/318M [00:06<00:09, 21.1MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  67%|██████▋   | 214M/318M [00:07<00:03, 26.8MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  38%|███▊      | 122M/318M [00:07<00:07, 26.3MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  70%|██████▉   | 222M/318M [00:07<00:03, 31.8MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  49%|████▊     | 155M/318M [00:07<00:09, 16.5MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  73%|███████▎  | 231M/318M [00:07<00:02, 36.5MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  99%|█████████▉| 315M/318M [00:05<00:00, 33.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 318M/318M [00:05<00:00, 55.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:  51%|█████▏    | 164M/318M [00:07<00:07, 20.7MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  75%|███████▌  | 239M/318M [00:08<00:01, 40.2MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  54%|█████▍    | 172M/318M [00:08<00:05, 25.6MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  78%|███████▊  | 247M/318M [00:08<00:01, 44.6MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  57%|█████▋    | 180M/318M [00:08<00:04, 30.6MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  80%|████████  | 256M/318M [00:08<00:01, 47.5MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  80%|████████  | 256M/318M [00:08<00:04, 15.2MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  83%|████████▎ | 264M/318M [00:08<00:01, 48.2MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  59%|█████▉    | 189M/318M [00:08<00:04, 31.8MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  86%|████████▌ | 273M/318M [00:08<00:01, 44.0MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  62%|██████▏   | 197M/318M [00:08<00:03, 35.7MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  65%|██████▍   | 206M/318M [00:08<00:02, 40.3MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  88%|████████▊ | 281M/318M [00:08<00:00, 47.0MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  91%|█████████ | 289M/318M [00:09<00:00, 49.2MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  67%|██████▋   | 214M/318M [00:08<00:02, 42.4MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  70%|██████▉   | 222M/318M [00:09<00:02, 42.5MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  72%|███████▏  | 231M/318M [00:09<00:01, 45.9MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  41%|████      | 130M/318M [00:08<00:16, 11.1MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  75%|███████▌  | 239M/318M [00:09<00:01, 49.3MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  83%|████████▎ | 264M/318M [00:09<00:04, 11.6MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  43%|████▎     | 138M/318M [00:09<00:12, 14.3MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  78%|███████▊  | 247M/318M [00:09<00:01, 50.4MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  86%|████████▌ | 273M/318M [00:09<00:02, 15.3MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  80%|████████  | 256M/318M [00:09<00:01, 52.5MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  88%|████████▊ | 281M/318M [00:09<00:01, 19.1MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  46%|████▌     | 147M/318M [00:09<00:10, 17.1MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  94%|█████████▎| 298M/318M [00:10<00:01, 20.1MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  91%|█████████ | 289M/318M [00:09<00:01, 24.1MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  49%|████▊     | 155M/318M [00:09<00:07, 21.9MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  94%|█████████▎| 298M/318M [00:09<00:00, 28.7MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  51%|█████▏    | 164M/318M [00:09<00:06, 23.5MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  54%|█████▍    | 172M/318M [00:09<00:05, 28.0MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  57%|█████▋    | 180M/318M [00:10<00:04, 31.5MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  59%|█████▉    | 189M/318M [00:10<00:03, 36.7MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  83%|████████▎ | 264M/318M [00:10<00:02, 19.3MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  96%|█████████▌| 306M/318M [00:10<00:00, 14.6MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  86%|████████▌ | 273M/318M [00:10<00:01, 24.1MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  99%|█████████▉| 315M/318M [00:11<00:00, 18.1MB/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 318M/318M [00:11<00:00, 28.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:  88%|████████▊ | 281M/318M [00:11<00:01, 29.3MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  96%|█████████▌| 306M/318M [00:10<00:00, 16.5MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  91%|█████████ | 289M/318M [00:11<00:00, 34.8MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  99%|█████████▉| 315M/318M [00:11<00:00, 21.0MB/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 318M/318M [00:11<00:00, 28.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:  94%|█████████▎| 298M/318M [00:11<00:00, 38.5MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  96%|█████████▌| 306M/318M [00:11<00:00, 43.4MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  99%|█████████▉| 315M/318M [00:11<00:00, 48.2MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 318M/318M [00:11<00:00, 27.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:  62%|██████▏   | 197M/318M [00:11<00:06, 17.9MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  65%|██████▍   | 206M/318M [00:11<00:05, 22.2MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  67%|██████▋   | 214M/318M [00:11<00:03, 27.3MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  70%|██████▉   | 222M/318M [00:11<00:03, 27.6MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  72%|███████▏  | 231M/318M [00:12<00:02, 32.4MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  75%|███████▌  | 239M/318M [00:12<00:02, 36.6MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  78%|███████▊  | 247M/318M [00:12<00:01, 40.9MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  80%|████████  | 256M/318M [00:12<00:01, 42.9MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  83%|████████▎ | 264M/318M [00:13<00:02, 19.4MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  86%|████████▌ | 273M/318M [00:13<00:01, 24.2MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  88%|████████▊ | 281M/318M [00:13<00:01, 29.2MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  91%|█████████ | 289M/318M [00:14<00:01, 25.7MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  94%|█████████▎| 298M/318M [00:15<00:01, 15.8MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  96%|█████████▌| 306M/318M [00:15<00:00, 19.4MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  99%|█████████▉| 315M/318M [00:15<00:00, 23.1MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 318M/318M [00:15<00:00, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mSetting num_proc from 72 to 5 for the train split as it only contains 5 shards.\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 9093 examples [00:00, 71092.68 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 87573 examples [00:00, 437133.55 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 192101 examples [00:00, 676896.40 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 316168 examples [00:00, 840937.34 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 444240 examples [00:00, 913495.63 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 586503 examples [00:00, 1010836.37 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 723838 examples [00:00, 1108922.62 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 837727 examples [00:00, 1095052.34 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 956939 examples [00:01, 1080067.59 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1093626 examples [00:01, 1075685.09 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1239662 examples [00:01, 1103495.12 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1362429 examples [00:01, 1122110.81 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1503588 examples [00:01, 1121533.55 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1644914 examples [00:01, 1104411.74 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1758497 examples [00:01, 1110513.09 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1781587 examples [00:01, 980172.36 examples/s]\u001b[0m\n",
      "\u001b[34mdataset printing:DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'timestamp', 'url'],\n",
      "        num_rows: 1781587\n",
      "    })\u001b[0m\n",
      "\u001b[34m})\u001b[0m\n",
      "\u001b[34mcolumn names: ['text', 'timestamp', 'url']\u001b[0m\n",
      "\u001b[34mtext cloumn name identified: text\u001b[0m\n",
      "\u001b[34msample train rown:{'text': \"The Bicycle® brand celebrates North America's (US and Canada) craft brewing spirit. A spirit that captures the passion for their craft, signature look as well as product, and the entrepreneurial drive to turn a hobby into a business. Each of the 52 cards in the deck feature a unique logo. From all parts of the US and Canada, these 52 logos represent what we love most about craft beer!\", 'timestamp': datetime.datetime(2019, 4, 21, 4, 8, 7), 'url': 'http://www.playingcards.net/Bicycle-Craft-Beer-V2-Deck_p_3277.html'}\u001b[0m\n",
      "\u001b[34mtokenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json: 100%|██████████| 287/287 [00:00<00:00, 2.44MB/s]\u001b[0m\n",
      "\u001b[34mtokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer.json: 100%|██████████| 2.73M/2.73M [00:00<00:00, 7.55MB/s]\u001b[0m\n",
      "\u001b[34mtokenizer.json: 100%|██████████| 2.73M/2.73M [00:00<00:00, 7.52MB/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json: 100%|██████████| 281/281 [00:00<00:00, 3.02MB/s]\u001b[0m\n",
      "\u001b[34mcloumn names: ['text', 'timestamp', 'url']\u001b[0m\n",
      "\u001b[34msample train row again:{'text': \"The Bicycle® brand celebrates North America's (US and Canada) craft brewing spirit. A spirit that captures the passion for their craft, signature look as well as product, and the entrepreneurial drive to turn a hobby into a business. Each of the 52 cards in the deck feature a unique logo. From all parts of the US and Canada, these 52 logos represent what we love most about craft beer!\", 'timestamp': datetime.datetime(2019, 4, 21, 4, 8, 7), 'url': 'http://www.playingcards.net/Bicycle-Craft-Beer-V2-Deck_p_3277.html'}\u001b[0m\n",
      "\u001b[34mparallel_proc:72\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   0%|          | 0/1781587 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2788 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2290 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2055 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   0%|          | 1000/1781587 [00:01<57:05, 519.87 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (6082 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (11087 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   0%|          | 2000/1781587 [00:02<25:43, 1153.20 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3308 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2076 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   0%|          | 5000/1781587 [00:02<08:11, 3612.33 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (7353 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2218 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (6538 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   0%|          | 7000/1781587 [00:02<05:39, 5231.59 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4950 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3534 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2879 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2921 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   1%|          | 9000/1781587 [00:02<04:14, 6963.70 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4462 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3786 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2917 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2254 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3560 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   1%|          | 12000/1781587 [00:02<02:55, 10065.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   1%|          | 16000/1781587 [00:02<02:01, 14548.83 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2242 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2392 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   1%|          | 19000/1781587 [00:02<01:48, 16188.17 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2454 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3378 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   1%|          | 22000/1781587 [00:03<01:50, 15859.37 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2197 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2958 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2403 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2500 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3212 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2259 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2242 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   1%|▏         | 24000/1781587 [00:03<02:46, 10571.28 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (5268 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   2%|▏         | 28000/1781587 [00:03<01:58, 14760.45 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2399 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   2%|▏         | 31000/1781587 [00:03<01:55, 15184.37 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4741 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2421 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (6140 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   2%|▏         | 34000/1781587 [00:04<02:42, 10728.66 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2925 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   2%|▏         | 36000/1781587 [00:04<03:05, 9401.73 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3806 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3024 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2186 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4325 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   2%|▏         | 38000/1781587 [00:04<03:27, 8405.66 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2676 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (7213 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4005 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2243 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (6741 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   2%|▏         | 41000/1781587 [00:04<02:50, 10223.90 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2608 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2436 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   3%|▎         | 45000/1781587 [00:05<02:00, 14424.78 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2705 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3440 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   3%|▎         | 51000/1781587 [00:05<01:19, 21886.32 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3153 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3005 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   3%|▎         | 55000/1781587 [00:05<01:17, 22280.96 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3086 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (12221 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2558 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2098 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   3%|▎         | 58000/1781587 [00:05<01:28, 19546.31 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2068 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   4%|▎         | 63000/1781587 [00:05<01:08, 24940.79 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2584 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2960 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (12007 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   4%|▍         | 69000/1781587 [00:05<00:58, 29349.23 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2096 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   4%|▍         | 73000/1781587 [00:05<00:54, 31097.67 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4504 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   4%|▍         | 77000/1781587 [00:06<00:54, 31149.63 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4611 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2749 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2331 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3176 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3862 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (6803 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (4216 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2082 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   5%|▍         | 81000/1781587 [00:06<01:07, 25351.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   5%|▍         | 84000/1781587 [00:06<01:05, 26083.76 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3428 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   5%|▌         | 92000/1781587 [00:06<00:44, 38054.47 examples/s]\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2418 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (2228 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   5%|▌         | 97000/1781587 [00:06<00:59, 28284.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   6%|▌         | 101000/1781587 [00:06<01:03, 26320.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   6%|▌         | 105000/1781587 [00:07<01:23, 19971.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   6%|▌         | 108000/1781587 [00:07<01:42, 16355.94 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   6%|▌         | 111000/1781587 [00:07<02:05, 13350.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   6%|▋         | 114000/1781587 [00:08<02:00, 13845.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   7%|▋         | 117000/1781587 [00:08<01:45, 15799.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   7%|▋         | 120000/1781587 [00:08<01:32, 18042.75 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   7%|▋         | 123000/1781587 [00:08<01:22, 20017.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   7%|▋         | 130000/1781587 [00:08<00:56, 29158.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   8%|▊         | 134000/1781587 [00:08<01:02, 26422.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   8%|▊         | 140000/1781587 [00:09<01:00, 27332.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   8%|▊         | 144000/1781587 [00:09<01:04, 25522.84 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   8%|▊         | 147000/1781587 [00:09<01:10, 23306.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   8%|▊         | 150000/1781587 [00:09<01:08, 23839.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   9%|▊         | 155000/1781587 [00:09<01:00, 26694.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   9%|▉         | 160000/1781587 [00:09<00:53, 30463.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   9%|▉         | 164000/1781587 [00:09<00:54, 29864.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):   9%|▉         | 168000/1781587 [00:10<01:04, 24896.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  10%|▉         | 172000/1781587 [00:10<00:58, 27725.79 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  10%|▉         | 176000/1781587 [00:10<01:24, 18934.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  10%|█         | 179000/1781587 [00:10<01:28, 18111.07 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  10%|█         | 183000/1781587 [00:11<01:39, 16063.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  10%|█         | 186000/1781587 [00:11<01:37, 16384.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  11%|█         | 189000/1781587 [00:11<01:43, 15333.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  11%|█         | 193000/1781587 [00:11<01:27, 18141.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  11%|█         | 196000/1781587 [00:11<01:27, 18064.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  11%|█         | 200000/1781587 [00:11<01:11, 21981.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  11%|█▏        | 204000/1781587 [00:12<01:01, 25572.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  12%|█▏        | 208000/1781587 [00:12<00:57, 27163.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  12%|█▏        | 215000/1781587 [00:12<00:51, 30375.94 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  12%|█▏        | 219000/1781587 [00:12<01:04, 24371.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  13%|█▎        | 225000/1781587 [00:12<00:53, 28868.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  13%|█▎        | 229000/1781587 [00:12<01:00, 25579.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  13%|█▎        | 233000/1781587 [00:13<01:01, 25258.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  13%|█▎        | 237000/1781587 [00:13<01:03, 24450.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  13%|█▎        | 240000/1781587 [00:13<01:32, 16622.21 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  14%|█▎        | 244000/1781587 [00:13<01:16, 20031.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  14%|█▍        | 248000/1781587 [00:13<01:05, 23455.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  14%|█▍        | 251000/1781587 [00:14<01:18, 19584.68 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  14%|█▍        | 254000/1781587 [00:14<01:22, 18499.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  14%|█▍        | 257000/1781587 [00:14<01:26, 17538.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  15%|█▍        | 260000/1781587 [00:14<01:19, 19083.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  15%|█▍        | 263000/1781587 [00:14<01:28, 17156.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  15%|█▍        | 266000/1781587 [00:14<01:26, 17553.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  15%|█▌        | 270000/1781587 [00:15<01:11, 21155.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  15%|█▌        | 274000/1781587 [00:15<01:03, 23880.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  16%|█▌        | 278000/1781587 [00:15<00:57, 25930.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  16%|█▌        | 281000/1781587 [00:15<00:59, 25244.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  16%|█▌        | 285000/1781587 [00:15<00:54, 27313.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  16%|█▌        | 289000/1781587 [00:15<00:49, 30127.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  16%|█▋        | 293000/1781587 [00:15<00:52, 28239.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  17%|█▋        | 296000/1781587 [00:15<00:54, 27216.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  17%|█▋        | 300000/1781587 [00:16<01:03, 23206.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  17%|█▋        | 304000/1781587 [00:16<00:59, 25040.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  17%|█▋        | 307000/1781587 [00:16<01:05, 22459.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  17%|█▋        | 310000/1781587 [00:16<01:11, 20544.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  18%|█▊        | 313000/1781587 [00:16<01:29, 16334.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  18%|█▊        | 317000/1781587 [00:17<01:18, 18714.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  18%|█▊        | 320000/1781587 [00:17<01:17, 18889.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  18%|█▊        | 323000/1781587 [00:17<01:29, 16310.84 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  18%|█▊        | 326000/1781587 [00:17<01:25, 17049.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  18%|█▊        | 328000/1781587 [00:17<01:27, 16666.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  19%|█▊        | 333000/1781587 [00:17<01:02, 23149.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  19%|█▉        | 336000/1781587 [00:18<01:06, 21700.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  19%|█▉        | 339000/1781587 [00:18<01:06, 21701.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  19%|█▉        | 344000/1781587 [00:18<00:51, 27746.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  20%|█▉        | 348000/1781587 [00:18<01:01, 23370.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  20%|█▉        | 351000/1781587 [00:18<01:02, 22949.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  20%|█▉        | 356000/1781587 [00:18<00:50, 28439.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  20%|██        | 361000/1781587 [00:18<00:43, 32887.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  20%|██        | 365000/1781587 [00:19<00:42, 33041.96 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  21%|██        | 369000/1781587 [00:19<01:03, 22140.21 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  21%|██        | 372000/1781587 [00:19<01:10, 19905.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  21%|██        | 375000/1781587 [00:19<01:05, 21436.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  21%|██        | 378000/1781587 [00:19<01:09, 20256.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  21%|██▏       | 383000/1781587 [00:20<01:03, 22022.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  22%|██▏       | 386000/1781587 [00:20<01:05, 21158.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  22%|██▏       | 389000/1781587 [00:20<01:04, 21556.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  22%|██▏       | 392000/1781587 [00:20<01:05, 21243.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  22%|██▏       | 395000/1781587 [00:20<01:44, 13303.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  22%|██▏       | 398000/1781587 [00:21<01:30, 15328.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  22%|██▏       | 400000/1781587 [00:21<01:30, 15223.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  23%|██▎       | 402000/1781587 [00:21<01:31, 15136.94 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  23%|██▎       | 406000/1781587 [00:21<01:13, 18720.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  23%|██▎       | 410000/1781587 [00:21<01:09, 19627.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  23%|██▎       | 415000/1781587 [00:21<00:53, 25452.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  23%|██▎       | 418000/1781587 [00:21<00:57, 23650.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  24%|██▎       | 423000/1781587 [00:22<00:48, 28241.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  24%|██▍       | 427000/1781587 [00:22<00:50, 26682.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  24%|██▍       | 431000/1781587 [00:22<00:48, 28085.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  24%|██▍       | 435000/1781587 [00:22<00:46, 28948.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  25%|██▍       | 439000/1781587 [00:22<00:46, 28768.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  25%|██▍       | 442000/1781587 [00:22<00:47, 28406.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  25%|██▍       | 445000/1781587 [00:22<00:52, 25654.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  25%|██▌       | 450000/1781587 [00:22<00:46, 28630.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  25%|██▌       | 453000/1781587 [00:23<00:50, 26387.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  26%|██▌       | 456000/1781587 [00:23<01:01, 21591.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  26%|██▌       | 459000/1781587 [00:23<00:57, 22983.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  26%|██▌       | 462000/1781587 [00:23<01:00, 21835.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  26%|██▌       | 465000/1781587 [00:23<01:11, 18313.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  26%|██▌       | 467000/1781587 [00:23<01:15, 17316.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  26%|██▋       | 469000/1781587 [00:24<01:41, 12896.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  26%|██▋       | 471000/1781587 [00:24<01:47, 12201.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  27%|██▋       | 476000/1781587 [00:24<01:11, 18361.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  27%|██▋       | 479000/1781587 [00:24<01:13, 17688.91 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  27%|██▋       | 484000/1781587 [00:24<00:58, 22070.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  27%|██▋       | 488000/1781587 [00:24<00:50, 25576.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  28%|██▊       | 491000/1781587 [00:25<00:52, 24517.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  28%|██▊       | 494000/1781587 [00:25<01:04, 19883.07 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  28%|██▊       | 498000/1781587 [00:25<00:55, 22925.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  28%|██▊       | 501000/1781587 [00:25<00:58, 21952.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  28%|██▊       | 506000/1781587 [00:25<00:54, 23304.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  29%|██▊       | 511000/1781587 [00:25<00:45, 27764.12 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  29%|██▉       | 516000/1781587 [00:26<00:39, 32224.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  29%|██▉       | 520000/1781587 [00:26<00:50, 25018.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  29%|██▉       | 525000/1781587 [00:26<00:43, 29180.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  30%|██▉       | 529000/1781587 [00:26<00:51, 24494.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  30%|██▉       | 532000/1781587 [00:26<00:52, 23694.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  30%|███       | 535000/1781587 [00:26<01:01, 20152.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  30%|███       | 538000/1781587 [00:27<01:04, 19408.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  30%|███       | 541000/1781587 [00:27<01:19, 15604.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  31%|███       | 544000/1781587 [00:27<01:12, 16979.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  31%|███       | 548000/1781587 [00:27<01:08, 17992.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  31%|███       | 550000/1781587 [00:27<01:08, 17929.73 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  31%|███       | 553000/1781587 [00:28<01:06, 18389.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  31%|███       | 556000/1781587 [00:28<01:01, 19918.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  31%|███▏      | 559000/1781587 [00:28<01:00, 20315.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  32%|███▏      | 562000/1781587 [00:28<00:57, 21199.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  32%|███▏      | 565000/1781587 [00:28<01:07, 18046.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  32%|███▏      | 567000/1781587 [00:28<01:09, 17572.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  32%|███▏      | 575000/1781587 [00:28<00:40, 29809.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  32%|███▏      | 579000/1781587 [00:29<00:40, 29596.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  33%|███▎      | 583000/1781587 [00:29<00:38, 31112.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  33%|███▎      | 588000/1781587 [00:29<00:37, 32244.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  33%|███▎      | 592000/1781587 [00:29<00:40, 29136.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  33%|███▎      | 596000/1781587 [00:29<00:43, 26954.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  34%|███▎      | 599000/1781587 [00:29<00:49, 23921.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  34%|███▍      | 602000/1781587 [00:29<00:53, 22124.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  34%|███▍      | 605000/1781587 [00:30<00:58, 20207.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  34%|███▍      | 608000/1781587 [00:30<00:57, 20557.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  34%|███▍      | 611000/1781587 [00:30<01:04, 18039.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  35%|███▍      | 615000/1781587 [00:30<00:53, 21640.26 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  35%|███▍      | 618000/1781587 [00:30<01:04, 18004.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  35%|███▍      | 621000/1781587 [00:31<01:16, 15260.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  35%|███▌      | 624000/1781587 [00:31<01:09, 16659.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  35%|███▌      | 627000/1781587 [00:31<01:03, 18107.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  35%|███▌      | 631000/1781587 [00:31<00:51, 22312.56 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  36%|███▌      | 634000/1781587 [00:31<01:08, 16767.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  36%|███▌      | 640000/1781587 [00:31<00:46, 24539.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  36%|███▌      | 644000/1781587 [00:32<00:45, 25040.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  36%|███▋      | 648000/1781587 [00:32<00:50, 22574.79 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  37%|███▋      | 653000/1781587 [00:32<00:45, 24733.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  37%|███▋      | 659000/1781587 [00:32<00:37, 29924.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  37%|███▋      | 663000/1781587 [00:32<00:37, 29621.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  37%|███▋      | 667000/1781587 [00:32<00:40, 27240.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  38%|███▊      | 670000/1781587 [00:33<00:51, 21388.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  38%|███▊      | 673000/1781587 [00:33<00:56, 19652.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  38%|███▊      | 677000/1781587 [00:33<00:49, 22124.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  38%|███▊      | 680000/1781587 [00:33<00:49, 22089.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  38%|███▊      | 683000/1781587 [00:33<00:53, 20500.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  39%|███▊      | 686000/1781587 [00:33<00:52, 20985.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  39%|███▊      | 689000/1781587 [00:34<01:10, 15582.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  39%|███▉      | 694000/1781587 [00:34<00:59, 18173.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  39%|███▉      | 696000/1781587 [00:34<01:00, 17851.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  39%|███▉      | 700000/1781587 [00:34<00:54, 19670.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  39%|███▉      | 703000/1781587 [00:34<01:00, 17705.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  40%|███▉      | 706000/1781587 [00:35<00:56, 18912.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  40%|███▉      | 708000/1781587 [00:35<01:03, 16988.69 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  40%|████      | 713000/1781587 [00:35<00:46, 23163.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  40%|████      | 717000/1781587 [00:35<00:41, 25424.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  41%|████      | 722000/1781587 [00:35<00:35, 29540.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  41%|████      | 726000/1781587 [00:35<00:34, 30228.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  41%|████      | 731000/1781587 [00:35<00:34, 30073.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  41%|████▏     | 735000/1781587 [00:36<00:35, 29267.84 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  41%|████▏     | 738000/1781587 [00:36<00:40, 25978.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  42%|████▏     | 741000/1781587 [00:36<00:45, 23005.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  42%|████▏     | 744000/1781587 [00:36<00:45, 22637.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  42%|████▏     | 747000/1781587 [00:36<00:48, 21316.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  42%|████▏     | 750000/1781587 [00:36<01:03, 16335.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  42%|████▏     | 753000/1781587 [00:37<00:56, 18115.56 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  42%|████▏     | 757000/1781587 [00:37<00:52, 19620.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  43%|████▎     | 760000/1781587 [00:37<00:50, 20252.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  43%|████▎     | 763000/1781587 [00:37<00:47, 21248.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  43%|████▎     | 766000/1781587 [00:37<00:52, 19456.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  43%|████▎     | 770000/1781587 [00:38<00:59, 17121.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  43%|████▎     | 772000/1781587 [00:38<01:00, 16672.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  43%|████▎     | 774000/1781587 [00:38<00:59, 16953.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  44%|████▎     | 779000/1781587 [00:38<00:43, 23254.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  44%|████▍     | 783000/1781587 [00:38<00:38, 26123.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  44%|████▍     | 787000/1781587 [00:38<00:35, 27814.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  44%|████▍     | 791000/1781587 [00:38<00:32, 30353.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  45%|████▍     | 795000/1781587 [00:38<00:39, 25227.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  45%|████▍     | 799000/1781587 [00:39<00:34, 28146.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  45%|████▌     | 803000/1781587 [00:39<00:40, 24126.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  45%|████▌     | 806000/1781587 [00:39<00:38, 25049.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  46%|████▌     | 811000/1781587 [00:39<00:34, 27743.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  46%|████▌     | 814000/1781587 [00:39<00:44, 21869.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  46%|████▌     | 817000/1781587 [00:39<00:49, 19309.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  46%|████▌     | 820000/1781587 [00:40<00:53, 17918.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  46%|████▌     | 823000/1781587 [00:40<00:50, 18979.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  46%|████▋     | 826000/1781587 [00:40<00:56, 16989.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  46%|████▋     | 828000/1781587 [00:40<01:00, 15842.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  47%|████▋     | 832000/1781587 [00:40<00:52, 18019.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  47%|████▋     | 835000/1781587 [00:40<00:50, 18931.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  47%|████▋     | 837000/1781587 [00:41<00:54, 17348.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  47%|████▋     | 840000/1781587 [00:41<00:47, 20005.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  47%|████▋     | 846000/1781587 [00:41<00:34, 27160.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  48%|████▊     | 849000/1781587 [00:41<00:35, 26082.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  48%|████▊     | 854000/1781587 [00:41<00:33, 28033.79 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  48%|████▊     | 858000/1781587 [00:41<00:30, 30557.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  48%|████▊     | 863000/1781587 [00:41<00:29, 30948.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  49%|████▊     | 867000/1781587 [00:42<00:40, 22683.77 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  49%|████▉     | 871000/1781587 [00:42<00:37, 24217.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  49%|████▉     | 874000/1781587 [00:42<00:39, 22690.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  49%|████▉     | 879000/1781587 [00:42<00:33, 26706.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  50%|████▉     | 883000/1781587 [00:42<00:33, 26704.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  50%|████▉     | 886000/1781587 [00:42<00:39, 22771.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  50%|████▉     | 889000/1781587 [00:43<00:49, 17950.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  50%|█████     | 893000/1781587 [00:43<00:45, 19364.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  50%|█████     | 896000/1781587 [00:43<00:42, 20606.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  50%|█████     | 899000/1781587 [00:43<00:54, 16051.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  51%|█████     | 901000/1781587 [00:43<00:56, 15512.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  51%|█████     | 904000/1781587 [00:44<00:53, 16555.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  51%|█████     | 907000/1781587 [00:44<00:49, 17734.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  51%|█████     | 911000/1781587 [00:44<00:39, 22214.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  51%|█████▏    | 914000/1781587 [00:44<00:38, 22615.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  52%|█████▏    | 921000/1781587 [00:44<00:31, 27565.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  52%|█████▏    | 926000/1781587 [00:44<00:26, 32131.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  52%|█████▏    | 930000/1781587 [00:44<00:25, 32833.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  52%|█████▏    | 934000/1781587 [00:45<00:29, 28463.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  53%|█████▎    | 938000/1781587 [00:45<00:35, 23924.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  53%|█████▎    | 941000/1781587 [00:45<00:39, 21351.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  53%|█████▎    | 944000/1781587 [00:45<00:37, 22606.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  53%|█████▎    | 947000/1781587 [00:45<00:34, 23863.94 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  53%|█████▎    | 951000/1781587 [00:45<00:30, 27370.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  54%|█████▎    | 954000/1781587 [00:46<00:37, 22329.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  54%|█████▍    | 958000/1781587 [00:46<00:37, 22113.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  54%|█████▍    | 961000/1781587 [00:46<00:43, 18902.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  54%|█████▍    | 964000/1781587 [00:46<00:46, 17437.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  54%|█████▍    | 967000/1781587 [00:46<00:42, 19225.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  54%|█████▍    | 970000/1781587 [00:46<00:47, 17102.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  55%|█████▍    | 973000/1781587 [00:47<00:55, 14524.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  55%|█████▍    | 976000/1781587 [00:47<00:47, 17096.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  55%|█████▍    | 979000/1781587 [00:47<00:43, 18373.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  55%|█████▌    | 982000/1781587 [00:47<00:39, 20023.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  55%|█████▌    | 985000/1781587 [00:47<00:42, 18858.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  56%|█████▌    | 990000/1781587 [00:47<00:32, 24056.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  56%|█████▌    | 993000/1781587 [00:48<00:34, 23010.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  56%|█████▌    | 999000/1781587 [00:48<00:26, 29568.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  56%|█████▋    | 1004000/1781587 [00:48<00:24, 32344.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  57%|█████▋    | 1008000/1781587 [00:48<00:26, 29248.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  57%|█████▋    | 1013000/1781587 [00:48<00:22, 33562.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  57%|█████▋    | 1017000/1781587 [00:48<00:27, 28193.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  57%|█████▋    | 1021000/1781587 [00:48<00:26, 28344.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  58%|█████▊    | 1025000/1781587 [00:49<00:38, 19686.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  58%|█████▊    | 1028000/1781587 [00:49<00:46, 16062.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  58%|█████▊    | 1031000/1781587 [00:49<00:46, 16058.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  58%|█████▊    | 1034000/1781587 [00:49<00:43, 17028.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  58%|█████▊    | 1039000/1781587 [00:50<00:36, 20565.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  58%|█████▊    | 1042000/1781587 [00:50<00:44, 16647.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  59%|█████▊    | 1044000/1781587 [00:50<00:47, 15368.91 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  59%|█████▊    | 1046000/1781587 [00:50<00:48, 15200.07 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  59%|█████▉    | 1051000/1781587 [00:50<00:36, 20131.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  59%|█████▉    | 1054000/1781587 [00:50<00:34, 20879.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  59%|█████▉    | 1057000/1781587 [00:51<00:39, 18129.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  59%|█████▉    | 1060000/1781587 [00:51<00:36, 19773.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  60%|█████▉    | 1065000/1781587 [00:51<00:31, 22875.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  60%|██████    | 1069000/1781587 [00:51<00:28, 25284.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  60%|██████    | 1075000/1781587 [00:51<00:23, 29906.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  61%|██████    | 1079000/1781587 [00:51<00:23, 29949.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  61%|██████    | 1083000/1781587 [00:51<00:22, 31479.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  61%|██████    | 1087000/1781587 [00:52<00:23, 29832.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  61%|██████    | 1091000/1781587 [00:52<00:26, 26416.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  61%|██████▏   | 1094000/1781587 [00:52<00:34, 19723.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  62%|██████▏   | 1097000/1781587 [00:52<00:40, 17004.11 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  62%|██████▏   | 1099000/1781587 [00:52<00:41, 16422.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  62%|██████▏   | 1102000/1781587 [00:53<00:38, 17745.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  62%|██████▏   | 1105000/1781587 [00:53<00:34, 19582.54 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  62%|██████▏   | 1110000/1781587 [00:53<00:27, 24390.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  62%|██████▏   | 1113000/1781587 [00:53<00:34, 19519.40 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  63%|██████▎   | 1116000/1781587 [00:53<00:41, 16047.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  63%|██████▎   | 1119000/1781587 [00:53<00:36, 18319.95 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  63%|██████▎   | 1123000/1781587 [00:54<00:31, 21226.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  63%|██████▎   | 1128000/1781587 [00:54<00:24, 26860.80 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  64%|██████▎   | 1132000/1781587 [00:54<00:34, 18984.47 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  64%|██████▍   | 1138000/1781587 [00:54<00:25, 25713.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  64%|██████▍   | 1143000/1781587 [00:54<00:23, 27500.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  64%|██████▍   | 1147000/1781587 [00:55<00:23, 27049.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  65%|██████▍   | 1151000/1781587 [00:55<00:24, 26162.78 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  65%|██████▍   | 1154000/1781587 [00:55<00:24, 25826.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  65%|██████▍   | 1158000/1781587 [00:55<00:25, 24860.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  65%|██████▌   | 1163000/1781587 [00:55<00:22, 27486.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  65%|██████▌   | 1166000/1781587 [00:55<00:25, 23882.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  66%|██████▌   | 1169000/1781587 [00:56<00:31, 19744.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  66%|██████▌   | 1172000/1781587 [00:56<00:28, 21109.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  66%|██████▌   | 1175000/1781587 [00:56<00:31, 19367.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  66%|██████▌   | 1178000/1781587 [00:56<00:32, 18619.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  66%|██████▋   | 1181000/1781587 [00:56<00:32, 18472.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  66%|██████▋   | 1183000/1781587 [00:56<00:37, 16112.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  67%|██████▋   | 1185000/1781587 [00:57<00:40, 14813.71 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  67%|██████▋   | 1191000/1781587 [00:57<00:25, 23301.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  67%|██████▋   | 1194000/1781587 [00:57<00:23, 24522.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  67%|██████▋   | 1197000/1781587 [00:57<00:23, 24917.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  67%|██████▋   | 1200000/1781587 [00:57<00:31, 18684.13 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  68%|██████▊   | 1203000/1781587 [00:57<00:29, 19624.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  68%|██████▊   | 1206000/1781587 [00:57<00:28, 20545.94 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  68%|██████▊   | 1209000/1781587 [00:58<00:26, 21250.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  68%|██████▊   | 1215000/1781587 [00:58<00:19, 29698.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  68%|██████▊   | 1219000/1781587 [00:58<00:20, 28000.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  69%|██████▊   | 1223000/1781587 [00:58<00:19, 28795.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  69%|██████▉   | 1227000/1781587 [00:58<00:24, 22839.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  69%|██████▉   | 1230000/1781587 [00:58<00:24, 22895.94 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  69%|██████▉   | 1233000/1781587 [00:59<00:32, 17008.31 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  69%|██████▉   | 1236000/1781587 [00:59<00:33, 16202.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  70%|██████▉   | 1242000/1781587 [00:59<00:22, 23743.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  70%|██████▉   | 1246000/1781587 [00:59<00:22, 23947.48 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  70%|███████   | 1250000/1781587 [00:59<00:19, 26889.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  70%|███████   | 1254000/1781587 [01:00<00:28, 18623.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  71%|███████   | 1257000/1781587 [01:00<00:25, 20194.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  71%|███████   | 1260000/1781587 [01:00<00:30, 16941.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  71%|███████   | 1264000/1781587 [01:00<00:28, 18304.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  71%|███████▏  | 1272000/1781587 [01:00<00:17, 29179.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  72%|███████▏  | 1276000/1781587 [01:01<00:22, 22111.94 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  72%|███████▏  | 1280000/1781587 [01:01<00:20, 24059.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  72%|███████▏  | 1284000/1781587 [01:01<00:21, 23285.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  72%|███████▏  | 1288000/1781587 [01:01<00:18, 26043.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  73%|███████▎  | 1292000/1781587 [01:01<00:18, 26948.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  73%|███████▎  | 1296000/1781587 [01:01<00:23, 20585.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  73%|███████▎  | 1301000/1781587 [01:02<00:22, 21660.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  73%|███████▎  | 1304000/1781587 [01:02<00:26, 18171.94 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  73%|███████▎  | 1307000/1781587 [01:02<00:25, 18640.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  74%|███████▎  | 1310000/1781587 [01:02<00:22, 20624.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  74%|███████▎  | 1313000/1781587 [01:02<00:22, 21081.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  74%|███████▍  | 1317000/1781587 [01:02<00:18, 25034.41 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  74%|███████▍  | 1320000/1781587 [01:02<00:20, 22448.68 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  74%|███████▍  | 1325000/1781587 [01:03<00:19, 23148.93 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  75%|███████▍  | 1328000/1781587 [01:03<00:24, 18346.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  75%|███████▍  | 1332000/1781587 [01:03<00:22, 20126.91 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  75%|███████▍  | 1335000/1781587 [01:03<00:22, 20046.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  75%|███████▌  | 1338000/1781587 [01:04<00:28, 15553.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  75%|███████▌  | 1341000/1781587 [01:04<00:24, 17916.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  76%|███████▌  | 1347000/1781587 [01:04<00:17, 24853.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  76%|███████▌  | 1353000/1781587 [01:04<00:13, 31249.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  76%|███████▋  | 1360000/1781587 [01:04<00:10, 39429.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  77%|███████▋  | 1365000/1781587 [01:04<00:14, 29002.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  77%|███████▋  | 1369000/1781587 [01:05<00:16, 24959.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  77%|███████▋  | 1373000/1781587 [01:05<00:21, 18966.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  77%|███████▋  | 1376000/1781587 [01:05<00:19, 20315.61 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  77%|███████▋  | 1379000/1781587 [01:05<00:24, 16330.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  78%|███████▊  | 1384000/1781587 [01:05<00:18, 21483.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  78%|███████▊  | 1390000/1781587 [01:06<00:14, 26170.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  78%|███████▊  | 1394000/1781587 [01:06<00:21, 18341.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  78%|███████▊  | 1397000/1781587 [01:06<00:22, 17168.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  79%|███████▊  | 1400000/1781587 [01:06<00:20, 18792.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  79%|███████▉  | 1403000/1781587 [01:06<00:21, 17619.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  79%|███████▉  | 1409000/1781587 [01:07<00:16, 22519.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  79%|███████▉  | 1412000/1781587 [01:07<00:15, 23869.52 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  79%|███████▉  | 1416000/1781587 [01:07<00:14, 24451.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  80%|███████▉  | 1421000/1781587 [01:07<00:12, 28294.19 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  80%|███████▉  | 1425000/1781587 [01:07<00:12, 28406.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  80%|████████  | 1429000/1781587 [01:07<00:12, 27565.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  80%|████████  | 1432000/1781587 [01:07<00:12, 27069.96 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  81%|████████  | 1435000/1781587 [01:08<00:13, 25620.42 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  81%|████████  | 1438000/1781587 [01:08<00:16, 20622.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  81%|████████  | 1441000/1781587 [01:08<00:15, 21446.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  81%|████████  | 1444000/1781587 [01:08<00:17, 19556.07 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  81%|████████▏ | 1448000/1781587 [01:08<00:14, 22614.51 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  81%|████████▏ | 1451000/1781587 [01:08<00:15, 21139.84 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  82%|████████▏ | 1454000/1781587 [01:09<00:14, 22551.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  82%|████████▏ | 1457000/1781587 [01:09<00:15, 20898.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  82%|████████▏ | 1461000/1781587 [01:09<00:16, 19653.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  82%|████████▏ | 1464000/1781587 [01:09<00:17, 18136.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  82%|████████▏ | 1467000/1781587 [01:09<00:16, 19344.68 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  83%|████████▎ | 1470000/1781587 [01:09<00:15, 20673.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  83%|████████▎ | 1473000/1781587 [01:10<00:15, 19525.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  83%|████████▎ | 1476000/1781587 [01:10<00:15, 20136.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  83%|████████▎ | 1479000/1781587 [01:10<00:15, 20068.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  83%|████████▎ | 1484000/1781587 [01:10<00:11, 25273.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  83%|████████▎ | 1487000/1781587 [01:10<00:12, 22861.76 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  84%|████████▎ | 1491000/1781587 [01:10<00:11, 26410.18 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  84%|████████▍ | 1494000/1781587 [01:10<00:12, 22737.94 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  84%|████████▍ | 1501000/1781587 [01:11<00:09, 29118.53 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  84%|████████▍ | 1505000/1781587 [01:11<00:10, 26704.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  85%|████████▍ | 1508000/1781587 [01:11<00:10, 25905.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  85%|████████▍ | 1511000/1781587 [01:11<00:15, 17384.22 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  85%|████████▌ | 1516000/1781587 [01:11<00:12, 21797.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  85%|████████▌ | 1522000/1781587 [01:11<00:09, 27655.89 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  86%|████████▌ | 1526000/1781587 [01:12<00:08, 28946.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  86%|████████▌ | 1530000/1781587 [01:12<00:09, 25864.21 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  86%|████████▌ | 1533000/1781587 [01:12<00:12, 20090.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  86%|████████▌ | 1536000/1781587 [01:12<00:13, 18458.09 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  86%|████████▋ | 1539000/1781587 [01:13<00:14, 16328.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  87%|████████▋ | 1542000/1781587 [01:13<00:14, 16300.00 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  87%|████████▋ | 1544000/1781587 [01:13<00:14, 16735.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  87%|████████▋ | 1548000/1781587 [01:13<00:11, 19553.83 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  87%|████████▋ | 1552000/1781587 [01:13<00:09, 23701.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  87%|████████▋ | 1556000/1781587 [01:13<00:08, 25318.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  88%|████████▊ | 1559000/1781587 [01:13<00:08, 25330.64 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  88%|████████▊ | 1563000/1781587 [01:13<00:08, 27058.65 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  88%|████████▊ | 1566000/1781587 [01:14<00:10, 21346.96 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  88%|████████▊ | 1569000/1781587 [01:14<00:09, 21895.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  88%|████████▊ | 1572000/1781587 [01:14<00:09, 21980.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  89%|████████▊ | 1576745/1781587 [01:14<00:08, 24092.39 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  89%|████████▊ | 1579745/1781587 [01:14<00:09, 20960.91 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  89%|████████▉ | 1584745/1781587 [01:14<00:08, 24069.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  89%|████████▉ | 1587745/1781587 [01:15<00:07, 24916.17 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  89%|████████▉ | 1592745/1781587 [01:15<00:06, 28270.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  90%|████████▉ | 1595745/1781587 [01:15<00:07, 24329.85 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  90%|████████▉ | 1598745/1781587 [01:15<00:07, 23417.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  90%|████████▉ | 1601745/1781587 [01:15<00:07, 22776.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  90%|█████████ | 1604745/1781587 [01:15<00:09, 19243.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  90%|█████████ | 1607745/1781587 [01:16<00:10, 16515.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  90%|█████████ | 1609745/1781587 [01:16<00:11, 14764.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  90%|█████████ | 1611745/1781587 [01:16<00:12, 14103.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  91%|█████████ | 1617745/1781587 [01:16<00:08, 19758.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  91%|█████████ | 1621745/1781587 [01:16<00:06, 23243.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  91%|█████████▏| 1625745/1781587 [01:16<00:06, 25854.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  91%|█████████▏| 1628745/1781587 [01:16<00:05, 26050.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  92%|█████████▏| 1631745/1781587 [01:17<00:05, 25550.27 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  92%|█████████▏| 1636235/1781587 [01:17<00:05, 27159.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  92%|█████████▏| 1639235/1781587 [01:17<00:07, 19011.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  92%|█████████▏| 1643235/1781587 [01:17<00:06, 22830.08 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  92%|█████████▏| 1646235/1781587 [01:17<00:06, 22426.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  93%|█████████▎| 1649235/1781587 [01:17<00:05, 23350.82 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  93%|█████████▎| 1653980/1781587 [01:18<00:04, 27307.75 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  93%|█████████▎| 1657468/1781587 [01:18<00:05, 23124.62 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  93%|█████████▎| 1662213/1781587 [01:18<00:04, 27085.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  93%|█████████▎| 1665213/1781587 [01:18<00:04, 24278.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  94%|█████████▎| 1668958/1781587 [01:18<00:05, 21774.14 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  94%|█████████▍| 1671447/1781587 [01:18<00:05, 20165.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  94%|█████████▍| 1675192/1781587 [01:18<00:04, 23095.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  94%|█████████▍| 1678681/1781587 [01:19<00:05, 19593.23 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  94%|█████████▍| 1682169/1781587 [01:19<00:04, 22313.99 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  95%|█████████▍| 1685657/1781587 [01:19<00:04, 21403.35 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  95%|█████████▍| 1689890/1781587 [01:19<00:03, 23649.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  95%|█████████▌| 1694380/1781587 [01:19<00:03, 25887.05 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  95%|█████████▌| 1698125/1781587 [01:19<00:02, 28093.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  95%|█████████▌| 1701125/1781587 [01:20<00:02, 26921.72 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  96%|█████████▌| 1704614/1781587 [01:20<00:02, 28384.67 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  96%|█████████▌| 1708102/1781587 [01:20<00:03, 19392.73 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  96%|█████████▌| 1711846/1781587 [01:20<00:03, 21288.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  96%|█████████▋| 1717846/1781587 [01:20<00:02, 25397.66 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  97%|█████████▋| 1721334/1781587 [01:20<00:02, 23930.20 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  97%|█████████▋| 1724822/1781587 [01:21<00:02, 23336.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  97%|█████████▋| 1729566/1781587 [01:21<00:01, 27479.24 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  97%|█████████▋| 1733054/1781587 [01:21<00:01, 28516.81 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  97%|█████████▋| 1736542/1781587 [01:21<00:01, 25606.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  98%|█████████▊| 1741263/1781587 [01:21<00:01, 26945.43 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  98%|█████████▊| 1744495/1781587 [01:21<00:01, 26220.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  98%|█████████▊| 1747727/1781587 [01:22<00:01, 21955.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  98%|█████████▊| 1750704/1781587 [01:22<00:01, 18652.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  98%|█████████▊| 1753448/1781587 [01:22<00:01, 16224.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  99%|█████████▊| 1757168/1781587 [01:22<00:01, 16451.02 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  99%|█████████▉| 1762144/1781587 [01:22<00:01, 17567.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  99%|█████████▉| 1764888/1781587 [01:23<00:01, 12965.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  99%|█████████▉| 1766888/1781587 [01:23<00:01, 12434.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  99%|█████████▉| 1768633/1781587 [01:23<00:01, 10273.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  99%|█████████▉| 1770633/1781587 [01:24<00:01, 5994.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72):  99%|█████████▉| 1771633/1781587 [01:24<00:01, 6011.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72): 100%|█████████▉| 1773377/1781587 [01:25<00:01, 6000.59 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72): 100%|█████████▉| 1776121/1781587 [01:25<00:00, 7637.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72): 100%|█████████▉| 1777610/1781587 [01:26<00:00, 4432.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72): 100%|█████████▉| 1779098/1781587 [01:26<00:00, 4621.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72): 100%|█████████▉| 1780843/1781587 [01:26<00:00, 4151.74 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72): 100%|██████████| 1781587/1781587 [01:28<00:00, 2152.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset (num_proc=72): 100%|██████████| 1781587/1781587 [01:28<00:00, 20198.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):   0%|          | 0/1781587 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):   0%|          | 1000/1781587 [00:00<24:14, 1224.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):   1%|          | 14000/1781587 [00:00<01:26, 20392.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):   2%|▏         | 38000/1781587 [00:01<00:29, 58799.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):   4%|▎         | 65000/1781587 [00:01<00:17, 98662.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):   5%|▍         | 84000/1781587 [00:01<00:31, 53742.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):   6%|▌         | 111000/1781587 [00:01<00:20, 79741.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):   7%|▋         | 132000/1781587 [00:01<00:16, 98683.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):   8%|▊         | 151000/1781587 [00:02<00:27, 59689.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  10%|▉         | 170000/1781587 [00:02<00:21, 74579.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  11%|█         | 194000/1781587 [00:02<00:16, 97274.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  12%|█▏        | 212000/1781587 [00:03<00:16, 96215.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  13%|█▎        | 227000/1781587 [00:03<00:25, 61636.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  14%|█▍        | 249000/1781587 [00:03<00:18, 81049.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  15%|█▌        | 268000/1781587 [00:03<00:15, 95984.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  16%|█▌        | 284000/1781587 [00:03<00:15, 96612.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  17%|█▋        | 298000/1781587 [00:04<00:23, 62107.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  17%|█▋        | 311000/1781587 [00:04<00:20, 71167.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  19%|█▊        | 333000/1781587 [00:04<00:15, 92305.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  20%|█▉        | 348000/1781587 [00:04<00:14, 96808.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  20%|██        | 361000/1781587 [00:05<00:22, 64365.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  21%|██        | 371000/1781587 [00:05<00:21, 65209.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  22%|██▏       | 389000/1781587 [00:05<00:16, 83483.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  23%|██▎       | 409000/1781587 [00:05<00:13, 103450.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  24%|██▎       | 423000/1781587 [00:05<00:14, 93247.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  24%|██▍       | 435000/1781587 [00:06<00:21, 63340.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  25%|██▍       | 445000/1781587 [00:06<00:19, 67917.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  26%|██▌       | 466000/1781587 [00:06<00:14, 92592.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  27%|██▋       | 480000/1781587 [00:06<00:12, 101630.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  28%|██▊       | 493000/1781587 [00:06<00:12, 101331.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  28%|██▊       | 505000/1781587 [00:06<00:20, 63529.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  29%|██▉       | 515000/1781587 [00:07<00:19, 63823.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  30%|██▉       | 534000/1781587 [00:07<00:14, 86191.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  31%|███       | 551000/1781587 [00:07<00:11, 103062.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  32%|███▏      | 565000/1781587 [00:07<00:12, 99758.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  32%|███▏      | 577000/1781587 [00:07<00:18, 63711.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  33%|███▎      | 587000/1781587 [00:07<00:18, 64010.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  34%|███▍      | 608000/1781587 [00:08<00:13, 89033.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  35%|███▍      | 622000/1781587 [00:08<00:11, 98978.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  36%|███▌      | 635000/1781587 [00:08<00:12, 90826.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  36%|███▋      | 646000/1781587 [00:08<00:16, 66869.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  37%|███▋      | 655000/1781587 [00:08<00:16, 68206.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  37%|███▋      | 664000/1781587 [00:08<00:15, 70088.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  39%|███▊      | 686000/1781587 [00:08<00:10, 100172.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  39%|███▉      | 698000/1781587 [00:09<00:11, 93947.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  40%|███▉      | 709000/1781587 [00:09<00:11, 93430.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  40%|████      | 720000/1781587 [00:09<00:16, 62765.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  41%|████      | 730000/1781587 [00:09<00:15, 67755.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  42%|████▏     | 744000/1781587 [00:09<00:12, 81538.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  43%|████▎     | 760000/1781587 [00:09<00:10, 95035.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  43%|████▎     | 772000/1781587 [00:10<00:10, 100347.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  44%|████▍     | 784000/1781587 [00:10<00:11, 83686.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  45%|████▍     | 794000/1781587 [00:10<00:15, 65491.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  45%|████▌     | 803000/1781587 [00:10<00:14, 68590.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  46%|████▌     | 819000/1781587 [00:10<00:11, 86981.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  47%|████▋     | 832000/1781587 [00:10<00:09, 96641.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  47%|████▋     | 843000/1781587 [00:10<00:09, 97117.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  48%|████▊     | 854000/1781587 [00:11<00:12, 75621.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  48%|████▊     | 863000/1781587 [00:11<00:13, 68867.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  49%|████▉     | 871000/1781587 [00:11<00:12, 71094.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  49%|████▉     | 880000/1781587 [00:11<00:12, 74310.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  50%|█████     | 893000/1781587 [00:11<00:10, 86684.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  51%|█████     | 906000/1781587 [00:11<00:09, 96561.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  51%|█████▏    | 917000/1781587 [00:11<00:08, 96220.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  52%|█████▏    | 928000/1781587 [00:12<00:11, 72790.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  53%|█████▎    | 937000/1781587 [00:12<00:12, 69037.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  53%|█████▎    | 949000/1781587 [00:12<00:10, 78802.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  54%|█████▍    | 958000/1781587 [00:12<00:10, 77792.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  55%|█████▍    | 972000/1781587 [00:12<00:08, 91612.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  55%|█████▌    | 984000/1781587 [00:12<00:08, 98331.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  56%|█████▌    | 995000/1781587 [00:12<00:09, 84230.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  56%|█████▋    | 1005000/1781587 [00:13<00:11, 70292.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  57%|█████▋    | 1013000/1781587 [00:13<00:11, 68046.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  57%|█████▋    | 1023000/1781587 [00:13<00:10, 73319.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  58%|█████▊    | 1037000/1781587 [00:13<00:08, 86634.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  59%|█████▉    | 1052000/1781587 [00:13<00:07, 102028.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  60%|█████▉    | 1063000/1781587 [00:13<00:08, 89019.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  60%|██████    | 1073000/1781587 [00:13<00:08, 78751.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  61%|██████    | 1082000/1781587 [00:14<00:10, 67445.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  61%|██████▏   | 1092000/1781587 [00:14<00:09, 71945.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  62%|██████▏   | 1104000/1781587 [00:14<00:08, 80547.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  63%|██████▎   | 1120000/1781587 [00:14<00:06, 98734.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  63%|██████▎   | 1131000/1781587 [00:14<00:07, 87587.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  64%|██████▍   | 1141000/1781587 [00:14<00:08, 79760.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  65%|██████▍   | 1150000/1781587 [00:14<00:08, 72513.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  65%|██████▍   | 1158000/1781587 [00:14<00:08, 71561.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  65%|██████▌   | 1166000/1781587 [00:15<00:08, 70790.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  66%|██████▋   | 1182000/1781587 [00:15<00:06, 91742.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  67%|██████▋   | 1194000/1781587 [00:15<00:05, 98677.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  68%|██████▊   | 1205000/1781587 [00:15<00:07, 81323.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  68%|██████▊   | 1214000/1781587 [00:15<00:07, 76672.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  69%|██████▊   | 1223000/1781587 [00:15<00:07, 70822.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  69%|██████▉   | 1233000/1781587 [00:15<00:07, 75311.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  70%|██████▉   | 1243000/1781587 [00:15<00:06, 80778.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  70%|███████   | 1256000/1781587 [00:16<00:05, 92384.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  71%|███████   | 1266000/1781587 [00:16<00:05, 87192.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  72%|███████▏  | 1276000/1781587 [00:16<00:06, 82253.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  72%|███████▏  | 1286000/1781587 [00:16<00:05, 85665.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  73%|███████▎  | 1295000/1781587 [00:16<00:07, 67052.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  73%|███████▎  | 1307000/1781587 [00:16<00:06, 78543.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  74%|███████▍  | 1317000/1781587 [00:16<00:05, 83405.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  75%|███████▍  | 1328000/1781587 [00:16<00:05, 84580.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  75%|███████▌  | 1338000/1781587 [00:17<00:05, 87355.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  76%|███████▌  | 1348000/1781587 [00:17<00:04, 86763.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  76%|███████▌  | 1357000/1781587 [00:17<00:05, 74845.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  77%|███████▋  | 1365000/1781587 [00:17<00:05, 72313.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  77%|███████▋  | 1376000/1781587 [00:17<00:05, 78292.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  78%|███████▊  | 1385000/1781587 [00:17<00:04, 79589.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  78%|███████▊  | 1396000/1781587 [00:17<00:04, 87065.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  79%|███████▉  | 1405000/1781587 [00:17<00:04, 87673.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  79%|███████▉  | 1414000/1781587 [00:18<00:04, 82374.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  80%|███████▉  | 1425000/1781587 [00:18<00:04, 86912.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  80%|████████  | 1434000/1781587 [00:18<00:04, 75558.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  81%|████████  | 1443000/1781587 [00:18<00:04, 74703.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  82%|████████▏ | 1454000/1781587 [00:18<00:04, 81139.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  82%|████████▏ | 1465000/1781587 [00:18<00:03, 87146.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  83%|████████▎ | 1474000/1781587 [00:18<00:03, 81861.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  83%|████████▎ | 1483000/1781587 [00:18<00:03, 77970.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  84%|████████▍ | 1495000/1781587 [00:19<00:03, 82634.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  84%|████████▍ | 1505000/1781587 [00:19<00:03, 81885.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  85%|████████▍ | 1514000/1781587 [00:19<00:03, 76692.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  86%|████████▌ | 1527000/1781587 [00:19<00:02, 89403.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  86%|████████▋ | 1537000/1781587 [00:19<00:02, 81902.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  87%|████████▋ | 1546000/1781587 [00:19<00:03, 76713.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  87%|████████▋ | 1555000/1781587 [00:19<00:02, 79587.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  88%|████████▊ | 1567000/1781587 [00:19<00:02, 86945.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  88%|████████▊ | 1576000/1781587 [00:20<00:02, 72719.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  89%|████████▉ | 1584000/1781587 [00:20<00:02, 74103.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  90%|████████▉ | 1599000/1781587 [00:20<00:02, 90645.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  90%|█████████ | 1609000/1781587 [00:20<00:02, 82919.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  91%|█████████ | 1618000/1781587 [00:20<00:01, 82458.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  91%|█████████▏| 1627000/1781587 [00:20<00:02, 76993.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  92%|█████████▏| 1637000/1781587 [00:20<00:01, 81049.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  92%|█████████▏| 1646000/1781587 [00:20<00:01, 79198.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  93%|█████████▎| 1657000/1781587 [00:21<00:01, 80365.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  94%|█████████▎| 1666000/1781587 [00:21<00:01, 77754.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  94%|█████████▍| 1675000/1781587 [00:21<00:01, 80315.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  94%|█████████▍| 1683489/1781587 [00:21<00:01, 81398.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  95%|█████████▌| 1695722/1781587 [00:21<00:00, 92412.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  96%|█████████▌| 1705700/1781587 [00:21<00:00, 93664.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  96%|█████████▋| 1715422/1781587 [00:21<00:00, 93288.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  97%|█████████▋| 1727378/1781587 [00:21<00:00, 98902.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  98%|█████████▊| 1737564/1781587 [00:21<00:00, 97612.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  98%|█████████▊| 1747748/1781587 [00:22<00:00, 96455.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  99%|█████████▊| 1757680/1781587 [00:22<00:00, 93437.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72):  99%|█████████▉| 1767866/1781587 [00:22<00:00, 73206.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72): 100%|█████████▉| 1776098/1781587 [00:23<00:00, 17328.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=72): 100%|██████████| 1781587/1781587 [00:25<00:00, 70260.59 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (0/23 shards):   0%|          | 0/415896 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (0/23 shards):   1%|          | 3000/415896 [00:00<00:19, 20816.89 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (0/23 shards):   1%|▏         | 6000/415896 [00:00<00:20, 19586.58 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (0/23 shards):   2%|▏         | 10000/415896 [00:00<00:18, 21833.83 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (0/23 shards):   3%|▎         | 14000/415896 [00:00<00:17, 22768.47 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (0/23 shards):   4%|▍         | 18000/415896 [00:00<00:17, 23049.38 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (1/23 shards):   4%|▍         | 18083/415896 [00:00<00:17, 23049.38 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (1/23 shards):   5%|▌         | 22083/415896 [00:01<00:20, 19353.71 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (1/23 shards):   6%|▋         | 26083/415896 [00:01<00:18, 20777.68 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (1/23 shards):   7%|▋         | 30083/415896 [00:01<00:17, 22023.03 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (1/23 shards):   8%|▊         | 34083/415896 [00:01<00:16, 22840.75 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (2/23 shards):   9%|▊         | 36166/415896 [00:01<00:16, 22840.75 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (2/23 shards):   9%|▉         | 38166/415896 [00:01<00:16, 22672.93 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (2/23 shards):  10%|█         | 42166/415896 [00:01<00:18, 19939.83 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (2/23 shards):  11%|█         | 46166/415896 [00:02<00:17, 21293.08 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (2/23 shards):  12%|█▏        | 50166/415896 [00:02<00:16, 22296.80 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (2/23 shards):  13%|█▎        | 54166/415896 [00:02<00:15, 23109.57 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (3/23 shards):  13%|█▎        | 54249/415896 [00:02<00:15, 23109.57 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (3/23 shards):  14%|█▍        | 58249/415896 [00:02<00:19, 18340.52 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (3/23 shards):  15%|█▍        | 62249/415896 [00:02<00:17, 19846.32 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (3/23 shards):  16%|█▌        | 66249/415896 [00:03<00:16, 21155.82 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (3/23 shards):  17%|█▋        | 70249/415896 [00:03<00:15, 22280.27 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (4/23 shards):  17%|█▋        | 72332/415896 [00:03<00:15, 22280.27 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (4/23 shards):  18%|█▊        | 74332/415896 [00:03<00:15, 22496.68 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (4/23 shards):  19%|█▉        | 78332/415896 [00:03<00:19, 17585.55 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (4/23 shards):  20%|█▉        | 82332/415896 [00:03<00:17, 19359.75 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (4/23 shards):  21%|██        | 86332/415896 [00:04<00:15, 20800.95 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (4/23 shards):  22%|██▏       | 90332/415896 [00:04<00:14, 21944.83 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (5/23 shards):  22%|██▏       | 90415/415896 [00:04<00:14, 21944.83 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (5/23 shards):  23%|██▎       | 94415/415896 [00:04<00:16, 18939.32 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (5/23 shards):  24%|██▎       | 98415/415896 [00:04<00:15, 20419.96 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (5/23 shards):  25%|██▍       | 102415/415896 [00:04<00:14, 21717.85 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (5/23 shards):  26%|██▌       | 106415/415896 [00:05<00:13, 22695.86 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (6/23 shards):  26%|██▌       | 108498/415896 [00:05<00:13, 22695.86 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (6/23 shards):  27%|██▋       | 110498/415896 [00:05<00:13, 22470.62 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (6/23 shards):  28%|██▊       | 114498/415896 [00:05<00:15, 19768.70 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (6/23 shards):  28%|██▊       | 118498/415896 [00:05<00:14, 21130.06 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (6/23 shards):  29%|██▉       | 122498/415896 [00:05<00:13, 22151.18 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (6/23 shards):  30%|███       | 126498/415896 [00:05<00:12, 22968.41 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (7/23 shards):  30%|███       | 126581/415896 [00:05<00:12, 22968.41 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (7/23 shards):  31%|███▏      | 130581/415896 [00:06<00:16, 17153.43 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (7/23 shards):  32%|███▏      | 134581/415896 [00:06<00:14, 18986.77 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (7/23 shards):  33%|███▎      | 138581/415896 [00:06<00:13, 20561.30 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (7/23 shards):  34%|███▍      | 142581/415896 [00:06<00:12, 21758.19 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (8/23 shards):  35%|███▍      | 144664/415896 [00:06<00:12, 21758.19 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (8/23 shards):  35%|███▌      | 146664/415896 [00:06<00:12, 22379.19 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (8/23 shards):  36%|███▌      | 150664/415896 [00:07<00:14, 18621.49 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (8/23 shards):  37%|███▋      | 154664/415896 [00:07<00:12, 20181.58 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (8/23 shards):  38%|███▊      | 158664/415896 [00:07<00:11, 21504.59 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (8/23 shards):  39%|███▉      | 162664/415896 [00:07<00:11, 22525.16 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (9/23 shards):  39%|███▉      | 162747/415896 [00:07<00:11, 22525.16 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (9/23 shards):  40%|████      | 166747/415896 [00:08<00:15, 16093.35 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (9/23 shards):  41%|████      | 170747/415896 [00:08<00:13, 17977.49 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (9/23 shards):  42%|████▏     | 174747/415896 [00:08<00:12, 19646.17 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (9/23 shards):  43%|████▎     | 178747/415896 [00:08<00:11, 21015.18 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (10/23 shards):  43%|████▎     | 180830/415896 [00:08<00:11, 21015.18 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (10/23 shards):  44%|████▎     | 181830/415896 [00:08<00:11, 20334.09 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (10/23 shards):  44%|████▍     | 184830/415896 [00:09<00:12, 18474.18 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (10/23 shards):  45%|████▌     | 188830/415896 [00:09<00:11, 20297.02 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (10/23 shards):  46%|████▋     | 192830/415896 [00:09<00:10, 21695.36 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (10/23 shards):  47%|████▋     | 196830/415896 [00:09<00:09, 22733.55 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (11/23 shards):  48%|████▊     | 198912/415896 [00:09<00:09, 22733.55 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (11/23 shards):  48%|████▊     | 200912/415896 [00:09<00:09, 22991.06 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (11/23 shards):  49%|████▉     | 204912/415896 [00:10<00:12, 17508.42 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (11/23 shards):  50%|█████     | 208912/415896 [00:10<00:10, 19275.93 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (11/23 shards):  51%|█████     | 212912/415896 [00:10<00:09, 20765.35 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (11/23 shards):  52%|█████▏    | 216912/415896 [00:10<00:09, 22025.93 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (12/23 shards):  52%|█████▏    | 216994/415896 [00:10<00:09, 22025.93 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (12/23 shards):  53%|█████▎    | 220994/415896 [00:10<00:10, 18052.85 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (12/23 shards):  54%|█████▍    | 224994/415896 [00:10<00:09, 19717.36 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (12/23 shards):  55%|█████▌    | 228994/415896 [00:11<00:08, 21160.74 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (12/23 shards):  56%|█████▌    | 232994/415896 [00:11<00:08, 22298.26 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (13/23 shards):  57%|█████▋    | 235076/415896 [00:11<00:08, 22298.26 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (13/23 shards):  57%|█████▋    | 237076/415896 [00:11<00:07, 22681.03 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (13/23 shards):  58%|█████▊    | 241076/415896 [00:11<00:09, 18325.70 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (13/23 shards):  59%|█████▉    | 245076/415896 [00:11<00:08, 19969.21 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (13/23 shards):  60%|█████▉    | 249076/415896 [00:12<00:07, 21347.37 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (13/23 shards):  61%|██████    | 253076/415896 [00:12<00:07, 22430.46 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (14/23 shards):  61%|██████    | 253158/415896 [00:12<00:07, 22430.46 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (14/23 shards):  62%|██████▏   | 257158/415896 [00:12<00:08, 18406.25 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (14/23 shards):  63%|██████▎   | 261158/415896 [00:12<00:07, 20015.11 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (14/23 shards):  64%|██████▍   | 265158/415896 [00:12<00:07, 21380.20 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (14/23 shards):  65%|██████▍   | 269158/415896 [00:13<00:06, 22428.44 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (15/23 shards):  65%|██████▌   | 271240/415896 [00:13<00:06, 22428.44 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (15/23 shards):  66%|██████▌   | 273240/415896 [00:13<00:06, 22912.80 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (15/23 shards):  67%|██████▋   | 277240/415896 [00:13<00:07, 18965.11 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (15/23 shards):  68%|██████▊   | 281240/415896 [00:13<00:06, 20472.74 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (15/23 shards):  69%|██████▊   | 285240/415896 [00:13<00:06, 21656.38 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (15/23 shards):  70%|██████▉   | 289240/415896 [00:13<00:05, 22651.70 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (16/23 shards):  70%|██████▉   | 289322/415896 [00:13<00:05, 22651.70 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (16/23 shards):  70%|███████   | 292322/415896 [00:14<00:05, 22535.07 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (16/23 shards):  71%|███████   | 295322/415896 [00:14<00:06, 18657.82 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (16/23 shards):  72%|███████▏  | 299322/415896 [00:14<00:05, 20390.70 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (16/23 shards):  73%|███████▎  | 303322/415896 [00:14<00:05, 21727.07 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (16/23 shards):  74%|███████▍  | 307322/415896 [00:14<00:04, 22670.09 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (17/23 shards):  74%|███████▍  | 307404/415896 [00:14<00:04, 22670.09 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (17/23 shards):  75%|███████▍  | 311404/415896 [00:15<00:05, 17923.33 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (17/23 shards):  76%|███████▌  | 315404/415896 [00:15<00:05, 19611.82 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (17/23 shards):  77%|███████▋  | 319404/415896 [00:15<00:04, 21015.95 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (17/23 shards):  78%|███████▊  | 323404/415896 [00:15<00:04, 22136.87 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (18/23 shards):  78%|███████▊  | 325486/415896 [00:15<00:04, 22136.87 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (18/23 shards):  79%|███████▊  | 327486/415896 [00:15<00:03, 22589.90 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (18/23 shards):  80%|███████▉  | 331486/415896 [00:16<00:04, 19327.03 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (18/23 shards):  81%|████████  | 335486/415896 [00:16<00:03, 20762.49 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (18/23 shards):  82%|████████▏ | 339486/415896 [00:16<00:03, 22040.13 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (18/23 shards):  83%|████████▎ | 343486/415896 [00:16<00:03, 22942.09 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (19/23 shards):  83%|████████▎ | 343568/415896 [00:16<00:03, 22942.09 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (19/23 shards):  84%|████████▎ | 347568/415896 [00:16<00:04, 16267.84 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (19/23 shards):  85%|████████▍ | 351568/415896 [00:17<00:03, 18144.34 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (19/23 shards):  85%|████████▌ | 355568/415896 [00:17<00:03, 19859.31 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (19/23 shards):  86%|████████▋ | 359568/415896 [00:17<00:02, 21225.74 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (20/23 shards):  87%|████████▋ | 361650/415896 [00:17<00:02, 21225.74 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (20/23 shards):  87%|████████▋ | 363650/415896 [00:17<00:02, 21942.67 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (20/23 shards):  88%|████████▊ | 367650/415896 [00:17<00:02, 17792.18 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (20/23 shards):  89%|████████▉ | 371650/415896 [00:18<00:02, 19519.85 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (20/23 shards):  90%|█████████ | 375650/415896 [00:18<00:01, 20927.41 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (20/23 shards):  91%|█████████▏| 379650/415896 [00:18<00:01, 22035.37 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (21/23 shards):  91%|█████████▏| 379732/415896 [00:18<00:01, 22035.37 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (21/23 shards):  92%|█████████▏| 382732/415896 [00:18<00:01, 20390.22 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (21/23 shards):  93%|█████████▎| 385732/415896 [00:18<00:01, 18346.78 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (21/23 shards):  94%|█████████▎| 389732/415896 [00:18<00:01, 20195.36 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (21/23 shards):  95%|█████████▍| 393732/415896 [00:19<00:01, 21527.42 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (21/23 shards):  96%|█████████▌| 397732/415896 [00:19<00:00, 22620.26 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (22/23 shards):  96%|█████████▌| 397814/415896 [00:19<00:00, 22620.26 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (22/23 shards):  97%|█████████▋| 401814/415896 [00:19<00:00, 17584.40 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (22/23 shards):  98%|█████████▊| 405814/415896 [00:19<00:00, 19259.81 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (22/23 shards):  99%|█████████▊| 409814/415896 [00:19<00:00, 20668.55 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (22/23 shards):  99%|█████████▉| 413814/415896 [00:20<00:00, 21816.67 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (23/23 shards): 100%|██████████| 415896/415896 [00:20<00:00, 21816.67 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (23/23 shards): 100%|██████████| 415896/415896 [00:20<00:00, 20572.21 examples/s]\u001b[0m\n",
      "\u001b[34mSaved data to: /opt/ml/input/data/train/huggingface-dataset-workertest-1-00-32-41/\u001b[0m\n",
      "\u001b[34m2024-04-19 00:36:02,905 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-04-19 00:36:02,905 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-04-19 00:36:02,905 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-04-19 00:37:12 Uploading - Uploading generated training model\n",
      "2024-04-19 00:37:20 Completed - Resource retained for reuse\n",
      "Training seconds: 272\n",
      "Billable seconds: 272\n"
     ]
    }
   ],
   "source": [
    "data_output_path = \"s3://sagemaker-demo-c4/\"\n",
    "\n",
    "base_job_name = f'huggingface-dataset-workertest'\n",
    "\n",
    "job_names=[]\n",
    "\n",
    "#for worker_index in range(len(worker_batches)):\n",
    "for worker_index in range(2):\n",
    "    current_time = datetime.datetime.now().strftime(\"%H-%M-%S\")\n",
    "\n",
    "    dataset_job_name = f'{base_job_name}-{worker_index}-{current_time}'\n",
    "\n",
    "    print(dataset_job_name)\n",
    "\n",
    "    job_names.append(dataset_job_name)\n",
    "    \n",
    "    # hyperparameters, which are passed into the training job\n",
    "    hyperparameters = {\n",
    "        \"model_id\": model_id,  # model id from huggingface.co/models\n",
    "        \"num_proc\": 72,\n",
    "        \"split_range\": ','.join(map(str, worker_batches[worker_index])),\n",
    "        \"job_name\": dataset_job_name\n",
    "    }\n",
    "    \n",
    "    # estimator\n",
    "    estimator = PyTorch(\n",
    "        entry_point=\"data.py\",\n",
    "        max_run=1800,\n",
    "        role=role,\n",
    "        framework_version=\"2.0.1\",\n",
    "        py_version=\"py310\",\n",
    "        source_dir=\"./scripts\",\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.c5.18xlarge\",\n",
    "        volume_size=200,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        disable_output_compression=True,\n",
    "        keep_alive_period_in_seconds=600,\n",
    "        hyperparameters=hyperparameters,\n",
    "        output_path=data_output_path,\n",
    "        subnets=['subnet-0067baa7d7be55e38'],\n",
    "        security_group_ids=['sg-05ffe325d7d90c501']\n",
    "    )\n",
    "\n",
    "    # starting the train job with our uploaded datasets as input\n",
    "    estimator.fit(inputs=data_channels, wait=True, job_name=dataset_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['huggingface-dataset-workertest-0-00-25-54',\n",
       " 'huggingface-dataset-workertest-1-00-32-41']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/amazon-sagemaker-examples/training/distributed_training/pytorch/data_parallel/fully_sharded_data_parallel/falcon\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start our training job, with the `.fit()` method passing our S3 path to the training script."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Expected Output\n",
    "\n",
    "After training begins, you should see output similar to below: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```4%|▍         | 1/25 [00:08<03:29,  8.72s/it]\n",
    "8%|▊         | 2/25 [00:10<01:41,  4.39s/it]\n",
    "12%|█▏        | 3/25 [00:11<01:06,  3.01s/it]\n",
    "16%|█▌        | 4/25 [00:12<00:49,  2.35s/it]\n",
    "20%|██        | 5/25 [00:14<00:39,  1.99s/it]\n",
    "24%|██▍       | 6/25 [00:15<00:33,  1.77s/it]\n",
    "28%|██▊       | 7/25 [00:16<00:29,  1.64s/it]\n",
    "32%|███▏      | 8/25 [00:18<00:26,  1.55s/it]\n",
    "36%|███▌      | 9/25 [00:19<00:23,  1.48s/it]\n",
    "40%|████      | 10/25 [00:20<00:21,  1.44s/it]\n",
    "44%|████▍     | 11/25 [00:22<00:19,  1.41s/it]\n",
    "48%|████▊     | 12/25 [00:23<00:18,  1.40s/it]\n",
    "52%|█████▏    | 13/25 [00:24<00:16,  1.38s/it]\n",
    "56%|█████▌    | 14/25 [00:26<00:15,  1.37s/it]\n",
    "60%|██████    | 15/25 [00:27<00:13,  1.37s/it]\n",
    "64%|██████▍   | 16/25 [00:29<00:12,  1.36s/it]\n",
    "68%|██████▊   | 17/25 [00:30<00:10,  1.36s/it]\n",
    "72%|███████▏  | 18/25 [00:31<00:09,  1.35s/it]\n",
    "76%|███████▌  | 19/25 [00:33<00:08,  1.35s/it]\n",
    "80%|████████  | 20/25 [00:34<00:06,  1.35s/it]\n",
    "84%|████████▍ | 21/25 [00:35<00:05,  1.35s/it]\n",
    "88%|████████▊ | 22/25 [00:37<00:04,  1.35s/it]\n",
    "92%|█████████▏| 23/25 [00:38<00:02,  1.35s/it]\n",
    "96%|█████████▌| 24/25 [00:39<00:01,  1.35s/it]\n",
    "100%|██████████| 25/25 [00:41<00:00,  1.35s/it]\n",
    "100%|██████████| 25/25 [00:41<00:00,  1.65s/it]\n",
    "******epoch=0: train_ppl=tensor(43260.7148, device='cuda:0') train_loss=tensor(10.6750, device='cuda:0')******\n",
    "0it [00:00, ?it/s]\n",
    "0it [00:00, ?it/s]\n",
    "*******epoch=0: eval_ppl=tensor(nan, device='cuda:0') eval_loss=tensor(nan, device='cuda:0')*******\n",
    "Training done!`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Terminate the warm pool cluster if no longer needed\n",
    "\n",
    "You can terminate the warm pool cluster once finished experimenting to reduce billed time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.update_training_job(\n",
    "    estimator.latest_training_job.job_name, resource_config={\"KeepAlivePeriodInSeconds\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%H-%M-%S\")\n",
    "training_job_name = f'huggingface-training-worker-{current_time}'\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters = {\n",
    "    \"model_id\": model_id,  # model id from huggingface.co/models\n",
    "    \"dataset_path\": \"/opt/ml/input/data/train\",  # path where sagemaker will save training dataset\n",
    "    \"valid_path\": \"/opt/ml/input/data/valid\",\n",
    "    \"gradient_checkpointing\": True,  # enable gradient checkpointing\n",
    "    \"bf16\": True,  # enable mixed precision training\n",
    "    \"optimizer\": \"adamw_torch\",  # optimizer\n",
    "    \"per_device_train_batch_size\": 1,  # batch size per device during training\n",
    "    \"epochs\": 1,  # number of epochs to train\n",
    "    \"fsdp\": '\"full_shard auto_wrap\"',  # fully sharded data parallelism\n",
    "    \"cache_dir\": \"/opt/ml/sagemaker/warmpoolcache\",  # change this to /tmp if not using warmpools\n",
    "    \"max_steps\": 1000,\n",
    "}\n",
    "\n",
    "# estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",\n",
    "    max_run=1800,\n",
    "    base_job_name=job_name,\n",
    "    role=role,\n",
    "    framework_version=\"2.0.1\",\n",
    "    py_version=\"py310\",\n",
    "    source_dir=\"./scripts\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p4d.24xlarge\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    disable_output_compression=True,\n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},\n",
    "    keep_alive_period_in_seconds=600,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=training_input_path,\n",
    "    subnets=['subnet-0067baa7d7be55e38'],\n",
    "    security_group_ids=['sg-05ffe325d7d90c501']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-training-worker-02-36-20-2024-04-19-02-49-04-099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-19 02:49:04 Starting - Starting the training job...\n",
      "2024-04-19 02:49:08 Pending - Training job failed for insufficient capacity\n",
      "2024-04-19 02:49:08 Failed - Training job failed\n",
      ".."
     ]
    },
    {
     "ename": "CapacityError",
     "evalue": "Error for Training job huggingface-training-worker-02-36-20-2024-04-19-02-49-04-099: Failed. Reason: CapacityError: Unable to provision requested ML compute capacity. Please retry using a different ML instance type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCapacityError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/estimator.py:1341\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_training_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/estimator.py:2680\u001b[0m, in \u001b[0;36m_TrainingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2678\u001b[0m \u001b[38;5;66;03m# If logs are requested, call logs_for_jobs.\u001b[39;00m\n\u001b[1;32m   2679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 2680\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2682\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:5760\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   5739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogs_for_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_name, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, poll\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, log_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll\u001b[39m\u001b[38;5;124m\"\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   5740\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Display logs for a given training job, optionally tailing them until job is complete.\u001b[39;00m\n\u001b[1;32m   5741\u001b[0m \n\u001b[1;32m   5742\u001b[0m \u001b[38;5;124;03m    If the output is a tty or a Jupyter cell, it will be color-coded\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5758\u001b[0m \u001b[38;5;124;03m        exceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[39;00m\n\u001b[1;32m   5759\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5760\u001b[0m     \u001b[43m_logs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:7989\u001b[0m, in \u001b[0;36m_logs_for_job\u001b[0;34m(sagemaker_session, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   7986\u001b[0m             last_profiler_rule_statuses \u001b[38;5;241m=\u001b[39m profiler_rule_statuses\n\u001b[1;32m   7988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 7989\u001b[0m     \u001b[43m_check_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrainingJobStatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7990\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dot:\n\u001b[1;32m   7991\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:8037\u001b[0m, in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   8033\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError for \u001b[39m\u001b[38;5;132;01m{job_type}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{job_name}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{status}\u001b[39;00m\u001b[38;5;124m. Reason: \u001b[39m\u001b[38;5;132;01m{reason}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   8034\u001b[0m     job_type\u001b[38;5;241m=\u001b[39mjob_type, job_name\u001b[38;5;241m=\u001b[39mjob, status\u001b[38;5;241m=\u001b[39mstatus, reason\u001b[38;5;241m=\u001b[39mreason\n\u001b[1;32m   8035\u001b[0m )\n\u001b[1;32m   8036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[0;32m-> 8037\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   8038\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   8039\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   8040\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   8041\u001b[0m     )\n\u001b[1;32m   8042\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   8043\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   8044\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   8045\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   8046\u001b[0m )\n",
      "\u001b[0;31mCapacityError\u001b[0m: Error for Training job huggingface-training-worker-02-36-20-2024-04-19-02-49-04-099: Failed. Reason: CapacityError: Unable to provision requested ML compute capacity. Please retry using a different ML instance type."
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs=data_channels, wait=True,job_name=training_job_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/training|distributed_training|pytorch|data_parallel|fully_sharded_data_parallel|falcon|smddp_fsdp_example.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/training|distributed_training|pytorch|data_parallel|fully_sharded_data_parallel|falcon|smddp_fsdp_example.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/training|distributed_training|pytorch|data_parallel|fully_sharded_data_parallel|falcon|smddp_fsdp_example.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/training|distributed_training|pytorch|data_parallel|fully_sharded_data_parallel|falcon|smddp_fsdp_example.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/training|distributed_training|pytorch|data_parallel|fully_sharded_data_parallel|falcon|smddp_fsdp_example.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/training|distributed_training|pytorch|data_parallel|fully_sharded_data_parallel|falcon|smddp_fsdp_example.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/training|distributed_training|pytorch|data_parallel|fully_sharded_data_parallel|falcon|smddp_fsdp_example.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/training|distributed_training|pytorch|data_parallel|fully_sharded_data_parallel|falcon|smddp_fsdp_example.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/training|distributed_training|pytorch|data_parallel|fully_sharded_data_parallel|falcon|smddp_fsdp_example.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/training|distributed_training|pytorch|data_parallel|fully_sharded_data_parallel|falcon|smddp_fsdp_example.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/training|distributed_training|pytorch|data_parallel|fully_sharded_data_parallel|falcon|smddp_fsdp_example.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/training|distributed_training|pytorch|data_parallel|fully_sharded_data_parallel|falcon|smddp_fsdp_example.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/training|distributed_training|pytorch|data_parallel|fully_sharded_data_parallel|falcon|smddp_fsdp_example.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/training|distributed_training|pytorch|data_parallel|fully_sharded_data_parallel|falcon|smddp_fsdp_example.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/training|distributed_training|pytorch|data_parallel|fully_sharded_data_parallel|falcon|smddp_fsdp_example.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
